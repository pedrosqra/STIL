{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["6CoLDMkY4Ew2","o2W-_Q-x7gKr","PJS9yuGDHpk8","UWQ8xRwaE6f6","vxLYKlXCFu3b","ekjL9_-gBrXC"],"authorship_tag":"ABX9TyNyr1ZGgS5AdI/G2Da88tly"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"Ahuma_oVQHth"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"Bgf8bXUlF7jD","executionInfo":{"status":"ok","timestamp":1725287682459,"user_tz":180,"elapsed":9675,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6e2d514a-d6b3-4b44-c993-39106546aee9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: diff-match-patch in /usr/local/lib/python3.10/dist-packages (20230430)\n","Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (0.25.1)\n","Requirement already satisfied: Levenshtein==0.25.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein) (0.25.1)\n","Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.25.1->python-Levenshtein) (3.9.6)\n"]}],"source":["!pip install -U -q google-generativeai\n","!pip install diff-match-patch\n","!pip install python-Levenshtein\n","import google.generativeai as genai\n","from google.colab import userdata\n","import pandas as pd\n","import Levenshtein\n","import json\n","import difflib\n","import time\n","import re\n","import unicodedata\n","from difflib import SequenceMatcher"]},{"cell_type":"code","source":["GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n","genai.configure(api_key=GOOGLE_API_KEY)\n","model = genai.GenerativeModel('gemini-1.5-pro-exp-0827')\n","\n","def get_response_and_time(prompt):\n","  start_time = time.time()\n","  response = model.generate_content(prompt)\n","  end_time = time.time()\n","  return response, end_time - start_time\n","response, duration = get_response_and_time(\"Say 'hello world' and nothing else\")\n","print(response.text)\n","print(duration)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"id":"RAHxHBzql_B9","executionInfo":{"status":"ok","timestamp":1725287684792,"user_tz":180,"elapsed":2335,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"outputId":"97981288-8286-4236-8196-44ee61fa12f1"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["hello world\n","1.0701103210449219\n"]}]},{"cell_type":"code","source":["df2 = pd.read_excel('/content/grupo 1 (revisado).xlsx')\n","marked = \" \".join(df2.iloc[:, 0].astype(str).tolist())\n","print(marked)"],"metadata":{"id":"bmOZaBWpGFGG","executionInfo":{"status":"ok","timestamp":1725287685456,"user_tz":180,"elapsed":668,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dae1e74d-c794-4934-e95b-5cf7e33fdbd1"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Vamos lá, <hes é/>  boa tarde todo mundo. Bem-vindos a este debate. Promovido pelo grupo de pesquisa do lacina debate em educação. Eu me chamo David e gostaria de apresentar aqui, quem está comigo, Klaywert que também faz parte do grupo. Mas aí a gente tem também Bryan e Hellen, que são tirando Hellen, a maioria estudante do mestrado, Hellen é estudante da graduação. <hes é/>, e esse projeto está sobre orientação do professor Campelo, que é o professor <erro que vocês conhecem/> <corr que vocês conheceram> agorinha. que vocês viram agora certo, okay, a razão pela qual nos reunimos aqui hoje, <rep é é/>  gerar uma base de dados de voz que posteriormente será transcrita e utilizada para avaliação e treinamento de modelos de inteligência artificial. Nosso foco está entre vários tópicos relacionados a debates, fazendo dessas iniciativa não apenas oportunidade de aprendizado e crescimento mas também uma contribuição valiosa para avanço de IA. \n","Vocês assinaram o termo, né? Todo mundo já assinou o termo, então a gente pode pular essa parte <erro cada um/> <corr cada /> debatedor vai receber uma identificação, né? Vocês já receberam <hes ee/> essa vai ser a identificação de vocês, como os debatedores, aqui a gente não estava interessado nos dados pessoais de vocês, então o processo vai ser identificado dessa forma com esses IDs, <hes é é/> certo? a gente vai gravar a voz de vocês.\n","Vocês assinaram o termo, né? Todo mundo já assinou o termo, então a gente pode pular essa parte <erro cada um/> <corr cada /> debatedor vai receber uma identificação, né? Vocês já receberam <hes ee/> essa vai ser a identificação de vocês, como os debatedores, aqui a gente não estava interessado nos dados pessoais de vocês, então o processo vai ser identificado dessa forma com esses IDs, <hes é é/> certo? a gente vai gravar a voz de vocês. Minha identificação número um. Estou contribuindo com a pesquisa no Brasil. Minha identificação número dois, estou contribuindo com a pesquisa no Brasil. Minha identificação número tres, estou contribuindo com a pesquisa no Brasil. Minha identificação número quatro, estou contribuindo com a pesquisa no Brasil. É, explicando as regras do debate. Antes da gente começar o debate é essencial, que todos compreendam e sigam as regras do debate, essas regras foram criadas para garantir um debate justo e ordenado para todos os envolvidos. Primeira regra sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando. Se você deseja contribuir para a discussão, oferecer algum contra argumento, por favor, levante a mão e aguarde o moderador, eu, lhe conceder a palavra, uma vez que tenha sido autorizado a falar, você terá a palavra poderá expressar seus pensamentos e responder aos outros também.\n","Certo, explicando o funcionamento do debate, vamos seguir em formato estruturado de de três momentos distintos, cada um com seu propósito e regras específicas. Momento um expressão inicial  <erro do /> <corr de />  suas opiniões. No primeiro momento, abordaremos a questão principal do debate e objetivo é  que <erro cada um/> <corr cada />, participante expresse sua opinião inicial sobre o tema central. Momento dois, rodada de perguntas. Num segundo momento teremos uma rodada de perguntas direcionada para cada um dos debatedores, abriremos espaço para os outros participantes contra argumentarem ou expressarem suas opiniões sobre a resposta dada após as perguntas direcionadas, teremos uma outra pergunta, que será direcionadas a todos os participante, neste momento, vocês terão a liberdade de escolher se desejam responder, caso que tenha algo relevante a acrescentar. No momento três é colocações finais, um terceiro e ultimo momento, será perguntado se os participantes têm alguma outra colocação final sobre o tema.\n","Certo ? <hes ãã> OK, então a gente vai começar agora. Ficou alguma duvida antes de tudo ? deu para entender. Vão ser três momentos o debate, então, vai ser um debate semi estruturado, se alguém quiser falar, tem que pedir a vez, não pode estar interrompendo o outro e é basicamente essas regras que vocês devem seguir e a gente vai ter umas perguntas para nortear o debate também, que eu vou mostrar, vou botar ali na tela e vou ler para vocês também essas perguntas, OK?\n","Certo, como vocês já sabem, o nosso tema é inteligência artificial generativa e seus impactos na sociedade. OK? Para começar, primeiramente, cada um terá um momento inicial para expressar <erro seus principais/> <corr cada /> opiniões e pensamentos sobre o tema,  <rep cada cada/> participante terá um momento para fazer isso, certo? Vamos começar com o debatedor 1, você gostaria de expressar a sua opinião? De forma geral, o que é que você pensa sobre o tema? Bom, as IAs generativas são bem dizer uma faca de dois gumes, né? Tem aspectos positivos e muito negativos também, positivos tem <rep automação automação/>  de algumas atividades  <hes é/É/éh/> pode auxiliar como ferramenta complementar em estudos como negativa, tem a questão de proteção de dados, de autenticidade, de resposta, infração de direitos autorais. Então, dependendo da área do argumento que quiser seguir, pode ser positivo ou negativo. Agora o debatedor 2 olha em relação a os impactos positivos que <hes é/É/éh/> as coisas repetitivas vão ser ao longo do tempo eliminadas alguns trabalhos que precisam de muita repetição e o que meio que vai ficar <hes é/É/éh/>, acho que produção intelectual intelectualizada que a IA não consegue fazer bem, inclusive os modelos atuais <hes é/É/éh/> <rep em em/>  relação a opiniões também e também <hes oo/oh /> <erro ele não/>, <corr ele tem /> um filtro muito grande, então acho que  <erro deve/>, <corr desde /> que não infrija nenhuma lei deve ter maior liberdade de criação. Os negativos, eu acho que problemas como o deep fake  <rep e e e/>  geração de voz também pelo timbre. Eu acho que vai ser um problema muito grande para as autoridades lidar e fazer contra medidas que reconheçam se aquilo é de fato verdade ou não, e meio que impulsiona a desinformação em relação a estudo também, eu acho que tende a, dependendo da base de dados ou a piorar a situação ou a melhorar, então acho que no futuro a especificação das IAs não ser um aí a geral, ser mais nichado é com os vetores de informação, vai vir a melhorar esse problema  <rep de de/> espalhar mentiras. Debatedora três É embora esse seja um assunto, um conteúdo que já venha sido tratado há muito tempo, várias pessoas já tenham trabalhado nisso <hes é/É/éh/> ultimamente está tendo <rep um um/>  uma abordagem maior sobre isso. Acho que até depois <rep do do /> chat GPT  ter vindo, né? E aí o pessoal ficou sabendo muito. Eu, por exemplo, quando eu não tinha esse conhecimento, eu não sabia da existecia das IAs nesse sentido. Nesse aspecto, depois que eu conheci o chat, eu consegui compreender mais e como os meninos falaram, ele tem aspectos muito positivos, e justamente pela pela automação, pela facilidade, pela agilidade, mas eu acho também que os usos negativos dele pode impactar também na autenticidade do próprio ser humano, como o texto diz, mesmo a criatividade, a humanização  <hes é/É/éh/> os textos por exemplo, quando a gente vai ver no TikTok e o pessoal está usando aquelas vozes fakes <erro tem são/>, <corr são /> a voz que você jura que é uma pessoa real, só que não tem as expressões e eu acho que <rep um um/> expressão de ironia, de sarcasmo, que o ser humano ele consegue ter, isso é algo do ser humano menos a IA, não consegue obter. Então eu acho que pode ser útil, sim, para facilitar a nossa vida mesmo, mas não com um substituto de coisas que só o ser humano consegue fazer. Debatedor <erro cinco/>, <corr quatro/> <hes é/É/éh/> sobre, as IAs, assim acho que o principal mesmo é em relação ao trabalho <erro que vai ser/> <corr que não tem/> como você lutar contra esse crescimento da IAs em relação à substituição de empregos. É algo desde a revolução industrial, até antes que a tecnologia sempre vai substituir o ser humano e algo que é, <rep não, não/> pode ser parado sobre <hes é/É/éh/>  regulamentação, <hes é/É/éh/>  etc. Eu acho que o principal ponto, na minha opinião, <rep é é> sobre o uso de banco de dados <erro de/> <corr com/> direitos autorais para geração de novas coisas, porque a maioria <erro da/> <corr das/> vezes que nesses essas IAs gerativas usam banco de dados de coisas já existentes, como por exemplo, desenhos já vozes e etc, para criar novas coisas. Então acho que a pauta na legalização de IAs vai ser principalmente nessa área de você poder ou não usar o desenho de alguém para gerar novos desenhos, e etc. Certo, vamos iniciar com a rodada de perguntas irei realizar uma pergunta para cada participante que terá seu tempo de resposta e ao final de sua resposta, os demais podem pedir espaço para comentar algo sobre a pergunta feita ou a resposta dada? OK, vamos começar. A primeira pergunta é pro debatedor 1,  <hes é/É/éh/>  se um sistema de IA generativa cria algo prejudicial ou ofensivo. Por exemplo, uma imagem com conteúdo racista. Quem deve ser responsabilizado? O desenvolvedor da IA, o usuário, <rep a plataforma a plataforma/> que hospeda ou alguma outra instituição ou pessoa. O autor do texto da plataforma que hospeda, a plataforma e quase sempre o desenvolvedor da Ia, porque querendo ou não, é ele que criou a ferramenta para conseguir filtrar o que ela deve ou não buscar, porque realmente, com o as IAs, elas podem perpetuar preconceitos e estereótipo, porque eles fazem o filtro e podem, nesses textos que elas estão filtrando, acabar inserindo no texto que ela vai enviar para o usuário certas falas que não são adequadas <erro no/> <corr na/> sociedade atual. Alguém tem algo a comentar sobre a resposta do debatedor? <hes é/É/éh/> mais alguém tem alguma outra colocação sobre essa pergunta específica que queira comentar? Pode dizer. Às vezes o banco de dados da  IA, <rep que que /> traz para a propria IA, às vezes já vem com alguns dados <rep que que /> podem ser preconceituosos. Seja racistas ou sexistas, e etc. Às vezes isso já vem do próprio banco de dados, que gera novos dados que também são racistas, sexistas, etc. Acho que <rep na minha na minha /> visão.  Então tu acha que a pessoa culpada seria quem introduziu o dado? Não, eu não acho que a pessoa culpada <hes é/É/éh/> seria que produziu o dado assim <hes é/É/éh/> <hes hm/mm/>, não sei sinceramente eu teria que pensar um pouco mais para saber quem seria punido nessa daí, porque realmente <hes é/É/éh/>. Dentro das opções ali é eu pense a Pri, a priori, eu pensei no usuário, mas também o desenvolvedor. A plataforma pode inclinar <rep o o/> dado a sair como como algo racista ou sexista por exemplo eu acho que <rep é, é /> seria mais ou menos como se fosse a política do Instagram que tem aquele filtro de palavras negativas e ofensivas que você usa em comentários que justamente já pela consciência de que isso pode ocorrer. Tanto o desenvolvedor já cria esse filtro, essas diretrizes <rep de de/> política, de respeito, de direitos humanos e tal, essas coisas, quanto também do usuário, assim rep<que ele que ele/> escrever já ter, tipo um bloqueio pra pra isso não acontecer. Tanto a consciência do usuário pra estar pesquisando essas coisas quanto do desenvolvedor. Só para fazer um adendo minha resposta falei que pudia punir plataforma que hospeda, mas desde que, por exemplo, vamos supor seja um site de crônicas, ai a pessoa tem autoridade dentro do site. Agora, se for, por exemplo, um reddit, um fórum de discussão, aí eu já acho que não deva responsabilizar a plataforma e sim fazer como a debatedora 3 falou e fazer a questão do filtro antes da mensagem ser enviada. já evita problemas posteriores A culpa maior, seria de usuário, em si, da pessoa?  Sim Pode dizer debatedor 4 Porque também varia muito do conteúdo que está sendo gerado. Por exemplo, um texto é algo um pouco mais direto. Agora, uma imagem, um dado às vezes pode ser um pouco mais indireto, mais sutil, esse preconceito. Eu acho que o principal responsabilidade deve ser o usuário. Eu acho que o desenvolvedor da IA, ele não, assim a gente sabe que o usuário muitas vezes ele é muito criativo em quebrar as coisas. Então, se uma IA é muito generalista, talvez o usuário seja muito criativo em fazer com que esse conteúdo seja produzido. Então eu acho que é meio que foge um pouco do escopo do que o desenvolvedor consegue ou não pensar. Porque assim, desde que a internet é internet, tem gente, só pensando em como quebrar aquela coisa que está disposta ali, então eu acho que o principal problema é o usuário e não o desenvolvedor. É a mesma coisa de ter um carro e usuário do carro meio, que o motorista decidir se ele vai sair batendo em tudo ou vai seguir o fluxo normal, acho que é basicamente isso Até porque o propósito desse dessa IA criada pelo desenvolvedor é auxiliar,  <hes é/É/éh/> trazendo,  <hes é/É/éh/> manutenção, facilidade para a pessoa de modo benéfico. Então seria realmente culpa do usuário o mau uso <rep do do/> da plataforma. Então, por isso que seria necessário, justamente por causa de talvez não fosse necessário. Se o usuário não fizesse isso, mas como a gente sabe que isso já é um histórico muito grande de que as pessoas usam isso para quebrar as regras, então seria necessário já <erro uma/> <corr umas/> diretrizes, para evitar que esse problema viesse acontecer. Que a culpa, o pessoal iria culpar a marca também, né? A plataforma em si. Alguém tem mais alguma coisa a comentar? Certo, vamos para a pergunta 2. Para o debatedor 2, IAs generativas podem ser usadas nos processos educacionais, por exemplo, em aulas, atividades ou provas. O ou a aluna devem reportar o professor sobre o uso de IA generativa em suas atividades. São duas perguntas, né não três no caso, a primeira, eu acho que sim. Pode ajudar mais do que atrapalhar, desde que seja usado da forma correta. Inclusive acho que está tendo um movimento na academia. Acho foi que uma professora está falando que estão desenvolvendo papers para que isso seja incentivado e não desincentivado como foi em um primeiro momento, porque é mais pelo uso mesmo do usuário, porque tem gente que só coloca lá e pede para ele. Já vim na resposta direta, mas se você, por exemplo, às vezes eu até uso isso, você coloca a sua resposta. Pra Ele incrementar algo, ou então  <hes é/É/éh/> fazer com que ele mude a forma como aquilo tá sendo visto e na maioria das vezes funciona, então  <hes é/É/éh/> isso, agrega conhecimento. Se for uma coisa que parta de você, mas se você só manda ele fazer e meio que você só copia e cola, isso não tem conhecimento nenhum sendo gerado. Então acho que pode sim responder a segunda pergunta também em aulas, atividades e provas, fica até mais dinâmica, eu acho não fica algo muito engessado, como normalmente o ensino tradicional é, e eu acho que deve reportar, sim, também para o professor ter ciência de que aquilo está sendo usado e como isso foi usado, inclusive se você perguntar, pegar uma resposta pronta da inteligência artificial e devolver para ele perguntar se ela foi que ela fez isso, se eu me engano, ela diz que foi ela, então acho que sim. Alguém tem algum comentário sobre a resposta do debatedor 2? Só um ponto bem assim, simples no negócio específico que ele falou, ele falou que se você colocar uma resposta que a IA gerou, ela responde que foi ela que fez, mas assim isso é algo também que ainda está <rep um pouco um pouco /> em desenvolvimento, porque existe, por exemplo, certas respostas criadas por humanos que se colocar, por exemplo, no chat GPT. Ele disse que foi ele que fez, então ainda é uma coisa um pouco falha, que eu acho que tem que se melhorar. Tem algo a comentar sobre a resposta dele? Não, eu acho que é isso mesmo, até porque está tudo meio que começando, ainda está dando os primeiros passos, então, normal ter falhas e imprecisões. Também acho que ela pode ser utilizada, estava vendo no fórum <erro da/> <corr do/> IF de Santa Catarina, o professor de lá falou que podia ser usado na discussão do assunto, porque às vezes você joga lá uma pergunta e ele pode responder uma coisa que não tem sentido com a realidade. Ele quando vai filtrar lá ele pode acabar, criando uma teoria, entre aspas, que não existe. Ele falou que a pessoa fala assim, é mais interessante você focar <erro na pergunta da qualidade/>, <corr na qualidade da pergunta/>  que você vai fazer para IA do que a resposta em si que ela vai dar, que ajuda a ampliar a discussão dentro do diálogo dentro da sala. Infelizmente a gente sabe que no mundo atual, a maioria das pessoas usam só para obter uma resposta pronta, mas se fosse usado, se a gente tivesse no mundo ideal, ajudaria muito nos processos de estudo. Ajudaria nos processos de estudo porque como ele é, como a IA  <hes é/É/éh/>  junta, agrupa vários complementos, vários conteúdos, seria uma fonte muito rica de informação, de conteúdo, de exercício e tudo mais que fosse complementar. Então, para ser aplicado nas escolas, eu acho que seria muito bom os professores, por exemplo, criarem diretrizes também <erro de/> <corr da/> forma como eles <rep deveriam deveriam/> usar também com penalidades, se fosse criar resposta pronta, porque é muito, muito bom, é algo realmente <rep uma uma/>, a gente tem a faca e o queijo que pode muito bem facilitar e ajudar no nosso processo acadêmico, como também pode prejudicar, porque um aluno que só pega resposta pronta <rep do do/> chat GPT, ele pode tirar nota muito boa, mas ele não vai ser um bom aluno, bom profissional, porque ele só tá <hes é/É/éh/> copiando aquilo que não foi ele que fez e o ensino, Ele não é baseado nisso. Então <rep se se/> a gente souber realmente usar da forma correta, <erro o/>, <corr a/> IA, ela é muito, muito promissora na educação. Alguém tem mais algo a comentar? Vamos para a terceira pergunta para o para a debatedora 3, de que maneira a propriedade intelectual deve ser tratada quando o conteúdo é gerado por IA, por exemplo, se um usuário gerou uma música usando IA o crédito pela criação deve ser deste usuário ,da plataforma de IA utilizada ou do criador dos dados originais com os quais a IA foi treinada? <hes é/É/éh/> no caso <hes é/É/éh/>  a IA aplicada da mesma forma que um agrupamento <rep de de/> conteúdo com musica, por exemplo? Entendi, eu não sei, eu não tenho opinião formada sobre isso porque imagem, a pessoa só colocou, só, escreveu o texto. E ela gerou lá. Um agrupamento de várias coisas, mas a criatividade ela é a junção de várias ideias juntas. Então não tem nada de novo e extraordinário. É tudo coisas que já foram criadas, então se é a pessoa, criou uma música usando o IA. Eu acho que o crédito pode ser dela mas não totalmente, não tenho uma opinião formada sobre isso. Alguém tem algo a comentar sobre a resposta dela?  <hes é/É/éh/>  sobre a parte <rep do do /> criador dos dados originais com o qual a IA foi treinada. Eu acho que assim.  <hes é/É/éh/>  varia muito.  <hes é/É/éh/>  assim. É a principal questão, na minha opinião, porque se você  <hes é/É/éh/>  for ver os dados que foi treinado a IA, muitas vezes você pega, tenta pegar o, puts pera aí, tenta gerar alguma coisa com a IA e a maioria das vezes é só os dados originais, só que embaralhados. Então assim, é grande parte dos dados originais que é criado <rep essas essas /> novas coisas. Então. Então você acha que é o direito autoral é do dado original? Se for, se o banco de dados <rep foi foi/>, por exemplo, só de um autor, eu acho que sim. É que nem o cover <erro a gente/> <corr o cover/> de uma música, ela tem uma forma diferente, pode até usar, você usa as mesmas notas e tals, usar instrumento diferente, tem um estilo diferente. Só que a música original é <rep do do/> cantor que <rep do do/> cantor, do compositor que escreveu aquela música. Acho que tem <erro a mesma/> <corr o mesmo/> significado. Alguém tem algo a comentar sobre a resposta, sobre a pergunta? Tá, vamos para a pergunta 4, então, para o debatedor 4. Como garantir que conteúdos gerados por IA não sejam usados para espalhar informações tendenciosas, errêneas ou maliciosos, por exemplo, quando este tipo de informação é propagada maximamente por bots em uma rede social, a responsabilidade deve ser da empresa que administra a Rede Social, dos programadores da IA ou de quem produziu aquele conteúdo usando a IA.  Tá, vamos lá. <hes é/É/éh/> acho que a primeira parte é como garantir que <rep esses esses/> conteúdos são, <hes é/É/éh/> são reguladas, <erro são/> <corr não são/> espalhados, são contidos. Eu acho que criando mais tecnologia para prever isso, uma IA que por exemplo, vê se <hes é/É/éh/> ver se a informação é verdadeira, ver se há, se alguma coisa é um deep fake ou algo do tipo  ou e acho que na parte da responsabilidade, são um pouco da rede social que sempre tem que melhorar a sua parte de segurança de análise para ver se é um bot ou não, e etc, mas eu acho que, principalmente da parte <erro de/> <corr do/> quem produziu o conteúdo também porque produziu um conteúdo falso, obviamente você tá <erro querendo que se />  <corr querendo fazer> uma coisa que não é dentro das partes legais, na minha opinião. Alguém tem algo a comentar sobre a resposta que ele deu? <hes é/É/éh/> , além <erro da/>  <corr de/> quem produziu ser responsabilizado, eu acho que também a rede social, porque quase tudo que a gente entra hoje em dia tem aquele caption, né, que é meio para evitar isso e também algumas redes sociais também fazem, inclusive acho que o tipo o WhatsApp fez isso que limita as mensagens ou quantidade de mensagens que você manda. Então meio que se foi disparado massivamente, então o canal de por onde isso foi espalhado e também tem uma certa culpa de não ter segurança o suficiente para isso. Alguém tem mais algo a comentar? Assim, eu concordo com isso, que também a empresa que administra tem um pouco de culpa, mas também do mesmo jeito que é a empresa vai se melhorando pra é vigiar isso, os bots também vão melhorando, porque muitas vezes criam-se bots orgânicos que se parecem ser perfis de pessoas, etc, que, por exemplo, <erro não são/>, <corr não é/> um bote que manda várias mensagens. São vários bots que vão individualmente mandando mensagens, que assim cria-se <rep várias, várias />, uma compartilhação massiva de fake news. Acho que, obviamente, a rede docial tem também um pouco de parte da da culpa, mas também não dá para se culpar grande parte dela, porque <rep é é é /> algo que <rep é o é o/> gato e rato um vai caçar e sempre o outro vai ter que conseguir escapar. Não <rep só, só /> pra complementar, quando tem notícia assim, falsa, espalhada, principalmente que eu vejo no Twitter e no Instagram. De vez em quando o Instagram mas é mais no Twitter, tem uma tarjazinha que alguém verificado <hes é/É/éh/> uma autoridade sobre o assunto, coloca se é falso ou verdadeiro e a descrição do que porque é falso ou verdadeiro. No Instagram eu vi isso, mas foi mais no período eleitoral, no Twitter, é mais assuntos gerais assim. Alguém tem mais alguma colocação? Nessa parte <erro da do> <corr de/> tarjas e e etc. Assim, no Twitter, <rep eu eu/> sei que é por parte dos próprios usuários, ou seja, não é algo algo que a rede social administra, são <rep os próprios os próprios/> usuários que regulam os próprios usários que muitas vezes os usuários que regulam não estão também certos. Eu já vi, por exemplo, tarjas que são falsas e que a, aí sim, a rede social tem que estar na culpa de ver se é verdadeiro ou não. Alguém tem mais algo a comentar? Não, okay. Nesse último momento, vou passar pra uma pergunta que essa pergunta é geral, é livre e todo mundo pode responder, não é direcionada a ninguém, certo? O uso e desenvolvimento de IAs generativas devem ser fortemente fiscalizados por órgãos governamentais ou elas são apenas mais um tipo de software comum, como milhares de outras existências? Alguém quer responder? <hes é/É/éh/>  eu acho que se o governo tem que meter a mão, eu acho que ele tem que meter a mão, meio que de longe, não incisivamente, porque <erro como/> <corr assim/>, isso também, como eu tava falando, vai atrapalhar a liberdade criativa da IA, e de quem cria essas IA, além de que vai ficar algo muito burocrático e muito ineficiente. Não vai, acho que aflorar muito, se falar de Brasil, especificamente do Brasil, acho que países que tendem a ter uma liberdade maior para os desenvolvedores meio que vai desenvolver mais esse conceito e essa ferramenta IA generativa. Então eu acho que sim, é tipo mais um software como qualquer outro, mas se for para fiscalizar, que seja meio que punitivamente e não fiscalizar de fato a produção e meter a mão na produção e esse tipo de coisa. Alguém tem algo a comentar sobre a resposta que ele deu? É <rep sobre  sobre/> os direitos humanos, né? Eu vou utilizar <rep essa essa/> plataforma para, enfim, como naquela pergunta de <rep algo algo /> racista, sexista ou algo assim não precisa de ser uma coisa estrita, até porque, por exemplo, o Instagram não tem um artigo na Constituição sobre como a gente deve usar o Instagram, existe as diretrizes <rep da própria da própria /> plataforma, sobre como aquele aplicativo deve funcionar, o que é que a gente pode ou não pode fazer? Então eu acho que deveria ser fiscalizado como ele disse, de longe assim no sentido de a ferir direitos humanos, mas também as diretrizes, enfatizar as diretrizes criadas pela própria plataforma como um filtro e regras mesmo de como <erro <rep aquele aquele />> <corr aquela/> plataforma deve ser utilizada, que é até então, nesse primeiro momento como ela é nova, ainda tá muito liberal assim, então a gente tá vendo, tá vendo como as coisas vão acontecendo, que vai ser necessário mesmo ter <erro mais um> <corr algo mais/> regrado não é ditatoriamente, mas de forma, a manter a passividade. Alguém tem mais alguma coisa a comentar? Sobre a pergunta, sobre a resposta que ela deu. Certo, agora a gente vai ter outro momento que é da mesma forma que vocês deram a opinião inicial de vocês no debate agora quero opinião final de vocês. Se vocês acham que tem algo a apresentar acrescentar eu vou passar a palavra, cada um de vocês e aí esse é um momento de dar opinião, final de vocês  depois do debate, começar pelo o debatedor um. Não acho que. É o que eu falei no começo, tem pontos positivos, negativos. A gente debateu vários pontos importantes aqui, <hes é/É/éh/>   essa questão da fiscalização, tem que tomar bastante cuidado, porque às vezes <hes é/É/éh/>  envolve interesse da instituição <rep ou ou/> pessoa que está fiscalizando isso pode acabar <inaudivel/>, mas acho que a gente debateu pontos importantes e não sei mais o que falar, minha opinião permanece a mesma, mas gostei de ouvir a opinião de cada um. <rep Pode Pode/> ser que tenha mudado minha opinião de certa forma, só não sei externar, ainda de que forma. Ok , debatedor 2. Acho que eu compartilho da mesma opinião do um, só que eu ainda <rep acho que acho que /> tem algumas consideração que eu não falei que eu ainda acho que fica meramente nesse trabalho repetitivo mesmo a IA ela nunca vai conseguir ser ou expressar algo que um humano de fato faz, porque por filosofia das coisas e jeito das coisas serem mesmo porque a IA de fato, não tem vontade, nem ela é um ser de fato, ela, basicamente um idiota útil, muito rápido e que consegue mimetizar dados que as pessoas colocam, ela até pode meio que desenvolver um falso afeto ou um falso sentimento em algum futuro, mas isso não vai ser de fato algo humano e real. Então, quanto a substituir os humanos, eu acho que isso nunca vai acontecer. <hes é/É/éh/>   <rep no no/> fato de intelectualizar e de sentimento e esse tipo de coisa, mas manualmente, provavelmente, mas é porque muitas coisas que a gente conversou aqui foge um pouco do escopo só IA e vão para escopo como educação, como moral, como ética e são assuntos de uma forma geral, então não fica só na IA isso,  até em relação ao filtro da IA, que de fato, o sujeito define como verdade ou falso e desse tipo de coisa toda é meio <erro subjetivo /> <corr subjetivista/> demais tudo isso. Acho que é muito importante esse debate, eu acho até que a gente deve levar isso até nós enquanto profissionais, né? Da computação, a gente tem que levar esse assunto mais em pauta para a sociedade, tanto pela importância disso quanto por trazer a verdade, porque as pessoas, elas são muito enganadas por fake news e tal e a gente realmente mostrar o que realmente significa, o que é de verdade, os benefícios que pode trazer e os malefícios. Isto vai trazer muito um melhor uso da da plataforma. Eu acho que o IA é muito importante, mas também a gente não pode endeusar tanto a ponto <rep de de/> achar <rep que que/> vai substituir o humano e que a gente não tem que usar, que isso daí tem que ser fiscalizado pelo governo, que isso não é bom, não é bom, não é bom mas eu também não acho que a gente deva deva   <hes é/É/éh/>  endeusar algo no ponto de <erro subir/>  <hes é/É/éh/>  <corr terceirizar/> todas as nossas responsabilidades, tudo do ser humano numa inteligência artificial, que é como <rep o o/> 2 falou, existem coisas que só nós, humanos, a gente tem capacidade de fazer uma IA ela pode reproduzir um som, mas ela não vai transmitir a emoção daquela voz, os sentimentos, a mensagem que ela quer passar. Então é realmente foi como a roda <rep para para/> os primeiros homens aqui facilitou, ajudou, então, se a gente souber utilizar essa ferramenta, de uma forma útil e de uma forma benéfica para a gente  <hes aa/ahh/ah/> a gente vai ter muitos benefícios e também eu volto a enfatizar, a criação de diretrizes da própria plataforma para evitar que danos maiores eles possam acontecer, como ferir os danos Morais, direitos humanos e todas essas questões que a gente abordou. Debatedor 4 Assim, completamente um pouco do que a 3 disso, eu acho que, principalmente na parte de, pera aí, putz deu um branco aqui mas principalmente essa parte <rep de de/> autoridade e tal, <hes é/É/éh/> assim o, como posso colocar em palavra? Deixa eu pensar. <rep O O/> banco de dados da IA sempre vai pegar algo humano, se você <hes é/É/éh/> ficar só utilizando IA IAI IA, você não vai ter coisas novas para incrementar nesse próprio banco de IA humanas. Então, acho que assim <rep é é/> o que eu falei no começo e acho que mantenho a principal pauta da IA é você está pegando uma uma base de dados autoral e vai mais ou menos reorganizar para criar coisas novas. Então <rep o quão, o quão/> etico é pegar isso e de outra pessoa e reorganizar, acho que isso é o principal pauta da´IA, em relação a principalmente entretenimento, basicamente. Mais alguma coisa? Massam Então é isso, vou finalzar a gravação agora, tudo certo.\n"]}]},{"cell_type":"markdown","source":["# Código que limpa o texto marcado de disfluências e armazena elas em um array"],"metadata":{"id":"SYY6CaVlv64h"}},{"cell_type":"code","source":["def produz_array(text):\n","    tags_pattern = r'<(rep|corr|erro|hes) ([^<>]*)/?>'\n","\n","    disfluencias = []  # Para armazenar todas as disfluências\n","\n","    def replace_tags(match):\n","\n","        tag = match.group(1)\n","        content = match.group(2).strip()\n","\n","        # Remove '/', '/>', '/>>', '//>' do final do conteúdo\n","        content = re.sub(r'[/]+>?$', '', content).strip()\n","\n","        # Adiciona a disfluência à lista\n","        if tag in ['rep', 'hes', 'erro', 'corr']:\n","            disfluencias.append((tag, content))\n","\n","        return content\n","\n","    # Aplicando a substituição de todas as tags no texto\n","    texto_disfluente = re.sub(tags_pattern, replace_tags, text)\n","\n","    return texto_disfluente, disfluencias\n","\n","texto_disfluente, disfluencias = produz_array(marked)\n","\n","print(\"Texto Disfluente:\\n\", texto_disfluente)\n","print(\"\\nDisfluências Encontradas:\\n\", disfluencias)\n"],"metadata":{"id":"0kf-p0jevJuR","executionInfo":{"status":"ok","timestamp":1725287685456,"user_tz":180,"elapsed":28,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c1678864-2729-43b7-f77e-93fb070c28fd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Texto Disfluente:\n"," Vamos lá, é  boa tarde todo mundo. Bem-vindos a este debate. Promovido pelo grupo de pesquisa do lacina debate em educação. Eu me chamo David e gostaria de apresentar aqui, quem está comigo, Klaywert que também faz parte do grupo. Mas aí a gente tem também Bryan e Hellen, que são tirando Hellen, a maioria estudante do mestrado, Hellen é estudante da graduação. é, e esse projeto está sobre orientação do professor Campelo, que é o professor que vocês conhecem que vocês conheceram agorinha. que vocês viram agora certo, okay, a razão pela qual nos reunimos aqui hoje, é é  gerar uma base de dados de voz que posteriormente será transcrita e utilizada para avaliação e treinamento de modelos de inteligência artificial. Nosso foco está entre vários tópicos relacionados a debates, fazendo dessas iniciativa não apenas oportunidade de aprendizado e crescimento mas também uma contribuição valiosa para avanço de IA. \n","Vocês assinaram o termo, né? Todo mundo já assinou o termo, então a gente pode pular essa parte cada um cada debatedor vai receber uma identificação, né? Vocês já receberam ee essa vai ser a identificação de vocês, como os debatedores, aqui a gente não estava interessado nos dados pessoais de vocês, então o processo vai ser identificado dessa forma com esses IDs, é é certo? a gente vai gravar a voz de vocês.\n","Vocês assinaram o termo, né? Todo mundo já assinou o termo, então a gente pode pular essa parte cada um cada debatedor vai receber uma identificação, né? Vocês já receberam ee essa vai ser a identificação de vocês, como os debatedores, aqui a gente não estava interessado nos dados pessoais de vocês, então o processo vai ser identificado dessa forma com esses IDs, é é certo? a gente vai gravar a voz de vocês. Minha identificação número um. Estou contribuindo com a pesquisa no Brasil. Minha identificação número dois, estou contribuindo com a pesquisa no Brasil. Minha identificação número tres, estou contribuindo com a pesquisa no Brasil. Minha identificação número quatro, estou contribuindo com a pesquisa no Brasil. É, explicando as regras do debate. Antes da gente começar o debate é essencial, que todos compreendam e sigam as regras do debate, essas regras foram criadas para garantir um debate justo e ordenado para todos os envolvidos. Primeira regra sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando. Se você deseja contribuir para a discussão, oferecer algum contra argumento, por favor, levante a mão e aguarde o moderador, eu, lhe conceder a palavra, uma vez que tenha sido autorizado a falar, você terá a palavra poderá expressar seus pensamentos e responder aos outros também.\n","Certo, explicando o funcionamento do debate, vamos seguir em formato estruturado de de três momentos distintos, cada um com seu propósito e regras específicas. Momento um expressão inicial  do de  suas opiniões. No primeiro momento, abordaremos a questão principal do debate e objetivo é  que cada um cada, participante expresse sua opinião inicial sobre o tema central. Momento dois, rodada de perguntas. Num segundo momento teremos uma rodada de perguntas direcionada para cada um dos debatedores, abriremos espaço para os outros participantes contra argumentarem ou expressarem suas opiniões sobre a resposta dada após as perguntas direcionadas, teremos uma outra pergunta, que será direcionadas a todos os participante, neste momento, vocês terão a liberdade de escolher se desejam responder, caso que tenha algo relevante a acrescentar. No momento três é colocações finais, um terceiro e ultimo momento, será perguntado se os participantes têm alguma outra colocação final sobre o tema.\n","Certo ? ãã OK, então a gente vai começar agora. Ficou alguma duvida antes de tudo ? deu para entender. Vão ser três momentos o debate, então, vai ser um debate semi estruturado, se alguém quiser falar, tem que pedir a vez, não pode estar interrompendo o outro e é basicamente essas regras que vocês devem seguir e a gente vai ter umas perguntas para nortear o debate também, que eu vou mostrar, vou botar ali na tela e vou ler para vocês também essas perguntas, OK?\n","Certo, como vocês já sabem, o nosso tema é inteligência artificial generativa e seus impactos na sociedade. OK? Para começar, primeiramente, cada um terá um momento inicial para expressar seus principais cada opiniões e pensamentos sobre o tema,  cada cada participante terá um momento para fazer isso, certo? Vamos começar com o debatedor 1, você gostaria de expressar a sua opinião? De forma geral, o que é que você pensa sobre o tema? Bom, as IAs generativas são bem dizer uma faca de dois gumes, né? Tem aspectos positivos e muito negativos também, positivos tem automação automação  de algumas atividades  é/É/éh pode auxiliar como ferramenta complementar em estudos como negativa, tem a questão de proteção de dados, de autenticidade, de resposta, infração de direitos autorais. Então, dependendo da área do argumento que quiser seguir, pode ser positivo ou negativo. Agora o debatedor 2 olha em relação a os impactos positivos que é/É/éh as coisas repetitivas vão ser ao longo do tempo eliminadas alguns trabalhos que precisam de muita repetição e o que meio que vai ficar é/É/éh, acho que produção intelectual intelectualizada que a IA não consegue fazer bem, inclusive os modelos atuais é/É/éh em em  relação a opiniões também e também oo/oh ele não, ele tem um filtro muito grande, então acho que  deve, desde que não infrija nenhuma lei deve ter maior liberdade de criação. Os negativos, eu acho que problemas como o deep fake  e e e  geração de voz também pelo timbre. Eu acho que vai ser um problema muito grande para as autoridades lidar e fazer contra medidas que reconheçam se aquilo é de fato verdade ou não, e meio que impulsiona a desinformação em relação a estudo também, eu acho que tende a, dependendo da base de dados ou a piorar a situação ou a melhorar, então acho que no futuro a especificação das IAs não ser um aí a geral, ser mais nichado é com os vetores de informação, vai vir a melhorar esse problema  de de espalhar mentiras. Debatedora três É embora esse seja um assunto, um conteúdo que já venha sido tratado há muito tempo, várias pessoas já tenham trabalhado nisso é/É/éh ultimamente está tendo um um  uma abordagem maior sobre isso. Acho que até depois do do chat GPT  ter vindo, né? E aí o pessoal ficou sabendo muito. Eu, por exemplo, quando eu não tinha esse conhecimento, eu não sabia da existecia das IAs nesse sentido. Nesse aspecto, depois que eu conheci o chat, eu consegui compreender mais e como os meninos falaram, ele tem aspectos muito positivos, e justamente pela pela automação, pela facilidade, pela agilidade, mas eu acho também que os usos negativos dele pode impactar também na autenticidade do próprio ser humano, como o texto diz, mesmo a criatividade, a humanização  é/É/éh os textos por exemplo, quando a gente vai ver no TikTok e o pessoal está usando aquelas vozes fakes tem são, são a voz que você jura que é uma pessoa real, só que não tem as expressões e eu acho que um um expressão de ironia, de sarcasmo, que o ser humano ele consegue ter, isso é algo do ser humano menos a IA, não consegue obter. Então eu acho que pode ser útil, sim, para facilitar a nossa vida mesmo, mas não com um substituto de coisas que só o ser humano consegue fazer. Debatedor cinco, quatro é/É/éh sobre, as IAs, assim acho que o principal mesmo é em relação ao trabalho que vai ser que não tem como você lutar contra esse crescimento da IAs em relação à substituição de empregos. É algo desde a revolução industrial, até antes que a tecnologia sempre vai substituir o ser humano e algo que é, não, não pode ser parado sobre é/É/éh  regulamentação, é/É/éh  etc. Eu acho que o principal ponto, na minha opinião, é é sobre o uso de banco de dados de com direitos autorais para geração de novas coisas, porque a maioria da das vezes que nesses essas IAs gerativas usam banco de dados de coisas já existentes, como por exemplo, desenhos já vozes e etc, para criar novas coisas. Então acho que a pauta na legalização de IAs vai ser principalmente nessa área de você poder ou não usar o desenho de alguém para gerar novos desenhos, e etc. Certo, vamos iniciar com a rodada de perguntas irei realizar uma pergunta para cada participante que terá seu tempo de resposta e ao final de sua resposta, os demais podem pedir espaço para comentar algo sobre a pergunta feita ou a resposta dada? OK, vamos começar. A primeira pergunta é pro debatedor 1,  é/É/éh  se um sistema de IA generativa cria algo prejudicial ou ofensivo. Por exemplo, uma imagem com conteúdo racista. Quem deve ser responsabilizado? O desenvolvedor da IA, o usuário, a plataforma a plataforma que hospeda ou alguma outra instituição ou pessoa. O autor do texto da plataforma que hospeda, a plataforma e quase sempre o desenvolvedor da Ia, porque querendo ou não, é ele que criou a ferramenta para conseguir filtrar o que ela deve ou não buscar, porque realmente, com o as IAs, elas podem perpetuar preconceitos e estereótipo, porque eles fazem o filtro e podem, nesses textos que elas estão filtrando, acabar inserindo no texto que ela vai enviar para o usuário certas falas que não são adequadas no na sociedade atual. Alguém tem algo a comentar sobre a resposta do debatedor? é/É/éh mais alguém tem alguma outra colocação sobre essa pergunta específica que queira comentar? Pode dizer. Às vezes o banco de dados da  IA, que que traz para a propria IA, às vezes já vem com alguns dados que que podem ser preconceituosos. Seja racistas ou sexistas, e etc. Às vezes isso já vem do próprio banco de dados, que gera novos dados que também são racistas, sexistas, etc. Acho que na minha na minha visão.  Então tu acha que a pessoa culpada seria quem introduziu o dado? Não, eu não acho que a pessoa culpada é/É/éh seria que produziu o dado assim é/É/éh hm/mm, não sei sinceramente eu teria que pensar um pouco mais para saber quem seria punido nessa daí, porque realmente é/É/éh. Dentro das opções ali é eu pense a Pri, a priori, eu pensei no usuário, mas também o desenvolvedor. A plataforma pode inclinar o o dado a sair como como algo racista ou sexista por exemplo eu acho que é, é seria mais ou menos como se fosse a política do Instagram que tem aquele filtro de palavras negativas e ofensivas que você usa em comentários que justamente já pela consciência de que isso pode ocorrer. Tanto o desenvolvedor já cria esse filtro, essas diretrizes de de política, de respeito, de direitos humanos e tal, essas coisas, quanto também do usuário, assim rep<que ele que ele/> escrever já ter, tipo um bloqueio pra pra isso não acontecer. Tanto a consciência do usuário pra estar pesquisando essas coisas quanto do desenvolvedor. Só para fazer um adendo minha resposta falei que pudia punir plataforma que hospeda, mas desde que, por exemplo, vamos supor seja um site de crônicas, ai a pessoa tem autoridade dentro do site. Agora, se for, por exemplo, um reddit, um fórum de discussão, aí eu já acho que não deva responsabilizar a plataforma e sim fazer como a debatedora 3 falou e fazer a questão do filtro antes da mensagem ser enviada. já evita problemas posteriores A culpa maior, seria de usuário, em si, da pessoa?  Sim Pode dizer debatedor 4 Porque também varia muito do conteúdo que está sendo gerado. Por exemplo, um texto é algo um pouco mais direto. Agora, uma imagem, um dado às vezes pode ser um pouco mais indireto, mais sutil, esse preconceito. Eu acho que o principal responsabilidade deve ser o usuário. Eu acho que o desenvolvedor da IA, ele não, assim a gente sabe que o usuário muitas vezes ele é muito criativo em quebrar as coisas. Então, se uma IA é muito generalista, talvez o usuário seja muito criativo em fazer com que esse conteúdo seja produzido. Então eu acho que é meio que foge um pouco do escopo do que o desenvolvedor consegue ou não pensar. Porque assim, desde que a internet é internet, tem gente, só pensando em como quebrar aquela coisa que está disposta ali, então eu acho que o principal problema é o usuário e não o desenvolvedor. É a mesma coisa de ter um carro e usuário do carro meio, que o motorista decidir se ele vai sair batendo em tudo ou vai seguir o fluxo normal, acho que é basicamente isso Até porque o propósito desse dessa IA criada pelo desenvolvedor é auxiliar,  é/É/éh trazendo,  é/É/éh manutenção, facilidade para a pessoa de modo benéfico. Então seria realmente culpa do usuário o mau uso do do da plataforma. Então, por isso que seria necessário, justamente por causa de talvez não fosse necessário. Se o usuário não fizesse isso, mas como a gente sabe que isso já é um histórico muito grande de que as pessoas usam isso para quebrar as regras, então seria necessário já uma umas diretrizes, para evitar que esse problema viesse acontecer. Que a culpa, o pessoal iria culpar a marca também, né? A plataforma em si. Alguém tem mais alguma coisa a comentar? Certo, vamos para a pergunta 2. Para o debatedor 2, IAs generativas podem ser usadas nos processos educacionais, por exemplo, em aulas, atividades ou provas. O ou a aluna devem reportar o professor sobre o uso de IA generativa em suas atividades. São duas perguntas, né não três no caso, a primeira, eu acho que sim. Pode ajudar mais do que atrapalhar, desde que seja usado da forma correta. Inclusive acho que está tendo um movimento na academia. Acho foi que uma professora está falando que estão desenvolvendo papers para que isso seja incentivado e não desincentivado como foi em um primeiro momento, porque é mais pelo uso mesmo do usuário, porque tem gente que só coloca lá e pede para ele. Já vim na resposta direta, mas se você, por exemplo, às vezes eu até uso isso, você coloca a sua resposta. Pra Ele incrementar algo, ou então  é/É/éh fazer com que ele mude a forma como aquilo tá sendo visto e na maioria das vezes funciona, então  é/É/éh isso, agrega conhecimento. Se for uma coisa que parta de você, mas se você só manda ele fazer e meio que você só copia e cola, isso não tem conhecimento nenhum sendo gerado. Então acho que pode sim responder a segunda pergunta também em aulas, atividades e provas, fica até mais dinâmica, eu acho não fica algo muito engessado, como normalmente o ensino tradicional é, e eu acho que deve reportar, sim, também para o professor ter ciência de que aquilo está sendo usado e como isso foi usado, inclusive se você perguntar, pegar uma resposta pronta da inteligência artificial e devolver para ele perguntar se ela foi que ela fez isso, se eu me engano, ela diz que foi ela, então acho que sim. Alguém tem algum comentário sobre a resposta do debatedor 2? Só um ponto bem assim, simples no negócio específico que ele falou, ele falou que se você colocar uma resposta que a IA gerou, ela responde que foi ela que fez, mas assim isso é algo também que ainda está um pouco um pouco em desenvolvimento, porque existe, por exemplo, certas respostas criadas por humanos que se colocar, por exemplo, no chat GPT. Ele disse que foi ele que fez, então ainda é uma coisa um pouco falha, que eu acho que tem que se melhorar. Tem algo a comentar sobre a resposta dele? Não, eu acho que é isso mesmo, até porque está tudo meio que começando, ainda está dando os primeiros passos, então, normal ter falhas e imprecisões. Também acho que ela pode ser utilizada, estava vendo no fórum da do IF de Santa Catarina, o professor de lá falou que podia ser usado na discussão do assunto, porque às vezes você joga lá uma pergunta e ele pode responder uma coisa que não tem sentido com a realidade. Ele quando vai filtrar lá ele pode acabar, criando uma teoria, entre aspas, que não existe. Ele falou que a pessoa fala assim, é mais interessante você focar na pergunta da qualidade, na qualidade da pergunta  que você vai fazer para IA do que a resposta em si que ela vai dar, que ajuda a ampliar a discussão dentro do diálogo dentro da sala. Infelizmente a gente sabe que no mundo atual, a maioria das pessoas usam só para obter uma resposta pronta, mas se fosse usado, se a gente tivesse no mundo ideal, ajudaria muito nos processos de estudo. Ajudaria nos processos de estudo porque como ele é, como a IA  é/É/éh  junta, agrupa vários complementos, vários conteúdos, seria uma fonte muito rica de informação, de conteúdo, de exercício e tudo mais que fosse complementar. Então, para ser aplicado nas escolas, eu acho que seria muito bom os professores, por exemplo, criarem diretrizes também de da forma como eles deveriam deveriam usar também com penalidades, se fosse criar resposta pronta, porque é muito, muito bom, é algo realmente uma uma, a gente tem a faca e o queijo que pode muito bem facilitar e ajudar no nosso processo acadêmico, como também pode prejudicar, porque um aluno que só pega resposta pronta do do chat GPT, ele pode tirar nota muito boa, mas ele não vai ser um bom aluno, bom profissional, porque ele só tá é/É/éh copiando aquilo que não foi ele que fez e o ensino, Ele não é baseado nisso. Então se se a gente souber realmente usar da forma correta, o, a IA, ela é muito, muito promissora na educação. Alguém tem mais algo a comentar? Vamos para a terceira pergunta para o para a debatedora 3, de que maneira a propriedade intelectual deve ser tratada quando o conteúdo é gerado por IA, por exemplo, se um usuário gerou uma música usando IA o crédito pela criação deve ser deste usuário ,da plataforma de IA utilizada ou do criador dos dados originais com os quais a IA foi treinada? é/É/éh no caso é/É/éh  a IA aplicada da mesma forma que um agrupamento de de conteúdo com musica, por exemplo? Entendi, eu não sei, eu não tenho opinião formada sobre isso porque imagem, a pessoa só colocou, só, escreveu o texto. E ela gerou lá. Um agrupamento de várias coisas, mas a criatividade ela é a junção de várias ideias juntas. Então não tem nada de novo e extraordinário. É tudo coisas que já foram criadas, então se é a pessoa, criou uma música usando o IA. Eu acho que o crédito pode ser dela mas não totalmente, não tenho uma opinião formada sobre isso. Alguém tem algo a comentar sobre a resposta dela?  é/É/éh  sobre a parte do do criador dos dados originais com o qual a IA foi treinada. Eu acho que assim.  é/É/éh  varia muito.  é/É/éh  assim. É a principal questão, na minha opinião, porque se você  é/É/éh  for ver os dados que foi treinado a IA, muitas vezes você pega, tenta pegar o, puts pera aí, tenta gerar alguma coisa com a IA e a maioria das vezes é só os dados originais, só que embaralhados. Então assim, é grande parte dos dados originais que é criado essas essas novas coisas. Então. Então você acha que é o direito autoral é do dado original? Se for, se o banco de dados foi foi, por exemplo, só de um autor, eu acho que sim. É que nem o cover a gente o cover de uma música, ela tem uma forma diferente, pode até usar, você usa as mesmas notas e tals, usar instrumento diferente, tem um estilo diferente. Só que a música original é do do cantor que do do cantor, do compositor que escreveu aquela música. Acho que tem a mesma o mesmo significado. Alguém tem algo a comentar sobre a resposta, sobre a pergunta? Tá, vamos para a pergunta 4, então, para o debatedor 4. Como garantir que conteúdos gerados por IA não sejam usados para espalhar informações tendenciosas, errêneas ou maliciosos, por exemplo, quando este tipo de informação é propagada maximamente por bots em uma rede social, a responsabilidade deve ser da empresa que administra a Rede Social, dos programadores da IA ou de quem produziu aquele conteúdo usando a IA.  Tá, vamos lá. é/É/éh acho que a primeira parte é como garantir que esses esses conteúdos são, é/É/éh são reguladas, são não são espalhados, são contidos. Eu acho que criando mais tecnologia para prever isso, uma IA que por exemplo, vê se é/É/éh ver se a informação é verdadeira, ver se há, se alguma coisa é um deep fake ou algo do tipo  ou e acho que na parte da responsabilidade, são um pouco da rede social que sempre tem que melhorar a sua parte de segurança de análise para ver se é um bot ou não, e etc, mas eu acho que, principalmente da parte de do quem produziu o conteúdo também porque produziu um conteúdo falso, obviamente você tá querendo que se  querendo fazer uma coisa que não é dentro das partes legais, na minha opinião. Alguém tem algo a comentar sobre a resposta que ele deu? é/É/éh , além da  de quem produziu ser responsabilizado, eu acho que também a rede social, porque quase tudo que a gente entra hoje em dia tem aquele caption, né, que é meio para evitar isso e também algumas redes sociais também fazem, inclusive acho que o tipo o WhatsApp fez isso que limita as mensagens ou quantidade de mensagens que você manda. Então meio que se foi disparado massivamente, então o canal de por onde isso foi espalhado e também tem uma certa culpa de não ter segurança o suficiente para isso. Alguém tem mais algo a comentar? Assim, eu concordo com isso, que também a empresa que administra tem um pouco de culpa, mas também do mesmo jeito que é a empresa vai se melhorando pra é vigiar isso, os bots também vão melhorando, porque muitas vezes criam-se bots orgânicos que se parecem ser perfis de pessoas, etc, que, por exemplo, não são, não é um bote que manda várias mensagens. São vários bots que vão individualmente mandando mensagens, que assim cria-se várias, várias, uma compartilhação massiva de fake news. Acho que, obviamente, a rede docial tem também um pouco de parte da da culpa, mas também não dá para se culpar grande parte dela, porque é é é algo que é o é o gato e rato um vai caçar e sempre o outro vai ter que conseguir escapar. Não só, só pra complementar, quando tem notícia assim, falsa, espalhada, principalmente que eu vejo no Twitter e no Instagram. De vez em quando o Instagram mas é mais no Twitter, tem uma tarjazinha que alguém verificado é/É/éh uma autoridade sobre o assunto, coloca se é falso ou verdadeiro e a descrição do que porque é falso ou verdadeiro. No Instagram eu vi isso, mas foi mais no período eleitoral, no Twitter, é mais assuntos gerais assim. Alguém tem mais alguma colocação? Nessa parte da do de tarjas e e etc. Assim, no Twitter, eu eu sei que é por parte dos próprios usuários, ou seja, não é algo algo que a rede social administra, são os próprios os próprios usuários que regulam os próprios usários que muitas vezes os usuários que regulam não estão também certos. Eu já vi, por exemplo, tarjas que são falsas e que a, aí sim, a rede social tem que estar na culpa de ver se é verdadeiro ou não. Alguém tem mais algo a comentar? Não, okay. Nesse último momento, vou passar pra uma pergunta que essa pergunta é geral, é livre e todo mundo pode responder, não é direcionada a ninguém, certo? O uso e desenvolvimento de IAs generativas devem ser fortemente fiscalizados por órgãos governamentais ou elas são apenas mais um tipo de software comum, como milhares de outras existências? Alguém quer responder? é/É/éh  eu acho que se o governo tem que meter a mão, eu acho que ele tem que meter a mão, meio que de longe, não incisivamente, porque como assim, isso também, como eu tava falando, vai atrapalhar a liberdade criativa da IA, e de quem cria essas IA, além de que vai ficar algo muito burocrático e muito ineficiente. Não vai, acho que aflorar muito, se falar de Brasil, especificamente do Brasil, acho que países que tendem a ter uma liberdade maior para os desenvolvedores meio que vai desenvolver mais esse conceito e essa ferramenta IA generativa. Então eu acho que sim, é tipo mais um software como qualquer outro, mas se for para fiscalizar, que seja meio que punitivamente e não fiscalizar de fato a produção e meter a mão na produção e esse tipo de coisa. Alguém tem algo a comentar sobre a resposta que ele deu? É sobre  sobre os direitos humanos, né? Eu vou utilizar essa essa plataforma para, enfim, como naquela pergunta de algo algo racista, sexista ou algo assim não precisa de ser uma coisa estrita, até porque, por exemplo, o Instagram não tem um artigo na Constituição sobre como a gente deve usar o Instagram, existe as diretrizes da própria da própria plataforma, sobre como aquele aplicativo deve funcionar, o que é que a gente pode ou não pode fazer? Então eu acho que deveria ser fiscalizado como ele disse, de longe assim no sentido de a ferir direitos humanos, mas também as diretrizes, enfatizar as diretrizes criadas pela própria plataforma como um filtro e regras mesmo de como <erro aquele aquele> aquela plataforma deve ser utilizada, que é até então, nesse primeiro momento como ela é nova, ainda tá muito liberal assim, então a gente tá vendo, tá vendo como as coisas vão acontecendo, que vai ser necessário mesmo ter mais um algo mais regrado não é ditatoriamente, mas de forma, a manter a passividade. Alguém tem mais alguma coisa a comentar? Sobre a pergunta, sobre a resposta que ela deu. Certo, agora a gente vai ter outro momento que é da mesma forma que vocês deram a opinião inicial de vocês no debate agora quero opinião final de vocês. Se vocês acham que tem algo a apresentar acrescentar eu vou passar a palavra, cada um de vocês e aí esse é um momento de dar opinião, final de vocês  depois do debate, começar pelo o debatedor um. Não acho que. É o que eu falei no começo, tem pontos positivos, negativos. A gente debateu vários pontos importantes aqui, é/É/éh   essa questão da fiscalização, tem que tomar bastante cuidado, porque às vezes é/É/éh  envolve interesse da instituição ou ou pessoa que está fiscalizando isso pode acabar <inaudivel/>, mas acho que a gente debateu pontos importantes e não sei mais o que falar, minha opinião permanece a mesma, mas gostei de ouvir a opinião de cada um. Pode Pode ser que tenha mudado minha opinião de certa forma, só não sei externar, ainda de que forma. Ok , debatedor 2. Acho que eu compartilho da mesma opinião do um, só que eu ainda acho que acho que tem algumas consideração que eu não falei que eu ainda acho que fica meramente nesse trabalho repetitivo mesmo a IA ela nunca vai conseguir ser ou expressar algo que um humano de fato faz, porque por filosofia das coisas e jeito das coisas serem mesmo porque a IA de fato, não tem vontade, nem ela é um ser de fato, ela, basicamente um idiota útil, muito rápido e que consegue mimetizar dados que as pessoas colocam, ela até pode meio que desenvolver um falso afeto ou um falso sentimento em algum futuro, mas isso não vai ser de fato algo humano e real. Então, quanto a substituir os humanos, eu acho que isso nunca vai acontecer. é/É/éh   no no fato de intelectualizar e de sentimento e esse tipo de coisa, mas manualmente, provavelmente, mas é porque muitas coisas que a gente conversou aqui foge um pouco do escopo só IA e vão para escopo como educação, como moral, como ética e são assuntos de uma forma geral, então não fica só na IA isso,  até em relação ao filtro da IA, que de fato, o sujeito define como verdade ou falso e desse tipo de coisa toda é meio subjetivo subjetivista demais tudo isso. Acho que é muito importante esse debate, eu acho até que a gente deve levar isso até nós enquanto profissionais, né? Da computação, a gente tem que levar esse assunto mais em pauta para a sociedade, tanto pela importância disso quanto por trazer a verdade, porque as pessoas, elas são muito enganadas por fake news e tal e a gente realmente mostrar o que realmente significa, o que é de verdade, os benefícios que pode trazer e os malefícios. Isto vai trazer muito um melhor uso da da plataforma. Eu acho que o IA é muito importante, mas também a gente não pode endeusar tanto a ponto de de achar que que vai substituir o humano e que a gente não tem que usar, que isso daí tem que ser fiscalizado pelo governo, que isso não é bom, não é bom, não é bom mas eu também não acho que a gente deva deva   é/É/éh  endeusar algo no ponto de subir  é/É/éh  terceirizar todas as nossas responsabilidades, tudo do ser humano numa inteligência artificial, que é como o o 2 falou, existem coisas que só nós, humanos, a gente tem capacidade de fazer uma IA ela pode reproduzir um som, mas ela não vai transmitir a emoção daquela voz, os sentimentos, a mensagem que ela quer passar. Então é realmente foi como a roda para para os primeiros homens aqui facilitou, ajudou, então, se a gente souber utilizar essa ferramenta, de uma forma útil e de uma forma benéfica para a gente  aa/ahh/ah a gente vai ter muitos benefícios e também eu volto a enfatizar, a criação de diretrizes da própria plataforma para evitar que danos maiores eles possam acontecer, como ferir os danos Morais, direitos humanos e todas essas questões que a gente abordou. Debatedor 4 Assim, completamente um pouco do que a 3 disso, eu acho que, principalmente na parte de, pera aí, putz deu um branco aqui mas principalmente essa parte de de autoridade e tal, é/É/éh assim o, como posso colocar em palavra? Deixa eu pensar. O O banco de dados da IA sempre vai pegar algo humano, se você é/É/éh ficar só utilizando IA IAI IA, você não vai ter coisas novas para incrementar nesse próprio banco de IA humanas. Então, acho que assim é é o que eu falei no começo e acho que mantenho a principal pauta da IA é você está pegando uma uma base de dados autoral e vai mais ou menos reorganizar para criar coisas novas. Então o quão, o quão etico é pegar isso e de outra pessoa e reorganizar, acho que isso é o principal pauta da´IA, em relação a principalmente entretenimento, basicamente. Mais alguma coisa? Massam Então é isso, vou finalzar a gravação agora, tudo certo.\n","\n","Disfluências Encontradas:\n"," [('hes', 'é'), ('hes', 'é'), ('erro', 'que vocês conhecem'), ('corr', 'que vocês conheceram'), ('rep', 'é é'), ('erro', 'cada um'), ('corr', 'cada'), ('hes', 'ee'), ('hes', 'é é'), ('erro', 'cada um'), ('corr', 'cada'), ('hes', 'ee'), ('hes', 'é é'), ('erro', 'do'), ('corr', 'de'), ('erro', 'cada um'), ('corr', 'cada'), ('hes', 'ãã'), ('erro', 'seus principais'), ('corr', 'cada'), ('rep', 'cada cada'), ('rep', 'automação automação'), ('hes', 'é/É/éh'), ('hes', 'é/É/éh'), ('hes', 'é/É/éh'), ('hes', 'é/É/éh'), ('rep', 'em em'), ('hes', 'oo/oh'), ('erro', 'ele não'), ('corr', 'ele tem'), ('erro', 'deve'), ('corr', 'desde'), ('rep', 'e e e'), ('rep', 'de de'), ('hes', 'é/É/éh'), ('rep', 'um um'), ('rep', 'do do'), ('hes', 'é/É/éh'), ('erro', 'tem são'), ('corr', 'são'), ('rep', 'um um'), ('erro', 'cinco'), ('corr', 'quatro'), ('hes', 'é/É/éh'), ('erro', 'que vai ser'), ('corr', 'que não tem'), ('rep', 'não, não'), ('hes', 'é/É/éh'), ('hes', 'é/É/éh'), ('rep', 'é é'), ('erro', 'de'), ('corr', 'com'), ('erro', 'da'), ('corr', 'das'), ('hes', 'é/É/éh'), ('rep', 'a plataforma a plataforma'), ('erro', 'no'), ('corr', 'na'), ('hes', 'é/É/éh'), ('rep', 'que que'), ('rep', 'que que'), ('rep', 'na minha na minha'), ('hes', 'é/É/éh'), ('hes', 'é/É/éh'), ('hes', 'hm/mm'), ('hes', 'é/É/éh'), ('rep', 'o o'), ('rep', 'é, é'), ('rep', 'de de'), ('hes', 'é/É/éh'), ('hes', 'é/É/éh'), ('rep', 'do do'), ('erro', 'uma'), ('corr', 'umas'), ('hes', 'é/É/éh'), ('hes', 'é/É/éh'), ('rep', 'um pouco um pouco'), ('erro', 'da'), ('corr', 'do'), ('erro', 'na pergunta da qualidade'), ('corr', 'na qualidade da pergunta'), ('hes', 'é/É/éh'), ('erro', 'de'), ('corr', 'da'), ('rep', 'deveriam deveriam'), ('rep', 'uma uma'), ('rep', 'do do'), ('hes', 'é/É/éh'), ('rep', 'se se'), ('erro', 'o'), ('corr', 'a'), ('hes', 'é/É/éh'), ('hes', 'é/É/éh'), ('rep', 'de de'), ('hes', 'é/É/éh'), ('rep', 'do do'), ('hes', 'é/É/éh'), ('hes', 'é/É/éh'), ('hes', 'é/É/éh'), ('rep', 'essas essas'), ('rep', 'foi foi'), ('erro', 'a gente'), ('corr', 'o cover'), ('rep', 'do do'), ('rep', 'do do'), ('erro', 'a mesma'), ('corr', 'o mesmo'), ('hes', 'é/É/éh'), ('rep', 'esses esses'), ('hes', 'é/É/éh'), ('erro', 'são'), ('corr', 'não são'), ('hes', 'é/É/éh'), ('erro', 'de'), ('corr', 'do'), ('erro', 'querendo que se'), ('corr', 'querendo fazer'), ('hes', 'é/É/éh'), ('erro', 'da'), ('corr', 'de'), ('erro', 'não são'), ('corr', 'não é'), ('rep', 'várias, várias'), ('rep', 'é é é'), ('rep', 'é o é o'), ('rep', 'só, só'), ('hes', 'é/É/éh'), ('erro', 'da do'), ('corr', 'de'), ('rep', 'eu eu'), ('rep', 'os próprios os próprios'), ('hes', 'é/É/éh'), ('erro', 'como'), ('corr', 'assim'), ('rep', 'sobre  sobre'), ('rep', 'essa essa'), ('rep', 'algo algo'), ('rep', 'da própria da própria'), ('rep', 'aquele aquele'), ('corr', 'aquela'), ('erro', 'mais um'), ('corr', 'algo mais'), ('hes', 'é/É/éh'), ('hes', 'é/É/éh'), ('rep', 'ou ou'), ('rep', 'Pode Pode'), ('rep', 'acho que acho que'), ('hes', 'é/É/éh'), ('rep', 'no no'), ('erro', 'subjetivo'), ('corr', 'subjetivista'), ('rep', 'de de'), ('rep', 'que que'), ('hes', 'é/É/éh'), ('erro', 'subir'), ('hes', 'é/É/éh'), ('corr', 'terceirizar'), ('rep', 'o o'), ('rep', 'para para'), ('hes', 'aa/ahh/ah'), ('rep', 'de de'), ('hes', 'é/É/éh'), ('rep', 'O O'), ('hes', 'é/É/éh'), ('rep', 'é é'), ('rep', 'o quão, o quão')]\n"]}]},{"cell_type":"markdown","source":["# Faz uma limpeza para que o texto corrigido humanamente sem anotações de disfluência fique 100% livre de ruídos"],"metadata":{"id":"6CoLDMkY4Ew2"}},{"cell_type":"code","source":["\n","\n","def limpar_texto(texto):\n","    # Remover todas as tags <hes .../> e <erro .../> junto com seus conteúdos\n","    texto = re.sub(r'<hes.*?/>', '', texto)\n","    texto = re.sub(r'<erro.*?/>', '', texto)\n","\n","    # Manter o conteúdo dentro de <corr .../> e remover a tag\n","    texto = re.sub(r'<corr (.*?)\\/>', r'\\1', texto)\n","\n","    def remove_repeticoes(match):\n","        # Captura o conteúdo da tag <rep> e converte para minúsculas\n","        conteudo = match.group(1).strip().lower()\n","        # Divide o conteúdo em uma lista de palavras\n","\n","        # Remove pontuação do conteúdo\n","        conteudo = re.sub(r'[^\\w\\s]', '', conteudo)\n","        palavras = conteudo.split()\n","\n","        # String para armazenar as palavras únicas\n","        ocorrencia_unica = \"\"\n","        # Set para armazenar palavras únicas\n","        palavras_armazenadas = set()\n","\n","        # Percorre cada palavra do conteúdo original\n","        for palavra in palavras:\n","            # Adiciona a palavra se ela ainda não estiver em palavras_armazenadas\n","            if palavra not in palavras_armazenadas:\n","                palavras_armazenadas.add(palavra)\n","                ocorrencia_unica += palavra + \" \"\n","\n","        # Remove o espaço extra no final e retorna o resultado\n","        return ocorrencia_unica.strip()\n","\n","\n","    texto = re.sub(r'<rep (.*?)\\/>', remove_repeticoes, texto)\n","\n","    # Remover espaços extras gerados após as substituições\n","    texto = re.sub(r'\\s+', ' ', texto).strip()\n","\n","    return texto\n","\n","texto_limpo = limpar_texto(marked)\n","print(texto_limpo)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NQiXJVEBb0Ad","executionInfo":{"status":"ok","timestamp":1725287685456,"user_tz":180,"elapsed":17,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"outputId":"0727a6f4-216b-4223-82c8-a4c7c6b3bdbd"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Vamos lá, boa tarde todo mundo. Bem-vindos a este debate. Promovido pelo grupo de pesquisa do lacina debate em educação. Eu me chamo David e gostaria de apresentar aqui, quem está comigo, Klaywert que também faz parte do grupo. Mas aí a gente tem também Bryan e Hellen, que são tirando Hellen, a maioria estudante do mestrado, Hellen é estudante da graduação. , e esse projeto está sobre orientação do professor Campelo, que é o professor que vocês conheceram> agorinha. que vocês viram agora certo, okay, a razão pela qual nos reunimos aqui hoje, <rep é é gerar uma base de dados de voz que posteriormente será transcrita e utilizada para avaliação e treinamento de modelos de inteligência artificial. Nosso foco está entre vários tópicos relacionados a debates, fazendo dessas iniciativa não apenas oportunidade de aprendizado e crescimento mas também uma contribuição valiosa para avanço de IA. Vocês assinaram o termo, né? Todo mundo já assinou o termo, então a gente pode pular essa parte cada debatedor vai receber uma identificação, né? Vocês já receberam essa vai ser a identificação de vocês, como os debatedores, aqui a gente não estava interessado nos dados pessoais de vocês, então o processo vai ser identificado dessa forma com esses IDs, certo? a gente vai gravar a voz de vocês. Vocês assinaram o termo, né? Todo mundo já assinou o termo, então a gente pode pular essa parte cada debatedor vai receber uma identificação, né? Vocês já receberam essa vai ser a identificação de vocês, como os debatedores, aqui a gente não estava interessado nos dados pessoais de vocês, então o processo vai ser identificado dessa forma com esses IDs, certo? a gente vai gravar a voz de vocês. Minha identificação número um. Estou contribuindo com a pesquisa no Brasil. Minha identificação número dois, estou contribuindo com a pesquisa no Brasil. Minha identificação número tres, estou contribuindo com a pesquisa no Brasil. Minha identificação número quatro, estou contribuindo com a pesquisa no Brasil. É, explicando as regras do debate. Antes da gente começar o debate é essencial, que todos compreendam e sigam as regras do debate, essas regras foram criadas para garantir um debate justo e ordenado para todos os envolvidos. Primeira regra sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando. Se você deseja contribuir para a discussão, oferecer algum contra argumento, por favor, levante a mão e aguarde o moderador, eu, lhe conceder a palavra, uma vez que tenha sido autorizado a falar, você terá a palavra poderá expressar seus pensamentos e responder aos outros também. Certo, explicando o funcionamento do debate, vamos seguir em formato estruturado de de três momentos distintos, cada um com seu propósito e regras específicas. Momento um expressão inicial de suas opiniões. No primeiro momento, abordaremos a questão principal do debate e objetivo é que cada , participante expresse sua opinião inicial sobre o tema central. Momento dois, rodada de perguntas. Num segundo momento teremos uma rodada de perguntas direcionada para cada um dos debatedores, abriremos espaço para os outros participantes contra argumentarem ou expressarem suas opiniões sobre a resposta dada após as perguntas direcionadas, teremos uma outra pergunta, que será direcionadas a todos os participante, neste momento, vocês terão a liberdade de escolher se desejam responder, caso que tenha algo relevante a acrescentar. No momento três é colocações finais, um terceiro e ultimo momento, será perguntado se os participantes têm alguma outra colocação final sobre o tema. Certo ? <hes ãã> OK, então a gente vai começar agora. Ficou alguma duvida antes de tudo ? deu para entender. Vão ser três momentos o debate, então, vai ser um debate semi estruturado, se alguém quiser falar, tem que pedir a vez, não pode estar interrompendo o outro e é basicamente essas regras que vocês devem seguir e a gente vai ter umas perguntas para nortear o debate também, que eu vou mostrar, vou botar ali na tela e vou ler para vocês também essas perguntas, OK? Certo, como vocês já sabem, o nosso tema é inteligência artificial generativa e seus impactos na sociedade. OK? Para começar, primeiramente, cada um terá um momento inicial para expressar cada opiniões e pensamentos sobre o tema, cada participante terá um momento para fazer isso, certo? Vamos começar com o debatedor 1, você gostaria de expressar a sua opinião? De forma geral, o que é que você pensa sobre o tema? Bom, as IAs generativas são bem dizer uma faca de dois gumes, né? Tem aspectos positivos e muito negativos também, positivos tem automação de algumas atividades pode auxiliar como ferramenta complementar em estudos como negativa, tem a questão de proteção de dados, de autenticidade, de resposta, infração de direitos autorais. Então, dependendo da área do argumento que quiser seguir, pode ser positivo ou negativo. Agora o debatedor 2 olha em relação a os impactos positivos que as coisas repetitivas vão ser ao longo do tempo eliminadas alguns trabalhos que precisam de muita repetição e o que meio que vai ficar , acho que produção intelectual intelectualizada que a IA não consegue fazer bem, inclusive os modelos atuais em relação a opiniões também e também , ele tem um filtro muito grande, então acho que , desde que não infrija nenhuma lei deve ter maior liberdade de criação. Os negativos, eu acho que problemas como o deep fake e geração de voz também pelo timbre. Eu acho que vai ser um problema muito grande para as autoridades lidar e fazer contra medidas que reconheçam se aquilo é de fato verdade ou não, e meio que impulsiona a desinformação em relação a estudo também, eu acho que tende a, dependendo da base de dados ou a piorar a situação ou a melhorar, então acho que no futuro a especificação das IAs não ser um aí a geral, ser mais nichado é com os vetores de informação, vai vir a melhorar esse problema de espalhar mentiras. Debatedora três É embora esse seja um assunto, um conteúdo que já venha sido tratado há muito tempo, várias pessoas já tenham trabalhado nisso ultimamente está tendo um uma abordagem maior sobre isso. Acho que até depois do chat GPT ter vindo, né? E aí o pessoal ficou sabendo muito. Eu, por exemplo, quando eu não tinha esse conhecimento, eu não sabia da existecia das IAs nesse sentido. Nesse aspecto, depois que eu conheci o chat, eu consegui compreender mais e como os meninos falaram, ele tem aspectos muito positivos, e justamente pela pela automação, pela facilidade, pela agilidade, mas eu acho também que os usos negativos dele pode impactar também na autenticidade do próprio ser humano, como o texto diz, mesmo a criatividade, a humanização os textos por exemplo, quando a gente vai ver no TikTok e o pessoal está usando aquelas vozes fakes , são a voz que você jura que é uma pessoa real, só que não tem as expressões e eu acho que um expressão de ironia, de sarcasmo, que o ser humano ele consegue ter, isso é algo do ser humano menos a IA, não consegue obter. Então eu acho que pode ser útil, sim, para facilitar a nossa vida mesmo, mas não com um substituto de coisas que só o ser humano consegue fazer. Debatedor , quatro sobre, as IAs, assim acho que o principal mesmo é em relação ao trabalho que não tem como você lutar contra esse crescimento da IAs em relação à substituição de empregos. É algo desde a revolução industrial, até antes que a tecnologia sempre vai substituir o ser humano e algo que é, não pode ser parado sobre regulamentação, etc. Eu acho que o principal ponto, na minha opinião, é sobre o uso de banco dados com direitos autorais para geração novas coisas porque a maioria das vezes que nesses essas ias gerativas usam já existentes como por exemplo desenhos vozes e etc criar então acho pauta na legalização vai ser principalmente nessa área você poder ou não usar desenho alguém gerar novos certo vamos iniciar rodada perguntas irei realizar uma pergunta cada participante terá seu tempo resposta ao final sua os demais podem pedir espaço comentar algo feita dada ok começar primeira pro debatedor 1 se um sistema ia generativa cria prejudicial ofensivo imagem conteúdo racista quem deve responsabilizado desenvolvedor da usuário rep plataforma que hospeda ou alguma outra instituição ou pessoa. O autor do texto da plataforma que hospeda, a plataforma e quase sempre o desenvolvedor da Ia, porque querendo ou não, é ele que criou a ferramenta para conseguir filtrar o que ela deve ou não buscar, porque realmente, com o as IAs, elas podem perpetuar preconceitos e estereótipo, porque eles fazem o filtro e podem, nesses textos que elas estão filtrando, acabar inserindo no texto que ela vai enviar para o usuário certas falas que não são adequadas na sociedade atual. Alguém tem algo a comentar sobre a resposta do debatedor? mais alguém tem alguma outra colocação sobre essa pergunta específica que queira comentar? Pode dizer. Às vezes o banco de dados da IA, que traz para a propria IA, às vezes já vem com alguns dados que podem ser preconceituosos. Seja racistas ou sexistas, e etc. Às vezes isso já vem do próprio banco de dados, que gera novos dados que também são racistas, sexistas, etc. Acho que na minha visão. Então tu acha que a pessoa culpada seria quem introduziu o dado? Não, eu não acho que a pessoa culpada seria que produziu o dado assim , não sei sinceramente eu teria que pensar um pouco mais para saber quem seria punido nessa daí, porque realmente . Dentro das opções ali é eu pense a Pri, a priori, eu pensei no usuário, mas também o desenvolvedor. A plataforma pode inclinar o dado a sair como como algo racista ou sexista por exemplo eu acho que é seria mais ou menos como se fosse a política do Instagram que tem aquele filtro de palavras negativas e ofensivas que você usa em comentários que justamente já pela consciência de que isso pode ocorrer. Tanto o desenvolvedor já cria esse filtro, essas diretrizes de política, de respeito, de direitos humanos e tal, essas coisas, quanto também do usuário, assim rep<que ele que ele/> escrever já ter, tipo um bloqueio pra pra isso não acontecer. Tanto a consciência do usuário pra estar pesquisando essas coisas quanto do desenvolvedor. Só para fazer um adendo minha resposta falei que pudia punir plataforma que hospeda, mas desde que, por exemplo, vamos supor seja um site de crônicas, ai a pessoa tem autoridade dentro do site. Agora, se for, por exemplo, um reddit, um fórum de discussão, aí eu já acho que não deva responsabilizar a plataforma e sim fazer como a debatedora 3 falou e fazer a questão do filtro antes da mensagem ser enviada. já evita problemas posteriores A culpa maior, seria de usuário, em si, da pessoa? Sim Pode dizer debatedor 4 Porque também varia muito do conteúdo que está sendo gerado. Por exemplo, um texto é algo um pouco mais direto. Agora, uma imagem, um dado às vezes pode ser um pouco mais indireto, mais sutil, esse preconceito. Eu acho que o principal responsabilidade deve ser o usuário. Eu acho que o desenvolvedor da IA, ele não, assim a gente sabe que o usuário muitas vezes ele é muito criativo em quebrar as coisas. Então, se uma IA é muito generalista, talvez o usuário seja muito criativo em fazer com que esse conteúdo seja produzido. Então eu acho que é meio que foge um pouco do escopo do que o desenvolvedor consegue ou não pensar. Porque assim, desde que a internet é internet, tem gente, só pensando em como quebrar aquela coisa que está disposta ali, então eu acho que o principal problema é o usuário e não o desenvolvedor. É a mesma coisa de ter um carro e usuário do carro meio, que o motorista decidir se ele vai sair batendo em tudo ou vai seguir o fluxo normal, acho que é basicamente isso Até porque o propósito desse dessa IA criada pelo desenvolvedor é auxiliar, trazendo, manutenção, facilidade para a pessoa de modo benéfico. Então seria realmente culpa do usuário o mau uso do da plataforma. Então, por isso que seria necessário, justamente por causa de talvez não fosse necessário. Se o usuário não fizesse isso, mas como a gente sabe que isso já é um histórico muito grande de que as pessoas usam isso para quebrar as regras, então seria necessário já umas diretrizes, para evitar que esse problema viesse acontecer. Que a culpa, o pessoal iria culpar a marca também, né? A plataforma em si. Alguém tem mais alguma coisa a comentar? Certo, vamos para a pergunta 2. Para o debatedor 2, IAs generativas podem ser usadas nos processos educacionais, por exemplo, em aulas, atividades ou provas. O ou a aluna devem reportar o professor sobre o uso de IA generativa em suas atividades. São duas perguntas, né não três no caso, a primeira, eu acho que sim. Pode ajudar mais do que atrapalhar, desde que seja usado da forma correta. Inclusive acho que está tendo um movimento na academia. Acho foi que uma professora está falando que estão desenvolvendo papers para que isso seja incentivado e não desincentivado como foi em um primeiro momento, porque é mais pelo uso mesmo do usuário, porque tem gente que só coloca lá e pede para ele. Já vim na resposta direta, mas se você, por exemplo, às vezes eu até uso isso, você coloca a sua resposta. Pra Ele incrementar algo, ou então fazer com que ele mude a forma como aquilo tá sendo visto e na maioria das vezes funciona, então isso, agrega conhecimento. Se for uma coisa que parta de você, mas se você só manda ele fazer e meio que você só copia e cola, isso não tem conhecimento nenhum sendo gerado. Então acho que pode sim responder a segunda pergunta também em aulas, atividades e provas, fica até mais dinâmica, eu acho não fica algo muito engessado, como normalmente o ensino tradicional é, e eu acho que deve reportar, sim, também para o professor ter ciência de que aquilo está sendo usado e como isso foi usado, inclusive se você perguntar, pegar uma resposta pronta da inteligência artificial e devolver para ele perguntar se ela foi que ela fez isso, se eu me engano, ela diz que foi ela, então acho que sim. Alguém tem algum comentário sobre a resposta do debatedor 2? Só um ponto bem assim, simples no negócio específico que ele falou, ele falou que se você colocar uma resposta que a IA gerou, ela responde que foi ela que fez, mas assim isso é algo também que ainda está um pouco em desenvolvimento, porque existe, por exemplo, certas respostas criadas por humanos que se colocar, por exemplo, no chat GPT. Ele disse que foi ele que fez, então ainda é uma coisa um pouco falha, que eu acho que tem que se melhorar. Tem algo a comentar sobre a resposta dele? Não, eu acho que é isso mesmo, até porque está tudo meio que começando, ainda está dando os primeiros passos, então, normal ter falhas e imprecisões. Também acho que ela pode ser utilizada, estava vendo no fórum do IF de Santa Catarina, o professor de lá falou que podia ser usado na discussão do assunto, porque às vezes você joga lá uma pergunta e ele pode responder uma coisa que não tem sentido com a realidade. Ele quando vai filtrar lá ele pode acabar, criando uma teoria, entre aspas, que não existe. Ele falou que a pessoa fala assim, é mais interessante você focar , na qualidade da pergunta que você vai fazer para IA do que a resposta em si que ela vai dar, que ajuda a ampliar a discussão dentro do diálogo dentro da sala. Infelizmente a gente sabe que no mundo atual, a maioria das pessoas usam só para obter uma resposta pronta, mas se fosse usado, se a gente tivesse no mundo ideal, ajudaria muito nos processos de estudo. Ajudaria nos processos de estudo porque como ele é, como a IA junta, agrupa vários complementos, vários conteúdos, seria uma fonte muito rica de informação, de conteúdo, de exercício e tudo mais que fosse complementar. Então, para ser aplicado nas escolas, eu acho que seria muito bom os professores, por exemplo, criarem diretrizes também da forma como eles deveriam usar também com penalidades, se fosse criar resposta pronta, porque é muito, muito bom, é algo realmente uma, a gente tem a faca e o queijo que pode muito bem facilitar e ajudar no nosso processo acadêmico, como também pode prejudicar, porque um aluno que só pega resposta pronta do chat GPT, ele pode tirar nota muito boa, mas ele não vai ser um bom aluno, bom profissional, porque ele só tá copiando aquilo que não foi ele que fez e o ensino, Ele não é baseado nisso. Então se a gente souber realmente usar da forma correta, , a IA, ela é muito, muito promissora na educação. Alguém tem mais algo a comentar? Vamos para a terceira pergunta para o para a debatedora 3, de que maneira a propriedade intelectual deve ser tratada quando o conteúdo é gerado por IA, por exemplo, se um usuário gerou uma música usando IA o crédito pela criação deve ser deste usuário ,da plataforma de IA utilizada ou do criador dos dados originais com os quais a IA foi treinada? no caso a IA aplicada da mesma forma que um agrupamento de conteúdo com musica, por exemplo? Entendi, eu não sei, eu não tenho opinião formada sobre isso porque imagem, a pessoa só colocou, só, escreveu o texto. E ela gerou lá. Um agrupamento de várias coisas, mas a criatividade ela é a junção de várias ideias juntas. Então não tem nada de novo e extraordinário. É tudo coisas que já foram criadas, então se é a pessoa, criou uma música usando o IA. Eu acho que o crédito pode ser dela mas não totalmente, não tenho uma opinião formada sobre isso. Alguém tem algo a comentar sobre a resposta dela? sobre a parte do criador dos dados originais com o qual a IA foi treinada. Eu acho que assim. varia muito. assim. É a principal questão, na minha opinião, porque se você for ver os dados que foi treinado a IA, muitas vezes você pega, tenta pegar o, puts pera aí, tenta gerar alguma coisa com a IA e a maioria das vezes é só os dados originais, só que embaralhados. Então assim, é grande parte dos dados originais que é criado essas novas coisas. Então. Então você acha que é o direito autoral é do dado original? Se for, se o banco de dados foi, por exemplo, só de um autor, eu acho que sim. É que nem o cover o cover de uma música, ela tem uma forma diferente, pode até usar, você usa as mesmas notas e tals, usar instrumento diferente, tem um estilo diferente. Só que a música original é do cantor que do cantor, do compositor que escreveu aquela música. Acho que tem o mesmo significado. Alguém tem algo a comentar sobre a resposta, sobre a pergunta? Tá, vamos para a pergunta 4, então, para o debatedor 4. Como garantir que conteúdos gerados por IA não sejam usados para espalhar informações tendenciosas, errêneas ou maliciosos, por exemplo, quando este tipo de informação é propagada maximamente por bots em uma rede social, a responsabilidade deve ser da empresa que administra a Rede Social, dos programadores da IA ou de quem produziu aquele conteúdo usando a IA. Tá, vamos lá. acho que a primeira parte é como garantir que esses conteúdos são, são reguladas, não são espalhados, são contidos. Eu acho que criando mais tecnologia para prever isso, uma IA que por exemplo, vê se ver se a informação é verdadeira, ver se há, se alguma coisa é um deep fake ou algo do tipo ou e acho que na parte da responsabilidade, são um pouco da rede social que sempre tem que melhorar a sua parte de segurança de análise para ver se é um bot ou não, e etc, mas eu acho que, principalmente da parte do quem produziu o conteúdo também porque produziu um conteúdo falso, obviamente você tá querendo fazer> uma coisa que não é dentro das partes legais, na minha opinião. Alguém tem algo a comentar sobre a resposta que ele deu? , além <corr de quem produziu ser responsabilizado, eu acho que também a rede social, porque quase tudo que a gente entra hoje em dia tem aquele caption, né, que é meio para evitar isso e também algumas redes sociais também fazem, inclusive acho que o tipo o WhatsApp fez isso que limita as mensagens ou quantidade de mensagens que você manda. Então meio que se foi disparado massivamente, então o canal de por onde isso foi espalhado e também tem uma certa culpa de não ter segurança o suficiente para isso. Alguém tem mais algo a comentar? Assim, eu concordo com isso, que também a empresa que administra tem um pouco de culpa, mas também do mesmo jeito que é a empresa vai se melhorando pra é vigiar isso, os bots também vão melhorando, porque muitas vezes criam-se bots orgânicos que se parecem ser perfis de pessoas, etc, que, por exemplo, , não é um bote que manda várias mensagens. São vários bots que vão individualmente mandando mensagens, que assim cria-se várias, uma compartilhação massiva de fake news. Acho que, obviamente, a rede docial tem também um pouco de parte da da culpa, mas também não dá para se culpar grande parte dela, porque é algo que é o gato e rato um vai caçar e sempre o outro vai ter que conseguir escapar. Não só pra complementar, quando tem notícia assim, falsa, espalhada, principalmente que eu vejo no Twitter e no Instagram. De vez em quando o Instagram mas é mais no Twitter, tem uma tarjazinha que alguém verificado uma autoridade sobre o assunto, coloca se é falso ou verdadeiro e a descrição do que porque é falso ou verdadeiro. No Instagram eu vi isso, mas foi mais no período eleitoral, no Twitter, é mais assuntos gerais assim. Alguém tem mais alguma colocação? Nessa parte tarjas e e etc. Assim, no Twitter, eu sei que é por parte dos próprios usuários, ou seja, não é algo algo que a rede social administra, são os próprios usuários que regulam os próprios usários que muitas vezes os usuários que regulam não estão também certos. Eu já vi, por exemplo, tarjas que são falsas e que a, aí sim, a rede social tem que estar na culpa de ver se é verdadeiro ou não. Alguém tem mais algo a comentar? Não, okay. Nesse último momento, vou passar pra uma pergunta que essa pergunta é geral, é livre e todo mundo pode responder, não é direcionada a ninguém, certo? O uso e desenvolvimento de IAs generativas devem ser fortemente fiscalizados por órgãos governamentais ou elas são apenas mais um tipo de software comum, como milhares de outras existências? Alguém quer responder? eu acho que se o governo tem que meter a mão, eu acho que ele tem que meter a mão, meio que de longe, não incisivamente, porque assim, isso também, como eu tava falando, vai atrapalhar a liberdade criativa da IA, e de quem cria essas IA, além de que vai ficar algo muito burocrático e muito ineficiente. Não vai, acho que aflorar muito, se falar de Brasil, especificamente do Brasil, acho que países que tendem a ter uma liberdade maior para os desenvolvedores meio que vai desenvolver mais esse conceito e essa ferramenta IA generativa. Então eu acho que sim, é tipo mais um software como qualquer outro, mas se for para fiscalizar, que seja meio que punitivamente e não fiscalizar de fato a produção e meter a mão na produção e esse tipo de coisa. Alguém tem algo a comentar sobre a resposta que ele deu? É sobre os direitos humanos, né? Eu vou utilizar essa plataforma para, enfim, como naquela pergunta de algo racista, sexista ou algo assim não precisa de ser uma coisa estrita, até porque, por exemplo, o Instagram não tem um artigo na Constituição sobre como a gente deve usar o Instagram, existe as diretrizes da própria plataforma, sobre como aquele aplicativo deve funcionar, o que é que a gente pode ou não pode fazer? Então eu acho que deveria ser fiscalizado como ele disse, de longe assim no sentido de a ferir direitos humanos, mas também as diretrizes, enfatizar as diretrizes criadas pela própria plataforma como um filtro e regras mesmo de como > aquela plataforma deve ser utilizada, que é até então, nesse primeiro momento como ela é nova, ainda tá muito liberal assim, então a gente tá vendo, tá vendo como as coisas vão acontecendo, que vai ser necessário mesmo ter regrado não é ditatoriamente, mas de forma, a manter a passividade. Alguém tem mais alguma coisa a comentar? Sobre a pergunta, sobre a resposta que ela deu. Certo, agora a gente vai ter outro momento que é da mesma forma que vocês deram a opinião inicial de vocês no debate agora quero opinião final de vocês. Se vocês acham que tem algo a apresentar acrescentar eu vou passar a palavra, cada um de vocês e aí esse é um momento de dar opinião, final de vocês depois do debate, começar pelo o debatedor um. Não acho que. É o que eu falei no começo, tem pontos positivos, negativos. A gente debateu vários pontos importantes aqui, essa questão da fiscalização, tem que tomar bastante cuidado, porque às vezes envolve interesse da instituição ou pessoa que está fiscalizando isso pode acabar <inaudivel/>, mas acho que a gente debateu pontos importantes e não sei mais o que falar, minha opinião permanece a mesma, mas gostei de ouvir a opinião de cada um. pode ser que tenha mudado minha opinião de certa forma, só não sei externar, ainda de que forma. Ok , debatedor 2. Acho que eu compartilho da mesma opinião do um, só que eu ainda acho que tem algumas consideração que eu não falei que eu ainda acho que fica meramente nesse trabalho repetitivo mesmo a IA ela nunca vai conseguir ser ou expressar algo que um humano de fato faz, porque por filosofia das coisas e jeito das coisas serem mesmo porque a IA de fato, não tem vontade, nem ela é um ser de fato, ela, basicamente um idiota útil, muito rápido e que consegue mimetizar dados que as pessoas colocam, ela até pode meio que desenvolver um falso afeto ou um falso sentimento em algum futuro, mas isso não vai ser de fato algo humano e real. Então, quanto a substituir os humanos, eu acho que isso nunca vai acontecer. no fato de intelectualizar e de sentimento e esse tipo de coisa, mas manualmente, provavelmente, mas é porque muitas coisas que a gente conversou aqui foge um pouco do escopo só IA e vão para escopo como educação, como moral, como ética e são assuntos de uma forma geral, então não fica só na IA isso, até em relação ao filtro da IA, que de fato, o sujeito define como verdade ou falso e desse tipo de coisa toda é meio subjetivista demais tudo isso. Acho que é muito importante esse debate, eu acho até que a gente deve levar isso até nós enquanto profissionais, né? Da computação, a gente tem que levar esse assunto mais em pauta para a sociedade, tanto pela importância disso quanto por trazer a verdade, porque as pessoas, elas são muito enganadas por fake news e tal e a gente realmente mostrar o que realmente significa, o que é de verdade, os benefícios que pode trazer e os malefícios. Isto vai trazer muito um melhor uso da da plataforma. Eu acho que o IA é muito importante, mas também a gente não pode endeusar tanto a ponto de achar que vai substituir o humano e que a gente não tem que usar, que isso daí tem que ser fiscalizado pelo governo, que isso não é bom, não é bom, não é bom mas eu também não acho que a gente deva deva endeusar algo no ponto de terceirizar todas as nossas responsabilidades, tudo do ser humano numa inteligência artificial, que é como o 2 falou, existem coisas que só nós, humanos, a gente tem capacidade de fazer uma IA ela pode reproduzir um som, mas ela não vai transmitir a emoção daquela voz, os sentimentos, a mensagem que ela quer passar. Então é realmente foi como a roda para os primeiros homens aqui facilitou, ajudou, então, se a gente souber utilizar essa ferramenta, de uma forma útil e de uma forma benéfica para a gente a gente vai ter muitos benefícios e também eu volto a enfatizar, a criação de diretrizes da própria plataforma para evitar que danos maiores eles possam acontecer, como ferir os danos Morais, direitos humanos e todas essas questões que a gente abordou. Debatedor 4 Assim, completamente um pouco do que a 3 disso, eu acho que, principalmente na parte de, pera aí, putz deu um branco aqui mas principalmente essa parte de autoridade e tal, assim o, como posso colocar em palavra? Deixa eu pensar. o banco de dados da IA sempre vai pegar algo humano, se você ficar só utilizando IA IAI IA, você não vai ter coisas novas para incrementar nesse próprio banco de IA humanas. Então, acho que assim é o que eu falei no começo e acho que mantenho a principal pauta da IA é você está pegando uma uma base de dados autoral e vai mais ou menos reorganizar para criar coisas novas. Então o quão etico é pegar isso e de outra pessoa e reorganizar, acho que isso é o principal pauta da´IA, em relação a principalmente entretenimento, basicamente. Mais alguma coisa? Massam Então é isso, vou finalzar a gravação agora, tudo certo.\n"]}]},{"cell_type":"markdown","source":["# Contador de Disfluências Removidas"],"metadata":{"id":"OKYj9oxTe4iw"}},{"cell_type":"code","source":["def contar_ocorrencias_texto(texto, dicionario):\n","    # Inicializando o dicionário de contagem de ocorrências\n","    ocorrencias_llm = {key: 0 for key in dicionario}\n","\n","    # Adiciona espaços ao redor do texto para capturar padrões no início e fim\n","    texto = f\" {texto} \"\n","\n","    # Pontuações consideradas após o padrão\n","    pontuacoes = r'[,.!?;:]?'\n","\n","    # Iterando sobre as chaves do dicionário\n","    for chave in dicionario:\n","        # Adiciona espaços ao redor da chave e permite pontuações depois da chave\n","        padrao = rf' {re.escape(chave)}{pontuacoes} '\n","        # Usando expressão regular para encontrar todas as ocorrências da chave no texto\n","        ocorrencias = re.findall(padrao, texto)\n","        # Atualizando a contagem no dicionário 'ocorrencias_llm'\n","        ocorrencias_llm[chave] = len(ocorrencias)\n","\n","    return ocorrencias_llm\n","\n","def subtrair_dicionarios(dict1, dict2):\n","    # Inicializando o dicionário de resultado para a diferença\n","    resultado = {}\n","\n","    # Conjunto de todas as chaves presentes em ambos os dicionários\n","    todas_chaves = set(dict1.keys()).union(set(dict2.keys()))\n","\n","    # Calculando a diferença para cada chave\n","    for chave in todas_chaves:\n","        # Contagem em dict1 (dicionário original)\n","        contagem1 = dict1.get(chave, 0)\n","        # Contagem em dict2 (dicionário resultante)\n","        contagem2 = dict2.get(chave, 0)\n","        # Calculando a diferença\n","        diferenca = contagem1 - contagem2\n","        # Adicionando ao dicionário de resultado apenas se a diferença for não zero\n","        if diferenca != 0:\n","            resultado[chave] = diferenca\n","\n","    return resultado\n","\n","def preenche_dic_disfluentes(disfluencias):\n","  # Inicializando os dicionários de hesitações, repetições, erros e correções\n","    hes = {}\n","    rep = {}\n","    erro = {}\n","    corr = {}\n","\n","    # Preenchendo os dicionários 'hes', 'rep', 'erro' e 'corr'\n","    for tag, content in disfluencias:\n","        if tag == 'hes':\n","            hes[content] = hes.get(content, 0) + 1\n","        elif tag == 'rep':\n","            rep[content] = rep.get(content, 0) + 1\n","        elif tag == 'erro':\n","            erro[content] = erro.get(content, 0) + 1\n","        elif tag == 'corr':\n","            corr[content] = corr.get(content, 0) + 1\n","\n","    return hes, rep, erro, corr\n","hes, rep, erro, corr = preenche_dic_disfluentes(disfluencias)\n","\n","def count_disfluencias_in_clean(clean_text, hes, rep, erro, corr):\n","        # Contando ocorrências no texto\n","    hes_llm = contar_ocorrencias_texto(clean_text, hes)\n","    rep_llm = contar_ocorrencias_texto(clean_text, rep)\n","    erro_llm = contar_ocorrencias_texto(clean_text, erro)\n","    corr_llm = contar_ocorrencias_texto(clean_text, corr)\n","\n","\n","    return hes_llm, rep_llm, erro_llm, corr_llm\n","\n"],"metadata":{"id":"fHMdHUT4gnWK","executionInfo":{"status":"ok","timestamp":1725287685456,"user_tz":180,"elapsed":6,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Código para fazer o balanço da limpeza da LLM"],"metadata":{"id":"LOaeIJ3IyyGn"}},{"cell_type":"code","source":["def count_matches(manual_dict, llm_dict):\n","    \"\"\"\n","    Counts how many times the LLM correction matches the manual correction.\n","\n","    Args:\n","    - manual_dict (dict): The dictionary with the manual correction.\n","    - llm_dict (dict): The dictionary with the LLM correction.\n","\n","    Returns:\n","    - int: The count of keys with matching values.\n","    \"\"\"\n","    # Initialize the counter for matches\n","    matches = 0\n","    length_of_incorrect_matches = 0\n","\n","    # Iterate through all keys in the manual correction dictionary\n","    for key in manual_dict:\n","        # Check if the key exists in the LLM correction dictionary and has the same value\n","        if key in llm_dict and manual_dict[key] == llm_dict[key]:\n","            matches += 1  # Increment the counter if the values match\n","        else:\n","          errors = abs(manual_dict[key] - llm_dict[key])\n","          length_of_incorrect_matches += abs(len(key)) * errors\n","    return matches, length_of_incorrect_matches\n","\n","def calcular_metricas(acertos, total_chaves):\n","    \"\"\"\n","    Calcula as métricas de comparação entre acertos da LLM e o total de chaves.\n","\n","    Args:\n","    - acertos (int): Número de acertos da LLM.\n","    - total_chaves (int): Número total de chaves no dicionário manual.\n","\n","    Returns:\n","    - porcentagem_acertos (float): Percentual de acertos da LLM.\n","    - erros (int): Número de chaves que a LLM não identificou corretamente.\n","    \"\"\"\n","    porcentagem_acertos = (acertos / total_chaves) * 100 if total_chaves > 0 else 0\n","    erros = total_chaves - acertos\n","    return porcentagem_acertos, erros\n","\n","def exibir_metricas(resultados):\n","    \"\"\"\n","    Exibe as métricas de comparação entre a LLM e o manual para cada categoria.\n","\n","    Args:\n","    - resultados (dict): Dicionário com as categorias e tuplas de (acertos, total_chaves).\n","    \"\"\"\n","    total_acertos = 0\n","    total_chaves = 0\n","    categorias_erro = ['Repetições', 'Hesitações', 'Erros']\n","\n","    # Calcula e exibe as métricas para cada categoria\n","    for categoria, (acertos, total) in resultados.items():\n","        porcentagem_acertos, erros = calcular_metricas(acertos, total)\n","        print(f'{categoria}:')\n","        print(f'  Acertos da LLM: {acertos}')\n","        print(f'  Total de chaves no manual: {total}')\n","        print(f'  Porcentagem de acertos: {porcentagem_acertos:.2f}%')\n","        print(f'  Número de chaves não corretamente identificadas: {erros}')\n","        print()\n","\n","        # Somando para o cálculo da média de acertos\n","        if categoria in categorias_erro:\n","            total_acertos += acertos\n","            total_chaves += total\n","\n","    # Calcula a porcentagem média de acertos para as categorias de erro\n","    media_acertos = (total_acertos / total_chaves) * 100 if total_chaves > 0 else 0\n","    print(f'Média de porcentagem de acertos entre Hesitações, Erros e Repetições: {media_acertos:.2f}%')\n"],"metadata":{"id":"K6VPlVWiy116","executionInfo":{"status":"ok","timestamp":1725287685456,"user_tz":180,"elapsed":5,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Código para mensurar as alterações e integridade"],"metadata":{"id":"o2W-_Q-x7gKr"}},{"cell_type":"code","source":["def calculate_metrics(original, processed):\n","    # Calcula a distância de Levenshtein\n","    levenshtein_distance = Levenshtein.distance(original, processed)\n","\n","    # Calcula a similaridade de Levenshtein\n","    levenshtein_similarity = Levenshtein.ratio(original, processed)\n","\n","    # Calcula a distância de edição\n","    edit_distance = Levenshtein.distance(original, processed)\n","\n","    original_length = len(original)\n","    processed_length = len(processed)\n","\n","    original_word_count = len(original.split())\n","    processed_word_count = len(processed.split())\n","\n","    return {\n","        'Levenshtein Distance': f'{levenshtein_distance:,}',\n","        'Levenshtein Similarity': f'{levenshtein_similarity * 100:.2f}%',\n","        'Edit Distance': f'{edit_distance:,}',\n","        'Original Length': f'{original_length:,}',\n","        'Processed Length': f'{processed_length:,}',\n","        'Original Word Count': f'{original_word_count:,}',\n","        'Processed Word Count': f'{processed_word_count:,}'\n","    }\n","\n","\n","def adjust_levenshtein_distance(data, not_to_be_considered):\n","    \"\"\"\n","    Adjusts the Levenshtein Distance by excluding a specified number of edits\n","    and recalculates the Levenshtein Similarity.\n","\n","    Parameters:\n","    data (dict): A dictionary containing Levenshtein metrics:\n","                 {'Levenshtein Distance': str, 'Processed Length': str}\n","    not_to_be_considered (int): The number of edits that should not be considered.\n","\n","    Returns:\n","    dict: A dictionary with the adjusted Levenshtein Distance and Similarity.\n","    \"\"\"\n","    # Extract values from the dictionary and convert them to integers\n","    levenshtein_distance = int(data['Levenshtein Distance'].replace(',', ''))\n","    processed_length = int(data['Processed Length'].replace(',', ''))\n","\n","    # Adjust the Levenshtein Distance\n","    adjusted_distance = levenshtein_distance - not_to_be_considered\n","\n","    # Recalculate the Levenshtein Similarity\n","    adjusted_similarity = (1 - (adjusted_distance / processed_length)) * 100\n","\n","    # Return the adjusted values as a dictionary\n","    return {\n","        'Adjusted Levenshtein Distance': adjusted_distance,\n","        'Adjusted Levenshtein Similarity': f'{adjusted_similarity:.2f}%'\n","    }\n"],"metadata":{"id":"j7QpUbqu7j2d","executionInfo":{"status":"ok","timestamp":1725287685456,"user_tz":180,"elapsed":5,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Prompt 1.1 (Zero-shot no context)"],"metadata":{"id":"PJS9yuGDHpk8"}},{"cell_type":"code","source":["prompt = f\"\"\"\n","Please remove disfluencies from the following Portuguese text transcription without changing the original text.\n","Ensure that aside from the removal of this disfluencies, no other changes are made to the text. You should NOT change text that does not refer to disfluencies. ANY text that is not in one of those three categories of disfluencies should not be changed. Return only the cleaned text with no additional information. Remember the text must be in its original full size, but without the disfluencies in it.\n","\n","\n","Text: {texto_disfluente}\n","\"\"\"\n","response1, duration1 = get_response_and_time(prompt)\n","\n","print(response1.text)\n","print('A limpeza foi feita em ', duration1)"],"metadata":{"id":"vyxII3TtHtgd","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1725287815371,"user_tz":180,"elapsed":129920,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"outputId":"7fbffabe-40f2-44f0-ffa9-eecfe79141b2"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Vamos lá, boa tarde todo mundo. Bem-vindos a este debate promovido pelo grupo de pesquisa do Lacina, debate em educação. Eu me chamo David e gostaria de apresentar aqui quem está comigo, Klaywert, que também faz parte do grupo. Mas aí a gente tem também Bryan e Hellen, que são, tirando Hellen, a maioria estudantes do mestrado, Hellen é estudante da graduação. E esse projeto está sobre orientação do professor Campelo, que é o professor que vocês conhecem, que vocês conheceram agorinha, que vocês viram agora, certo? OK. A razão pela qual nos reunimos aqui hoje é gerar uma base de dados de voz que posteriormente será transcrita e utilizada para avaliação e treinamento de modelos de inteligência artificial. Nosso foco está entre vários tópicos relacionados a debates, fazendo dessa iniciativa não apenas oportunidade de aprendizado e crescimento, mas também uma contribuição valiosa para avanço de IA.\n","Vocês assinaram o termo, né? Todo mundo já assinou o termo, então a gente pode pular essa parte. Cada um, cada debatedor vai receber uma identificação, né? Vocês já receberam e essa vai ser a identificação de vocês como os debatedores. Aqui a gente não estava interessado nos dados pessoais de vocês, então o processo vai ser identificado dessa forma com esses IDs, certo? A gente vai gravar a voz de vocês. Minha identificação número um. Estou contribuindo com a pesquisa no Brasil. Minha identificação número dois, estou contribuindo com a pesquisa no Brasil. Minha identificação número três, estou contribuindo com a pesquisa no Brasil. Minha identificação número quatro, estou contribuindo com a pesquisa no Brasil. É, explicando as regras do debate. Antes da gente começar o debate é essencial que todos compreendam e sigam as regras do debate. Essas regras foram criadas para garantir um debate justo e ordenado para todos os envolvidos. Primeira regra: sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando. Se você deseja contribuir para a discussão, oferecer algum contra-argumento, por favor, levante a mão e aguarde o moderador, eu, lhe conceder a palavra. Uma vez que tenha sido autorizado a falar, você terá a palavra, poderá expressar seus pensamentos e responder aos outros também.\n","Certo, explicando o funcionamento do debate, vamos seguir em formato estruturado de três momentos distintos, cada um com seu propósito e regras específicas. Momento um: expressão inicial de suas opiniões. No primeiro momento, abordaremos a questão principal do debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central. Momento dois: rodada de perguntas. Num segundo momento, teremos uma rodada de perguntas direcionada para cada um dos debatedores, abriremos espaço para os outros participantes contra argumentarem ou expressarem suas opiniões sobre a resposta dada. Após as perguntas direcionadas, teremos uma outra pergunta, que será direcionada a todos os participantes. Neste momento, vocês terão a liberdade de escolher se desejam responder, caso queira acrescentar algo relevante. No momento três: colocações finais. Um terceiro e último momento será perguntado se os participantes têm alguma outra colocação final sobre o tema.\n","Certo? OK, então a gente vai começar agora. Ficou alguma dúvida antes de tudo? Deu para entender? Vão ser três momentos o debate, então vai ser um debate semi estruturado. Se alguém quiser falar, tem que pedir a vez, não pode estar interrompendo o outro e é basicamente essas regras que vocês devem seguir. E a gente vai ter umas perguntas para nortear o debate também, que eu vou mostrar, vou botar ali na tela e vou ler para vocês também essas perguntas, OK?\n","Certo, como vocês já sabem, o nosso tema é inteligência artificial generativa e seus impactos na sociedade, OK? Para começar, primeiramente, cada um terá um momento inicial para expressar seus principais opiniões e pensamentos sobre o tema, cada participante terá um momento para fazer isso, certo? Vamos começar com o debatedor 1. Você gostaria de expressar a sua opinião? De forma geral, o que é que você pensa sobre o tema? Bom, as IAs generativas são, bem dizer, uma faca de dois gumes, né? Tem aspectos positivos e muito negativos também. Positivos tem automação de algumas atividades, pode auxiliar como ferramenta complementar em estudos. Como negativa, tem a questão de proteção de dados, de autenticidade de resposta, infração de direitos autorais. Então, dependendo da área do argumento que quiser seguir, pode ser positivo ou negativo. Agora o debatedor 2. Olha, em relação aos impactos positivos, as coisas repetitivas vão ser ao longo do tempo eliminadas, alguns trabalhos que precisam de muita repetição. E o que meio que vai ficar, acho que produção intelectualizada, que a IA não consegue fazer bem, inclusive os modelos atuais em relação a opiniões também. E também ele não, ele tem um filtro muito grande, então acho que deve, desde que não infrinja nenhuma lei, deve ter maior liberdade de criação. Os negativos, eu acho que problemas como o deep fake e geração de voz também pelo timbre, eu acho que vai ser um problema muito grande para as autoridades lidar e fazer contramedidas que reconheçam se aquilo é de fato verdade ou não, e meio que impulsiona a desinformação. Em relação a estudo também, eu acho que tende a, dependendo da base de dados, ou a piorar a situação ou a melhorar. Então acho que no futuro a especificação das IAs não ser um aí a geral, ser mais nichado com os vetores de informação, vai vir a melhorar esse problema de espalhar mentiras. Debatedora 3. É, embora esse seja um assunto, um conteúdo que já venha sido tratado há muito tempo, várias pessoas já tenham trabalhado nisso, ultimamente está tendo uma abordagem maior sobre isso. Acho que até depois do chat GPT ter vindo, né? E aí o pessoal ficou sabendo muito. Eu, por exemplo, quando eu não tinha esse conhecimento, eu não sabia da existência das IAs nesse sentido, nesse aspecto. Depois que eu conheci o chat, eu consegui compreender mais e, como os meninos falaram, ele tem aspectos muito positivos e justamente pela pela automação, pela facilidade, pela agilidade. Mas eu acho também que os usos negativos dele podem impactar também na autenticidade do próprio ser humano, como o texto diz, mesmo a criatividade, a humanização. Os textos, por exemplo, quando a gente vai ver no TikTok e o pessoal está usando aquelas vozes fakes, tem, são a voz que você jura que é uma pessoa real, só que não tem as expressões. E eu acho que uma expressão de ironia, de sarcasmo, que o ser humano ele consegue ter, isso é algo do ser humano, menos a IA não consegue obter. Então eu acho que pode ser útil sim para facilitar a nossa vida mesmo, mas não com um substituto de coisas que só o ser humano consegue fazer. Debatedor 5, 4. Sobre as IAs, assim, acho que o principal mesmo é em relação ao trabalho que vai ser, que não tem como você lutar contra esse crescimento das IAs em relação à substituição de empregos. É algo desde a Revolução Industrial, até antes, que a tecnologia sempre vai substituir o ser humano e algo que não pode ser parado. Sobre regulamentação, etc, eu acho que o principal ponto, na minha opinião, é sobre o uso de banco de dados com direitos autorais para geração de novas coisas, porque a maioria das vezes que nesses, essas IAs generativas usam banco de dados de coisas já existentes, como por exemplo, desenhos, já vozes e etc, para criar novas coisas. Então acho que a pauta na legalização de IAs vai ser principalmente nessa área de você poder ou não usar o desenho de alguém para gerar novos desenhos e etc. Certo, vamos iniciar com a rodada de perguntas. Irei realizar uma pergunta para cada participante, que terá seu tempo de resposta e, ao final de sua resposta, os demais podem pedir espaço para comentar algo sobre a pergunta feita ou a resposta dada, OK? Vamos começar. A primeira pergunta é para o debatedor 1. Se um sistema de IA generativa cria algo prejudicial ou ofensivo, por exemplo, uma imagem com conteúdo racista, quem deve ser responsabilizado? O desenvolvedor da IA, o usuário, a plataforma que hospeda ou alguma outra instituição ou pessoa? O autor do texto, da plataforma que hospeda, a plataforma e quase sempre o desenvolvedor da IA, porque, querendo ou não, é ele que criou a ferramenta para conseguir filtrar o que ela deve ou não buscar, porque, realmente, com as IAs, elas podem perpetuar preconceitos e estereótipos, porque eles fazem o filtro e podem, nesses textos que elas estão filtrando, acabar inserindo no texto que ela vai enviar para o usuário certas falas que não são adequadas na sociedade atual. Alguém tem algo a comentar sobre a resposta do debatedor? Mais alguém tem alguma outra colocação sobre essa pergunta específica que queira comentar? Pode dizer. Às vezes o banco de dados da IA que traz para a própria IA, às vezes já vem com alguns dados que podem ser preconceituosos, seja racistas ou sexistas e etc. Às vezes isso já vem do próprio banco de dados, que gera novos dados que também são racistas, sexistas, etc. Acho que na minha, na minha visão. Então tu acha que a pessoa culpada seria quem introduziu o dado? Não, eu não acho que a pessoa culpada seria quem produziu o dado, assim. Não sei, sinceramente, eu teria que pensar um pouco mais para saber quem seria punido nessa daí, porque realmente dentro das opções ali, eu pensei a priori, eu pensei no usuário, mas também o desenvolvedor. A plataforma pode inclinar o dado a sair como como algo racista ou sexista, por exemplo. Eu acho que seria mais ou menos como se fosse a política do Instagram, que tem aquele filtro de palavras negativas e ofensivas que você usa em comentários que, justamente, já pela consciência de que isso pode ocorrer, tanto o desenvolvedor já cria esse filtro, essas diretrizes de de política, de respeito, de direitos humanos e tal, essas coisas, quanto também do usuário, assim, que ele escrever, já ter, tipo, um bloqueio para para isso não acontecer, tanto a consciência do usuário para estar pesquisando essas coisas quanto do desenvolvedor. Só para fazer um adendo à minha resposta, falei que podia punir a plataforma que hospeda, mas desde que, por exemplo, vamos supor, seja um site de crônicas, aí a pessoa tem autoridade dentro do site. Agora, se for, por exemplo, um Reddit, um fórum de discussão, aí eu já acho que não deva responsabilizar a plataforma e sim fazer como a debatedora 3 falou e fazer a questão do filtro antes da mensagem ser enviada, já evita problemas posteriores. A culpa maior seria de usuário em si, da pessoa? Sim. Pode dizer, debatedor 4. Porque também varia muito do conteúdo que está sendo gerado. Por exemplo, um texto é algo um pouco mais direto. Agora, uma imagem, um dado, às vezes, pode ser um pouco mais indireto, mais sutil esse preconceito. Eu acho que o principal responsabilidade deve ser o usuário. Eu acho que o desenvolvedor da IA, ele não, assim, a gente sabe que o usuário, muitas vezes, ele é muito criativo em quebrar as coisas. Então se uma IA é muito generalista, talvez o usuário seja muito criativo em fazer com que esse conteúdo seja produzido. Então eu acho que é meio que foge um pouco do escopo do que o desenvolvedor consegue ou não pensar, porque, assim, desde que a internet é internet, tem gente só pensando em como quebrar aquela coisa que está disposta ali, então eu acho que o principal problema é o usuário e não o desenvolvedor. É a mesma coisa de ter um carro e o usuário do carro, meio que o motorista, decidir se ele vai sair batendo em tudo ou vai seguir o fluxo normal, acho que é basicamente isso. Até porque o propósito desse, dessa IA criada pelo desenvolvedor é auxiliar, trazendo manutenção, facilidade para a pessoa de modo benéfico. Então seria realmente culpa do usuário o mau uso do da plataforma. Então, por isso que seria necessário, justamente por causa de, talvez não fosse necessário se o usuário não fizesse isso, mas como a gente sabe que isso já é um histórico muito grande de que as pessoas usam isso para quebrar as regras, então seria necessário já umas diretrizes para evitar que esse problema viesse acontecer, que a culpa, o pessoal iria culpar a marca também, né? A plataforma em si. Alguém tem mais alguma coisa a comentar? Certo, vamos para a pergunta 2. Para o debatedor 2. IAs generativas podem ser usadas nos processos educacionais, por exemplo, em aulas, atividades ou provas? O aluno devem reportar o professor sobre o uso de IA generativa em suas atividades? São duas perguntas, né? Não, três no caso. A primeira, eu acho que sim, pode ajudar mais do que atrapalhar, desde que seja usado da forma correta. Inclusive, acho que está tendo um movimento na academia. Acho que foi uma professora que está falando que estão desenvolvendo papers para que isso seja incentivado e não desincentivado, como foi em um primeiro momento, porque é mais pelo uso mesmo do usuário, porque tem gente que só coloca lá e pede para ele já vim na resposta direta. Mas se você, por exemplo, às vezes eu até uso isso, você coloca a sua resposta para ele incrementar algo ou então fazer com que ele mude a forma como aquilo está sendo visto e, na maioria das vezes, funciona. Então isso agrega conhecimento, se for uma coisa que parta de você, mas se você só manda ele fazer e meio que você só copia e cola, isso não tem conhecimento nenhum sendo gerado. Então acho que pode sim. Responder a segunda pergunta também. Em aulas, atividades e provas fica até mais dinâmica, eu acho, não fica algo muito engessado, como normalmente o ensino tradicional é. E eu acho que deve reportar sim, também para o professor ter ciência de que aquilo está sendo usado e como isso foi usado. Inclusive, se você perguntar, pegar uma resposta pronta da inteligência artificial e devolver para ele, perguntar se ela foi, que ela fez isso, se eu me engano, ela diz que foi ela. Então acho que sim. Alguém tem algum comentário sobre a resposta do debatedor 2? Só um ponto bem assim, simples, no negócio específico que ele falou, ele falou que se você colocar uma resposta que a IA gerou, ela responde que foi ela que fez, mas assim, isso é algo também que ainda está um pouco, um pouco em desenvolvimento, porque existe, por exemplo, certas respostas criadas por humanos que, se colocar, por exemplo, no chat GPT, ele disse que foi ele que fez. Então ainda é uma coisa um pouco falha, que eu acho que tem que se melhorar. Tem algo a comentar sobre a resposta dele? Não, eu acho que é isso mesmo, até porque está tudo meio que começando, ainda está dando os primeiros passos, então normal ter falhas e imprecisões. Também acho que ela pode ser utilizada. Estava vendo no fórum da do IF de Santa Catarina, o professor de lá falou que podia ser usado na discussão do assunto, porque às vezes você joga lá uma pergunta e ele pode responder uma coisa que não tem sentido com a realidade. Ele, quando vai filtrar lá, ele pode acabar criando uma teoria, entre aspas, que não existe. Ele falou que a pessoa fala assim: \"É mais interessante você focar na pergunta da qualidade, na qualidade da pergunta que você vai fazer para IA do que a resposta em si que ela vai dar\", que ajuda a ampliar a discussão dentro do diálogo, dentro da sala. Infelizmente, a gente sabe que no mundo atual a maioria das pessoas usam só para obter uma resposta pronta, mas se fosse usado, se a gente tivesse no mundo ideal, ajudaria muito nos processos de estudo. Ajudaria nos processos de estudo porque como ele é, como a IA junta, agrupa vários complementos, vários conteúdos, seria uma fonte muito rica de informação, de conteúdo, de exercício e tudo mais que fosse complementar. Então, para ser aplicado nas escolas, eu acho que seria muito bom os professores, por exemplo, criarem diretrizes também da forma como eles deveriam, deveriam usar, também com penalidades se fosse criar resposta pronta, porque é muito, muito bom, é algo realmente uma, a gente tem a faca e o queijo, que pode muito bem facilitar e ajudar no nosso processo acadêmico, como também pode prejudicar, porque um aluno que só pega resposta pronta do chat GPT, ele pode tirar nota muito boa, mas ele não vai ser um bom aluno, bom profissional, porque ele só está copiando aquilo que não foi ele que fez e o ensino, ele não é baseado nisso. Então se, se a gente souber realmente usar da forma correta, a IA, ela é muito, muito promissora na educação. Alguém tem mais algo a comentar? Vamos para a terceira pergunta para a debatedora 3. De que maneira a propriedade intelectual deve ser tratada quando o conteúdo é gerado por IA? Por exemplo, se um usuário gerou uma música usando IA, o crédito pela criação deve ser deste usuário, da plataforma de IA utilizada ou do criador dos dados originais com os quais a IA foi treinada? No caso, a IA aplicada da mesma forma que um agrupamento de de conteúdo com música, por exemplo? Entendi, eu não sei, eu não tenho opinião formada sobre isso porque imagem, a pessoa só colocou, só escreveu o texto e ela gerou lá um agrupamento de várias coisas, mas a criatividade, ela é a junção de várias ideias juntas, então não tem nada de novo e extraordinário, é tudo coisas que já foram criadas. Então se é a pessoa criou uma música usando o IA, eu acho que o crédito pode ser dela, mas não totalmente, não tenho uma opinião formada sobre isso. Alguém tem algo a comentar sobre a resposta dela? Sobre a parte do do criador dos dados originais com o qual a IA foi treinada, eu acho que, assim, varia muito, assim. É a principal questão, na minha opinião, porque se você for ver os dados que foi treinado a IA, muitas vezes você pega, tenta pegar o, puts, pera aí, tenta gerar alguma coisa com a IA e, a maioria das vezes, é só os dados originais, só que embaralhados. Então, assim, é grande parte dos dados originais que é criado essas, essas novas coisas. Então. Então você acha que o direito autoral é do dado original? Se for, se o banco de dados foi, foi, por exemplo, só de um autor, eu acho que sim. É que nem o cover, a gente, o cover de uma música, ela tem uma forma diferente, pode até usar, você usa as mesmas notas e tals, usar instrumento diferente, tem um estilo diferente, só que a música original é do do cantor que, do cantor, do compositor que escreveu aquela música. Acho que tem a mesma, o mesmo significado. Alguém tem algo a comentar sobre a resposta, sobre a pergunta? Tá, vamos para a pergunta 4 então, para o debatedor 4. Como garantir que conteúdos gerados por IA não sejam usados para espalhar informações tendenciosas, errôneas ou maliciosos? Por exemplo, quando este tipo de informação é propagada maximamente por bots em uma rede social, a responsabilidade deve ser da empresa que administra a rede social, dos programadores da IA ou de quem produziu aquele conteúdo usando a IA? Tá, vamos lá. Acho que a primeira parte é como garantir que esses, esses conteúdos são, são regulados, são, não são espalhados, são contidos. Eu acho que criando mais tecnologia para prever isso, uma IA que, por exemplo, vê se, ver se a informação é verdadeira, ver se há, se alguma coisa é um deep fake ou algo do tipo. E acho que na parte da responsabilidade são um pouco da rede social, que sempre tem que melhorar a sua parte de segurança de análise para ver se é um bot ou não e etc. Mas eu acho que, principalmente da parte de do quem produziu o conteúdo também, porque produziu um conteúdo falso, obviamente, você está querendo que se, querendo fazer uma coisa que não é dentro das partes legais, na minha opinião. Alguém tem algo a comentar sobre a resposta que ele deu? Além da de quem produziu ser responsabilizado, eu acho que também a rede social, porque quase tudo que a gente entra hoje em dia tem aquele caption, né? Que é meio para evitar isso. E também algumas redes sociais também fazem, inclusive acho que o tipo WhatsApp fez isso, que limita as mensagens, a quantidade de mensagens que você manda, então meio que se foi disparado massivamente. Então o canal de por onde isso foi espalhado e também tem uma certa culpa de não ter segurança o suficiente para isso. Alguém tem mais algo a comentar? Assim, eu concordo com isso, que também a empresa que administra tem um pouco de culpa, mas também do mesmo jeito que é, a empresa vai se melhorando para vigiar isso, os bots também vão melhorando, porque muitas vezes criam-se bots orgânicos que se parecem ser perfis de pessoas, etc, que, por exemplo, não são, não é um bot que manda várias mensagens. São vários bots que vão individualmente mandando mensagens, que, assim, cria-se várias, várias, uma compartilhação massiva de fake news. Acho que, obviamente, a rede social tem também um pouco de parte da da culpa, mas também não dá para se culpar grande parte dela, porque é, é algo que é o, é o gato e rato, um vai caçar e sempre o outro vai ter que conseguir escapar. Não só, só para complementar, quando tem notícia assim, falsa, espalhada, principalmente que eu vejo no Twitter e no Instagram, de vez em quando o Instagram, mas é mais no Twitter, tem uma tarjazinha que alguém verificado, uma autoridade sobre o assunto, coloca se é falso ou verdadeiro e a descrição do que, porque é falso ou verdadeiro. No Instagram eu vi isso, mas foi mais no período eleitoral, no Twitter é mais assuntos gerais, assim. Alguém tem mais alguma colocação? Nessa parte da do de tarjas e e etc, assim, no Twitter eu, eu sei que é por parte dos próprios usuários, ou seja, não é algo, algo que a rede social administra, são os próprios, os próprios usuários que regulam os próprios usuários, que muitas vezes os usuários que regulam não estão também certos. Eu já vi, por exemplo, tarjas que são falsas e que a, aí sim, a rede social tem que estar na culpa de ver se é verdadeiro ou não. Alguém tem mais algo a comentar? Não, OK. Nesse último momento, vou passar para uma pergunta que, essa pergunta é geral, é livre e todo mundo pode responder, não é direcionada a ninguém, certo? O uso e desenvolvimento de IAs generativas devem ser fortemente fiscalizados por órgãos governamentais ou elas são apenas mais um tipo de software comum, como milhares de outras existências? Alguém quer responder? Eu acho que se o governo tem que meter a mão, eu acho que ele tem que meter a mão meio que de longe, não incisivamente, porque, como assim, isso também, como eu estava falando, vai atrapalhar a liberdade criativa da IA e de quem cria essas IAs, além de que vai ficar algo muito burocrático e muito ineficiente, não vai, acho que, aflorar muito, se falar de Brasil, especificamente do Brasil. Acho que países que tendem a ter uma liberdade maior para os desenvolvedores meio que vai desenvolver mais esse conceito e essa ferramenta, IA generativa. Então eu acho que sim, é tipo mais um software como qualquer outro, mas se for para fiscalizar, que seja meio que punitivamente e não fiscalizar de fato a produção e meter a mão na produção e esse tipo de coisa. Alguém tem algo a comentar sobre a resposta que ele deu? É sobre os direitos humanos, né? Eu vou utilizar essa, essa plataforma para, enfim, como naquela pergunta de algo, algo racista, sexista ou algo assim, não precisa de ser uma coisa estrita, até porque, por exemplo, o Instagram não tem um artigo na Constituição sobre como a gente deve usar o Instagram, existe as diretrizes da própria, da própria plataforma sobre como aquele aplicativo deve funcionar, o que é que a gente pode ou não pode fazer? Então eu acho que deveria ser fiscalizado, como ele disse, de longe, assim, no sentido de a ferir direitos humanos, mas também as diretrizes, enfatizar as diretrizes criadas pela própria plataforma como um filtro e regras mesmo de como aquela plataforma deve ser utilizada, que é até então, nesse primeiro momento, como ela é nova, ainda está muito liberal, assim. Então a gente está vendo, está vendo como as coisas vão acontecendo, que vai ser necessário mesmo ter mais um, algo mais regrado, não é ditatoriamente, mas de forma a manter a passividade. Alguém tem mais alguma coisa a comentar? Sobre a pergunta, sobre a resposta que ela deu. Certo, agora a gente vai ter outro momento, que é da mesma forma que vocês deram a opinião inicial de vocês no debate, agora quero opinião final de vocês, se vocês acham que tem algo a apresentar, acrescentar, eu vou passar a palavra, cada um de vocês, e aí esse é um momento de dar opinião final de vocês depois do debate. Começar pelo debatedor 1. Não acho que. É o que eu falei no começo, tem pontos positivos, negativos. A gente debateu vários pontos importantes aqui, essa questão da fiscalização tem que tomar bastante cuidado, porque às vezes envolve interesse da instituição ou ou pessoa que está fiscalizando, isso pode acabar, mas acho que a gente debateu pontos importantes e não sei mais o que falar. Minha opinião permanece a mesma, mas gostei de ouvir a opinião de cada um. Pode, pode ser que tenha mudado minha opinião de certa forma, só não sei externar ainda de que forma. OK, debatedor 2. Acho que eu compartilho da mesma opinião do 1, só que eu ainda acho que, acho que tem algumas considerações que eu não falei, que eu ainda acho que fica meramente nesse trabalho repetitivo mesmo. A IA, ela nunca vai conseguir ser ou expressar algo que um humano de fato faz, porque por filosofia das coisas e jeito das coisas serem mesmo, porque a IA, de fato, não tem vontade, nem ela é um ser de fato. Ela, basicamente, um idiota útil muito rápido e que consegue mimetizar dados que as pessoas colocam. Ela até pode meio que desenvolver um falso afeto ou um falso sentimento em algum futuro, mas isso não vai ser de fato algo humano e real. Então, quanto a substituir os humanos, eu acho que isso nunca vai acontecer no fato de intelectualizar e de sentimento e esse tipo de coisa, mas manualmente, provavelmente. Mas é porque muitas coisas que a gente conversou aqui foge um pouco do escopo só IA e vão para escopo como educação, como moral, como ética, e são assuntos de uma forma geral, então não fica só na IA isso, até em relação ao filtro da IA, que, de fato, o sujeito define como verdade ou falso e desse tipo de coisa toda. É meio subjetivo, subjetivista demais tudo isso. Acho que é muito importante esse debate, eu acho até que a gente deve levar isso até nós, enquanto profissionais, né? Da computação, a gente tem que levar esse assunto mais em pauta para a sociedade, tanto pela importância disso quanto por trazer a verdade, porque as pessoas, elas são muito enganadas por fake news e tal. E a gente realmente mostrar o que realmente significa, o que é de verdade, os benefícios que pode trazer e os malefícios, isto vai trazer muito um melhor uso da da plataforma. Eu acho que o IA é muito importante, mas também a gente não pode endeusar tanto a ponto de de achar que que vai substituir o humano e que a gente não tem que usar, que isso daí tem que ser fiscalizado pelo governo, que isso não é bom, não é bom, não é bom. Mas eu também não acho que a gente deva, deva terceirizar todas as nossas responsabilidades, tudo do ser humano, numa inteligência artificial, que é como o 2 falou, existem coisas que só nós, humanos, a gente tem capacidade de fazer. Uma IA, ela pode reproduzir um som, mas ela não vai transmitir a emoção daquela voz, os sentimentos, a mensagem que ela quer passar. Então é realmente foi como a roda para para os primeiros homens aqui, facilitou, ajudou. Então se a gente souber utilizar essa ferramenta de uma forma útil e de uma forma benéfica para a gente, a gente vai ter muitos benefícios. E também eu volto a enfatizar, a criação de diretrizes da própria plataforma para evitar que danos maiores eles possam acontecer, como ferir os danos morais, direitos humanos e todas essas questões que a gente abordou. Debatedor 4. Assim, complementando um pouco do que a 3 disse, eu acho que, principalmente na parte de, pera aí, putz, deu um branco aqui, mas principalmente essa parte de de autoridade e tal, assim, o, como posso colocar em palavra? Deixa eu pensar. O banco de dados da IA sempre vai pegar algo humano, se você ficar só utilizando IA, IA, IA, você não vai ter coisas novas para incrementar nesse próprio banco de IA humanas. Então acho que, assim, é, é o que eu falei no começo e acho que mantenho, a principal pauta da IA é você está pegando uma, uma base de dados autoral e vai mais ou menos reorganizar para criar coisas novas. Então o quão, o quão ético é pegar isso e de outra pessoa e reorganizar? Acho que isso é o principal pauta da IA em relação a, principalmente, entretenimento, basicamente. Mais alguma coisa? Mas então é isso, vou finalizar a gravação agora, tudo certo.\n","A limpeza foi feita em  129.68013620376587\n"]}]},{"cell_type":"markdown","source":["## prompt"],"metadata":{"id":"tlgCwgUS8iY_"}},{"cell_type":"code","source":["prompt_1 = \"\"\"Gravação iniciada. Minha identificação é o número aluno um, estou contribuindo para a pesquisa no Brasil. Minha identificação é aluno 2, estou contribuindo para a pesquisa no Brasil. Minha identificação é a número 3. Estou contribuindo com a pesquisa no Brasil. Minha eficação é o número 4. Estou contribuindo com a pesquisa do Brasil. Minha identificação número 5, estou contribuindo com a pesquisa no Brasil. Excelente. Pois bem, agora eu explicarei as regras deste debate, e então, antes de mergulharmos em nossa discussão, é essencial. Todos compreendam e sigam as reuniões de debate. Essas regras foram ampliadas para garantir um debate justo e ordenado para todos os envolvidos. A única principal regra é: sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando. Se você deseja contribuir para alguma discussão ou oferecer um contra argumento, por favor, levante a mão e aguarde um moderador, no caso eu lhe conceder a palavra, uma vez que tenha sido autorizada a palavra, você terá a palavra e poderá expressar seus pensamentos ou responder aos outros. vamos seguir um formato estruturado dividido em 3 momentos distintos, cada um com seu propósito e regras específicas. No primeiro momento abordaremos a questão principal no debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central. Que foi aquele tema que lhes foi enviado. No segundo momento teremos uma rodada de perguntas direcionadas para cada um dos debatedores. Abriremos espaço para outros participantes contra argumentar, ou espressarem as suas opiniões sobre a resposta dada após as perguntas direcionadas, teremos uma última pergunta que será direcionada a todos os participantes, nesse momento, vocês têm a Liberdade de escolher se desejam responder ou não e só caso tenham algo no caso sintam que tem algo relevante a acrescentar. Por fim, no terceiro momento, será perguntado se os participantes têm alguma outra colocação final sobre o tema. Então cada um de vocês terá esse movimento inicial para expressar suas principais opiniões e pensamentos sobre o tema. E o tema é, esse que aí está e que foi também lhes enviado, então começando do debatedor número 1. Quais são as suas opiniões iniciais sobre o tema? Uma opinião inicial é que, conforme vai crescendo na inteligência artificial e se não for assim, não foi controlado o público que a utiliza, as pessoas vão acabar se dependendo, dependendo de mais dela, por causa de vai acabar usando ela para fazer qualquer coisa na vamos ver, o estudante vai usar a inteligência artificial para fazer as questões por de algum professor e vai acabar não se dedicando para aprender o assunto. Assim vai acabar sendo muito dependente dela e não vai acabar crescendo quase nada, na sociedade. Debatedor número 2. Eu acredito que o uso da da inteligência artificial de forma benigna, pode como o próprio já diz, causar um bem no sentido, por exemplo, aplicativos que utilizam da inteligência artificial, da IA, para produzir, por exemplo, na questão da construção civil, que pode utilizar para a questão de produção de planta baixa ou de outros projetos arquitetônicos nesse sentido olhando essa visão, eu acredito que é um uso com um bem explícito, mas que também depende, por exemplo, do seu uso como o debatedor 1 falou poderia no caso do estudante que ele começa a depender demais da da inteligência artificial, no nosso caso mais atual, por exemplo, o ChatGPT que para responder as perguntas de seja de exercício ou atividades, enfim, começa a depender o uso demasiado da inteligência artificial e pelo contrário não provocam bem a si mesmo. Ele está degenerando a si mesmo. Está seu tá agravando seu processo de de desconstrução de conhecimento, é isso que é isso que eu defendo, é a questão do uso mais moderado. Debatedor número 3. Eu acredito que a IA como qualquer outra tecnologia, ela vai ela vai ser útil para facilitar a nossa vida, mas como nas outras tecnologias, também tem que ser usado de uma da forma certa. Durante a guerra a gente viu que usou a tecnologia para fazer mal para a sociedade, a IA pode ser a mesma, pode ser usado para a mesma coisa e pode fazer um mal para você próprio. Então acho que ela deve ser usada, mas também tem que ser empregado no ponto de como usar ela da maneira certa, tem que ensinar as pessoas a usar da maneira correta. Debatedor número 4 Sinto que é necessário criar uma verificação no que está sendo passada para ela, uma vez que sem um limite eu posso infringir a própria ética no caso de criar, por exemplo, deep face, né? Fake news que é desenvolver né imagens né alteradas, então foi pelo. Acho que é bom é que exista uma evolução na na IA, mas deve ter assim, uma verificação, pra que que está sendo passado para ela não seja nada que infrinja a ética, a moral, como um todo. Debatedor número 5 Bem, eu acredito que esse, na verdade, é um assunto bastante delicado, né? É pessoas de diversas áreas, vão ter opiniões que divergem uma das outras É, mas como qualquer outra coisa, é o seu uso de forma imprópria é pode causar desses problemas, né? Então, é o uso de inteligência artificial, tem que ser definitivamente, tem que ser pensado antes de ser usado, né? Você não pode usar de uma forma indevida, ainda mais que ainda não está dentro de um de uma lei. Se, como você pode usar, como você não pode, então imagino que seja um assunto bem delicado. Pois bem, nós estaremos agora, então a rodada de perguntas, certo? A primeira rodada de perguntas. E nela eu irei realizar uma pergunta para cada um dos participantes, que terá seu tempo de resposta ao final da sua, ao final da sua resposta, onde os demais terão, é espaço para comentar algo sobre a pergunta ou a resposta dada. Então, vamos começar. A primeira pergunta para o levantador número 1. Se o sistema de IA generativo criar algo prejudicial ou ofensivo, por exemplo, uma imagem com conteúdo racista, quem deve ser responsabilizada? Desenvolvedor da IA, o usuário, a plataforma que hospeda com alguma outra instituição pessoa? Debatedor número 1. Acredito que seja um único, acredito que seja o usuário, que seja responsabilizado por causa que como já foi dito, pelo debatedor 3, número 3 a sobre a opinião dele, que a inteligência artificial se for utilizada de forma errada, acaba sendo mais a culpa da pessoa que está usando ela não de alguém que desenvolver, porque a pessoa que desenvolveu a internet artificial fez para com intuito de beneficiar a sociedade. Mas a pessoa que usou o usuário usou de forma errada e acaba fazendo alguma coisa prejudicial. Alguém tem algo a comentar sobre a resposta do debatedor um ou a pergunta em si. Tá, então passemos para a segunda pergunta para o debatedor número 2. IAs generativas podem ser usadas nos processos educacionais, por exemplo, em aulas, atividades ou provas, o ou a aluno ou a aluna deve reportar ao professor ou professora sobre o uso de IAs generativas em suas atividades? Eu acredito que pode ser utilizado sim, como qualquer outra tecnologia, a gente utiliza, por exemplo, em nossas atividades escolares acadêmicas. A questão do do uso da internet, por exemplo em sites de pesquisa,e a gente pode encontrar informações. Como a IA se baseia em um banco de dados gigante eu acredito que nós podemos utilizar no sentido de que podemos utilizá-la como fonte dessas informações, certo? Por exemplo, eu quero pesquisar, supondo, de uma forma bem grotesca sobre a questão da história da do Brasil. Eu Acredito que a IA vai nos fornecer é informações que serão necessárias ou muito importantes para o nosso crescimento, para o nosso crescimento intelectual de conhecimento e outra pergunta, o aluno deve reportar ao professor sobre o uso das IAs generativas em suas atividades? Eu lembro que se Eu Acredito que sim, como qualquer outro banco de dados que nós já vemos referir da onde a gente pegou essas informações. Eu acredito que é necessário também reportar ao professor, ao docente, o da onde a gente tirou essas informações. Alguém gostaria de comentar algo sobre a resposta dada ou a pergunta em si? Então passemos pra pergunta 3, ao debatedor número 3. De que maneira a propriedade intelectual deve ser tratada quando um conteúdo é gerado por uma IA? Por exemplo, se um usuário gerou uma música usando IA, o crédito pela criação deve ser o deste usuário? Da plataforma de IA utilizada? Do criador dos dados originais, com os quais a IA foi treinada? Ou de que?\n"," Não acredito que deva ser da IA porque a IA gerativa, ela é feita como uma base de dados muito gigantesca e ela vai fazer as coisas coisas novas, não vai replicar o que tem, ela vai aprender e vai replicar e vai criar coisas novas. Então, uma criação dela e uma criação de outras pessoas, ela, o crédito deve ser dela. Debatedor número 5 Eu imagino que seja, tenha créditos à inteligência artificial, mas que não totalmente, já que ela utiliza de um banco de dados, possivelmente ela vai estar pegando algo de outra pessoa e reutilizando, é de certa forma, então possivelmente, se você identifica é seus direitos autorais no que ela gerou, eu imagino que é o os direitos autorais você também tenha participação disso. Debatedor número 2. Como o debatedor falou, número 5, ele falou, é como se fosse uma árvore, né? Se a gente puxar, é de onde está havendo as informações sempre vai ter um crédito como ele falou, na questão do do do grande banco de dados, O o artistao músico que está procurando, é, criar uma nova música utilizando a inteligência artificial também deve ter seu crédito de certa forma, mas acredito também tanto os conteúdos é que estão dentro É da IA, do do banco de dados da IA também devem ser procurados de de onde foi que ela utilizou essas informações E, de certa forma, acredito que também até o os criadores do da IA também. Alguém mais, tem algo a comentar sobre a pergunta, sobre as respostas dadas? Não? Então sigamos para a pergunta 4 debatedor número 4. Como garantir que conteúdo gerados por IA não sejam usados para espelhar informações tendenciosas, errôneas ou maliciosas, por exemplo, quando esse tipo de informação é propagada massivamente por bots em uma rede social, a responsabilidade deve ser da empresa que administra a rede social, dos programadores da IA, de quem produziu aquele conteúdo usando a IA?   Eu prevejo que seja de quem produziu aquele conteúdo. Porque não minto minto que seja do da empresa o cara tem domínio né, daquela rede social de propagar aquilo que ela está passando. Então se passa uma informação que ela não consegue verificar, não consegue analisar que é justamente tendenciosa é errônea, né? Como uma imagem, né? Uma fake news, uma, um som, uma até uma, música que passe por assim sem ela perceber essa essa falha, né? Que pode dar na ética. Eu vejo que seja dela a essa essa falha, né não de que ade que a produziu, assim, quem produziu também, mas seria mais ela, que tá propagando. Debatedor 2 Eu Acredito também, assim como o debatedor 4, falou É, tem uma parcela em culpa da empresa em talvez propagar essa esse conteúdo de forma errônea ou de forma é replicada, mas também do próprio usuário que que produziu o conteúdo usando da IA. Acredito que a IA ela Não, não, não tem essa, tanto, essa parcela de culpa que que eu comparo com se fosse o carro, por exemplo, de forma grotesca, claro. Um carro, o criador de um automóvel, no caso ele não pensou naquelas pessoas, talvez muito provavelmente nas pessoas que poderiam utilizálo como 11 veículo de de de rachas na rua, por exemplo. Mas como uma forma de locomoção das pessoas e para um lugar, outros lugares et cetera, et cetera, mas que devido aos seus usuários, por exemplo, nós, quando nós utilizamos OOO nosso automóvel, assumimos essa essa responsabilidade de que, caso venha, venhamos a desrespeitar desrespeitar ou infringir leis de trânsitos, leis de trânsito perdão e assumirmos essas responsabilidades, assumimos essa culpa de talvez provocar um acidente e comparando de forma com o usuário que utiliza essa IA eu acredito que ele também deve ser responsabilizado. Por quê? Porque ele está assumindo de que quando ele produz esse conteúdo, é claro, é evidência evidencialmente vai ser 11 conteúdo é pejorativo, um conteúdo que é traz mal para a sociedade. Debatedor 5 Eu já para mim, eu não imagino que a empresa, a rede social que administra ela seria responsável, já que possivelmente vai haver algum algoritmo ele vai identificar aquilo, claro que existem métodos de filtragem para identificar se se é um, se é uma informação falsa ou não, mas é o algoritmo, só vai repassar para outras pessoas se as pessoas concordarem e curtirem compartilharem, repassarem para outras pessoas, então, eu imagino que é mais das pessoas que veem aquele conteúdo e de quem produziu esse conteúdo É a culpa de informações tendenciosas serem repassadas do que mesmo da responsabilidade da rede social, né? Já que, teoricamente, a rede social não foi feita para isso. Alguém tem algo a comentar sobre o que tinha dito ou sobre a pergunta? Então passemos a quinta pergunta ao debatedor número 5. Quais os impactos da IA no ambiente de trabalho, você acha que o uso de IAs generativas irá gerar ou destruir empregos, por exemplo, uma IA generativa que consegue fazer um trabalho de um arquiteto ou publicitário de forma mais rápida fará um trabalho totalmente confiável. É, eu imagino que E vai existir impactos dessa inteligência artificial, né no mercado de trabalho, mas isso acontece hoje em dia sempre aconteceu com diversas outras coisas existem diversos empregos que não existem mais porque foi criado algo novo, que é melhor, que é superado hoje em dia, por exemplo, não tem mais antigamente tinha um emprego nas naqueles lugares de jogar boliche, tinha um pessoal que organizava os pinos para você jogar de novo. Hoje em dia não é assim, mais não. Esse emprego não existe mais. Então, é enquanto a inteligência artificial estiver sendo é desenvolvida, é claro que você não pode confiar totalmente, né? É preciso que você tenha a é a inspeção de um arquiteto, de um cara que estudou para isso. Possivelmente a inteligência artificial vai ter arquitetos que vão ter, vão estar trabalhando em conjunto com programadores para desenvolver essa inteligência. Então, eu imagino que enquanto a inteligência artificial estiver evoluindo, a tendência é que ela esteja mais e mais confiável E diante disse empregos, se não forem atualizados, se não tiverem mais AA eficácia deixaram de existir. Alguém tem algo a comentar sobre esse ponto ou sobre a resposta dada? Bem, então passamos agora para a pergunta livre. A, lembrando que vocês podem responder ou não. Uso e o desenvolvimento de áreas narrativas devem ser fortemente fiscalizados por órgãos governamentais ou elas são apenas mais um tipo de software comum, como milhares de outros existentes? Debatedor número 5. É bastante adverso. Sim, elas devem ser fiscalizadas, mas não fortemente. Até porque tem que ter algum, alguma parte criativa naquilo, né? Se for totalmente fiscalizado, talvez você trave você pare o desenvolvimento daquilo, que você torne lento. O desenvolvimento disso, se você não corr Claro que a fiscalização é importante/> justamente por outros motivos, direitos autorais, tudo mais, mas é, se for fortemente, é fiscalizado, é A gente vai deixar de evoluir? Basicamente a gente vai deixar de ter um desenvolvimento mais rápido simplesmente por conta que o governo está fiscalizando e ele não deixa por conta N motivos, né? Então, imagino que deve ser fiscalizado, mas até certo ponto. Alguém mais gostaria de responder a pergunta ou comentar sobre o que foi dito? Bem, então agora cada participante terá um momento para falar suas considerações finais sobre o tema, sua opinião ou visão sobre o tema mudou depois do debate? Começando do debatedor número 1, você tem alguma coisa sobre para falar mais sobre o tema? Tem alguma concentração final, senão, você sua ou visão ou opinião mudou sobre o tema de IAs generativas depois do debate? Não. Debatedor 2 Eu acredito, só, para, a título de conclusão final, acredito que a inteligência artificial, assim como qualquer outra tecnologia, assim como na comparação que eu fiz como automóveis, de forma, grotesca, é claro, mas, ela pode auxiliar, ela vai auxiliar a sociedade na criação de, de, na produção de, de n coisas. No entanto, que deve ter assim um cuidado sim, uma fiscalização para que não torne essa, essa produção de forma demasiada ou que acabe por gerar, é, algo algo que não produza benefícios, pelo contrário, produza malefícios para a sociedade na questão, por exemplo, de criação de imagens utilizando fotos de pessoas e aí parece com que uma pessoa está em um canto que não está ou que está fazendo algo que não, nunca fez. Eu acho que isso acredito que isso deve ser considerado na fiscalização da, da IA para que não ocorra, por exemplo, se, se a IA, um usuário utiliza a minha imagem, usando também a IA e coloque a minha imagem como se eu tivesse fazendo algo ilícito. Não, claro que isso traz no benefício para mim, como pessoa, porque eu nunca fiz aquilo, porque eu nunca estive naquele lugar, et cetera, et cetera. Então deve ser fiscalizado sim, para que não ocorra esse tipo de produção. Debatedor 3 Não Debatedor 4 Prevejo que ela é uma ferramenta, uma conquista, na verdade, em toda espaço da, da, da, da computação, por exemplo, e que, sim, é, deve existir, né, uma fiscalização ali, não fortemente, é claro, mas para barrar justamente problemas, pois uma ferramenta como ela, é, ela é aberta ao público, é vai do usuário, né? O seu intuito, né? O que ele quer trazer, o que quer que a IA faça e retorne. Então, para não ter problemas como direitos autorais ou de problemas que infrinjam a ética, então é algo racista, né, algo homofóbico, por exemplo, uma imagem. Eu vejo que tem que ter um, um, limite, né? Um órgão que verifique, né, passe de parâmetro para a IA e o cara retorna. Debatedor 5. Só para finalizar, é, eu imagino que é um conteúdo, é um, é um, é um tema que, é, traz bastante medo na sociedade, né? Principalmente porque, a sociedade em geral, não conhece como a inteligência artificial funciona, o que que ela pode fazer, o que que ela não pode fazer. Então é preciso entender corretamente o que, que ela pode fazer, até onde ela vai chegar, o que é que ela pode te causar. E a partir disso, é a inteligência artificial vai ser mais aceita, né? Principalmente por gerações que já vem, né? E é isso. Então utilizem este QR Code para acessar e responder a um questionário, que é uma avaliação e avaliação geral do debate. Suas respostas são confidenciais e serão usadas para fins de avaliação e aprimoramento. Dito isto, obrigado pela participação de vocês no experimento, iremos fazermos um sorteio de um brinde no final de todos os experimentos. Fiquem atentos, portanto, ao e-mail que vocês cadastraram no formulário de inscrição.\n","\"\"\""],"metadata":{"id":"P1IEUrGB7v6M","executionInfo":{"status":"ok","timestamp":1725287815371,"user_tz":180,"elapsed":8,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Prompt 1.2 (Zero-shot some context)\n","\n","\n","\n"],"metadata":{"id":"UWQ8xRwaE6f6"}},{"cell_type":"code","source":["prompt = f\"\"\"\n","The following Portuguese text was generated using an STT (Speech To Text) model from a debate recording. Such transcriptions often contain unwanted elements known as disfluencies, which include:\n","\n","- **Repetitions**: These occur when a word or phrase is repeated consecutively without adding any new meaning or value to the sentence. Repetitions are often present in speech but they do not contribute any additional information to the context. For example, in the phrase \"o ambiente da da tecnologia,\" the word \"da\" is repeated twitce without adding anything meaningful to the sentence, only one occurence of \"da\" would be sufficient to get what the phrase is trying to transmit.\n","\n","- **Hesitations**: These are non-verbal expressions or fillers used in speech to indicate a pause or hesitation. Common hesitations include sounds like \"ahh,\" \"ehh,\" \"um,\", \"hmm\" or \"uh.\" They serve as verbal placeholders while the speaker thinks or searches for the right words. Although they can indicate thought processes, they do not add substantive meaning to the text and should be removed for clarity. For example, in the phrase \"Eu estava, ahh, pensando sobre isso,\" the term \"ahh\" is a hesitation that can be removed.\n","\n","- **Corrections**: These occur when a speaker makes an initial error in their speech and then corrects it. The correction typically involves an initial incorrect phrase followed by a revised version of the same phrase. For instance, in the phrase \"que isso é, quer dizer, isso foi,\" the speaker initially says \"que isso é,\" makes a correction by saying \"quer dizer,\" and finally provides the corrected phrase \"isso foi.\" The goal is to remove the error, leaving only the final corrected version.\n","\n","Please remove these disfluencies from the text without altering the original meaning. You should NOT change text that does not refer to disfluencies. ANY text that is not in one of those three categories of disfluencies should not be changed. Return only the cleaned text with no additional information. Remember the text must be in its original full size, but without the disfluencies in it.\n","\n","\n","Text: {texto_disfluente}\n","\"\"\"\n","\n","response2, duration2 = get_response_and_time(prompt)\n","\n","print(response2.text)\n","print('A limpeza foi feita em ', duration2)"],"metadata":{"id":"uR556RKZE-Ut","executionInfo":{"status":"ok","timestamp":1725287943453,"user_tz":180,"elapsed":128087,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"4667d539-e93e-48f8-d7de-3fc5933b1204"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Vamos lá, é boa tarde todo mundo. Bem-vindos a este debate promovido pelo grupo de pesquisa do lacina debate em educação. Eu me chamo David e gostaria de apresentar aqui, quem está comigo, Klaywert que também faz parte do grupo. Mas aí a gente tem também Bryan e Hellen, que são, tirando Hellen, a maioria estudante do mestrado, Hellen é estudante da graduação. E esse projeto está sobre orientação do professor Campelo, que é o professor que vocês conhecem que vocês conheceram agorinha, que vocês viram agora, certo? Ok, a razão pela qual nos reunimos aqui hoje é gerar uma base de dados de voz que posteriormente será transcrita e utilizada para avaliação e treinamento de modelos de inteligência artificial. Nosso foco está entre vários tópicos relacionados a debates, fazendo dessa iniciativa não apenas oportunidade de aprendizado e crescimento, mas também uma contribuição valiosa para avanço de IA. \n","Vocês assinaram o termo, né? Todo mundo já assinou o termo, então a gente pode pular essa parte. Cada debatedor vai receber uma identificação, né? Vocês já receberam e essa vai ser a identificação de vocês, como os debatedores, aqui a gente não estava interessado nos dados pessoais de vocês, então o processo vai ser identificado dessa forma com esses IDs, certo? A gente vai gravar a voz de vocês. Minha identificação número um. Estou contribuindo com a pesquisa no Brasil. Minha identificação número dois, estou contribuindo com a pesquisa no Brasil. Minha identificação número três, estou contribuindo com a pesquisa no Brasil. Minha identificação número quatro, estou contribuindo com a pesquisa no Brasil. É, explicando as regras do debate. Antes da gente começar o debate, é essencial que todos compreendam e sigam as regras do debate, essas regras foram criadas para garantir um debate justo e ordenado para todos os envolvidos. Primeira regra: sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando. Se você deseja contribuir para a discussão, oferecer algum contra argumento, por favor, levante a mão e aguarde o moderador, eu, lhe conceder a palavra, uma vez que tenha sido autorizado a falar, você terá a palavra, poderá expressar seus pensamentos e responder aos outros também.\n","Certo, explicando o funcionamento do debate, vamos seguir em formato estruturado de três momentos distintos, cada um com seu propósito e regras específicas. Momento um: expressão inicial de suas opiniões. No primeiro momento, abordaremos a questão principal do debate e objetivo é que cada participante expresse sua opinião inicial sobre o tema central. Momento dois: rodada de perguntas. Num segundo momento teremos uma rodada de perguntas direcionada para cada um dos debatedores, abriremos espaço para os outros participantes contra argumentarem ou expressarem suas opiniões sobre a resposta dada. Após as perguntas direcionadas, teremos uma outra pergunta, que será direcionadas a todos os participantes, neste momento, vocês terão a liberdade de escolher se desejam responder, caso que tenha algo relevante a acrescentar. No momento três: colocações finais, um terceiro e último momento, será perguntado se os participantes têm alguma outra colocação final sobre o tema.\n","Certo? Ok, então a gente vai começar agora. Ficou alguma dúvida antes de tudo? Deu para entender. Vão ser três momentos o debate, então, vai ser um debate semi estruturado, se alguém quiser falar, tem que pedir a vez, não pode estar interrompendo o outro e é basicamente essas regras que vocês devem seguir e a gente vai ter umas perguntas para nortear o debate também, que eu vou mostrar, vou botar ali na tela e vou ler para vocês também essas perguntas, Ok?\n","Certo, como vocês já sabem, o nosso tema é inteligência artificial generativa e seus impactos na sociedade. Ok? Para começar, primeiramente, cada um terá um momento inicial para expressar seus principais, cada opiniões e pensamentos sobre o tema, cada participante terá um momento para fazer isso, certo? Vamos começar com o debatedor 1, você gostaria de expressar a sua opinião? De forma geral, o que é que você pensa sobre o tema? Bom, as IAs generativas são bem dizer uma faca de dois gumes, né? Tem aspectos positivos e muito negativos também, positivos tem automação de algumas atividades, pode auxiliar como ferramenta complementar em estudos, como negativa, tem a questão de proteção de dados, de autenticidade de resposta, infração de direitos autorais. Então, dependendo da área do argumento que quiser seguir, pode ser positivo ou negativo. Agora o debatedor 2, olha em relação a os impactos positivos que as coisas repetitivas vão ser ao longo do tempo eliminadas, alguns trabalhos que precisam de muita repetição e o que meio que vai ficar, acho que produção intelectualizada que a IA não consegue fazer bem, inclusive os modelos atuais em relação a opiniões também e também ele não, ele tem um filtro muito grande, então acho que deve, desde que não infrija nenhuma lei, deve ter maior liberdade de criação. Os negativos, eu acho que problemas como o deep fake e geração de voz também pelo timbre. Eu acho que vai ser um problema muito grande para as autoridades lidar e fazer contra medidas que reconheçam se aquilo é de fato verdade ou não, e meio que impulsiona a desinformação em relação a estudo também, eu acho que tende a, dependendo da base de dados, ou a piorar a situação ou a melhorar, então acho que no futuro a especificação das IAs não ser um aí a geral, ser mais nichado é com os vetores de informação, vai vir a melhorar esse problema de espalhar mentiras. Debatedora três: É, embora esse seja um assunto, um conteúdo que já venha sido tratado há muito tempo, várias pessoas já tenham trabalhado nisso, ultimamente está tendo uma uma abordagem maior sobre isso. Acho que até depois do do chat GPT ter vindo, né? E aí o pessoal ficou sabendo muito. Eu, por exemplo, quando eu não tinha esse conhecimento, eu não sabia da existência das IAs nesse sentido. Nesse aspecto, depois que eu conheci o chat, eu consegui compreender mais e como os meninos falaram, ele tem aspectos muito positivos, e justamente pela pela automação, pela facilidade, pela agilidade, mas eu acho também que os usos negativos dele pode impactar também na autenticidade do próprio ser humano, como o texto diz, mesmo a criatividade, a humanização, os textos por exemplo, quando a gente vai ver no TikTok e o pessoal está usando aquelas vozes fakes, tem são, são a voz que você jura que é uma pessoa real, só que não tem as expressões e eu acho que um expressão de ironia, de sarcasmo, que o ser humano ele consegue ter, isso é algo do ser humano, menos a IA, não consegue obter. Então eu acho que pode ser útil, sim, para facilitar a nossa vida mesmo, mas não com um substituto de coisas que só o ser humano consegue fazer. Debatedor cinco, quatro, sobre as IAs, assim, acho que o principal mesmo é em relação ao trabalho que vai ser, que não tem como você lutar contra esse crescimento da IAs em relação à substituição de empregos. É algo desde a revolução industrial, até antes que a tecnologia sempre vai substituir o ser humano e algo que é, não pode ser parado. Sobre regulamentação, etc. Eu acho que o principal ponto, na minha opinião, é sobre o uso de banco de dados de com direitos autorais para geração de novas coisas, porque a maioria da das vezes que nesses essas IAs gerativas usam banco de dados de coisas já existentes, como por exemplo, desenhos, já vozes e etc, para criar novas coisas. Então acho que a pauta na legalização de IAs vai ser principalmente nessa área de você poder ou não usar o desenho de alguém para gerar novos desenhos, e etc. Certo, vamos iniciar com a rodada de perguntas. Irei realizar uma pergunta para cada participante que terá seu tempo de resposta e ao final de sua resposta, os demais podem pedir espaço para comentar algo sobre a pergunta feita ou a resposta dada? Ok, vamos começar. A primeira pergunta é para o debatedor 1, se um sistema de IA generativa cria algo prejudicial ou ofensivo, por exemplo, uma imagem com conteúdo racista. Quem deve ser responsabilizado? O desenvolvedor da IA, o usuário, a plataforma a plataforma que hospeda ou alguma outra instituição ou pessoa. O autor do texto da plataforma que hospeda, a plataforma e quase sempre o desenvolvedor da Ia, porque querendo ou não, é ele que criou a ferramenta para conseguir filtrar o que ela deve ou não buscar, porque realmente, com o as IAs, elas podem perpetuar preconceitos e estereótipos, porque eles fazem o filtro e podem, nesses textos que elas estão filtrando, acabar inserindo no texto que ela vai enviar para o usuário certas falas que não são adequadas no na sociedade atual. Alguém tem algo a comentar sobre a resposta do debatedor? Mais alguém tem alguma outra colocação sobre essa pergunta específica que queira comentar? Pode dizer. Às vezes o banco de dados da IA que que traz para a própria IA, às vezes já vem com alguns dados que que podem ser preconceituosos, seja racistas ou sexistas, e etc. Às vezes isso já vem do próprio banco de dados, que gera novos dados que também são racistas, sexistas, etc. Acho que na minha na minha visão. Então tu acha que a pessoa culpada seria quem introduziu o dado? Não, eu não acho que a pessoa culpada seria que produziu o dado assim, não sei sinceramente, eu teria que pensar um pouco mais para saber quem seria punido nessa daí, porque realmente dentro das opções ali, eu pensei a Pri, a priori, eu pensei no usuário, mas também o desenvolvedor. A plataforma pode inclinar o dado a sair como como algo racista ou sexista, por exemplo, eu acho que é, seria mais ou menos como se fosse a política do Instagram que tem aquele filtro de palavras negativas e ofensivas que você usa em comentários que justamente já pela consciência de que isso pode ocorrer. Tanto o desenvolvedor já cria esse filtro, essas diretrizes de de política, de respeito, de direitos humanos e tal, essas coisas, quanto também do usuário, assim, ele que ele escrever já ter, tipo um bloqueio para para isso não acontecer. Tanto a consciência do usuário para estar pesquisando essas coisas quanto do desenvolvedor. Só para fazer um adendo minha resposta, falei que podia punir plataforma que hospeda, mas desde que, por exemplo, vamos supor seja um site de crônicas, aí a pessoa tem autoridade dentro do site. Agora, se for, por exemplo, um reddit, um fórum de discussão, aí eu já acho que não deva responsabilizar a plataforma e sim fazer como a debatedora 3 falou e fazer a questão do filtro antes da mensagem ser enviada, já evita problemas posteriores. A culpa maior seria de usuário, em si, da pessoa? Sim. Pode dizer debatedor 4. Porque também varia muito do conteúdo que está sendo gerado. Por exemplo, um texto é algo um pouco mais direto. Agora, uma imagem, um dado às vezes pode ser um pouco mais indireto, mais sutil, esse preconceito. Eu acho que o principal responsabilidade deve ser o usuário. Eu acho que o desenvolvedor da IA, ele não, assim a gente sabe que o usuário muitas vezes ele é muito criativo em quebrar as coisas. Então, se uma IA é muito generalista, talvez o usuário seja muito criativo em fazer com que esse conteúdo seja produzido. Então eu acho que é meio que foge um pouco do escopo do que o desenvolvedor consegue ou não pensar. Porque assim, desde que a internet é internet, tem gente só pensando em como quebrar aquela coisa que está disposta ali, então eu acho que o principal problema é o usuário e não o desenvolvedor. É a mesma coisa de ter um carro e usuário do carro meio que o motorista decidir se ele vai sair batendo em tudo ou vai seguir o fluxo normal, acho que é basicamente isso. Até porque o propósito desse dessa IA criada pelo desenvolvedor é auxiliar, trazendo manutenção, facilidade para a pessoa de modo benéfico. Então seria realmente culpa do usuário o mau uso do do da plataforma. Então, por isso que seria necessário, justamente por causa de, talvez não fosse necessário se o usuário não fizesse isso, mas como a gente sabe que isso já é um histórico muito grande de que as pessoas usam isso para quebrar as regras, então seria necessário já uma umas diretrizes para evitar que esse problema viesse acontecer, que a culpa, o pessoal iria culpar a marca também, né? A plataforma em si. Alguém tem mais alguma coisa a comentar? Certo, vamos para a pergunta 2. Para o debatedor 2, IAs generativas podem ser usadas nos processos educacionais, por exemplo, em aulas, atividades ou provas. O ou a aluna devem reportar o professor sobre o uso de IA generativa em suas atividades. São duas perguntas, né, não três no caso, a primeira, eu acho que sim. Pode ajudar mais do que atrapalhar, desde que seja usado da forma correta. Inclusive acho que está tendo um movimento na academia. Acho foi que uma professora está falando que estão desenvolvendo papers para que isso seja incentivado e não desincentivado como foi em um primeiro momento, porque é mais pelo uso mesmo do usuário, porque tem gente que só coloca lá e pede para ele já vim na resposta direta, mas se você, por exemplo, às vezes eu até uso isso, você coloca a sua resposta para ele incrementar algo, ou então fazer com que ele mude a forma como aquilo está sendo visto e na maioria das vezes funciona, então isso agrega conhecimento. Se for uma coisa que parta de você, mas se você só manda ele fazer e meio que você só copia e cola, isso não tem conhecimento nenhum sendo gerado. Então acho que pode sim responder a segunda pergunta também em aulas, atividades e provas, fica até mais dinâmica, eu acho, não fica algo muito engessado, como normalmente o ensino tradicional é, e eu acho que deve reportar sim, também para o professor ter ciência de que aquilo está sendo usado e como isso foi usado, inclusive se você perguntar, pegar uma resposta pronta da inteligência artificial e devolver para ele perguntar se ela foi que ela fez isso, se eu me engano, ela diz que foi ela, então acho que sim. Alguém tem algum comentário sobre a resposta do debatedor 2? Só um ponto bem assim, simples no negócio específico que ele falou, ele falou que se você colocar uma resposta que a IA gerou, ela responde que foi ela que fez, mas assim isso é algo também que ainda está um pouco um pouco em desenvolvimento, porque existe, por exemplo, certas respostas criadas por humanos que se colocar, por exemplo, no chat GPT, ele disse que foi ele que fez, então ainda é uma coisa um pouco falha, que eu acho que tem que se melhorar. Tem algo a comentar sobre a resposta dele? Não, eu acho que é isso mesmo, até porque está tudo meio que começando, ainda está dando os primeiros passos, então normal ter falhas e imprecisões. Também acho que ela pode ser utilizada, estava vendo no fórum da do IF de Santa Catarina, o professor de lá falou que podia ser usado na discussão do assunto, porque às vezes você joga lá uma pergunta e ele pode responder uma coisa que não tem sentido com a realidade. Ele quando vai filtrar lá, ele pode acabar criando uma teoria, entre aspas, que não existe. Ele falou que a pessoa fala assim: \"É mais interessante você focar na pergunta da qualidade, na qualidade da pergunta que você vai fazer para IA do que a resposta em si que ela vai dar, que ajuda a ampliar a discussão dentro do diálogo dentro da sala\". Infelizmente a gente sabe que no mundo atual, a maioria das pessoas usam só para obter uma resposta pronta, mas se fosse usado, se a gente tivesse no mundo ideal, ajudaria muito nos processos de estudo. Ajudaria nos processos de estudo porque como ele é, como a IA junta, agrupa vários complementos, vários conteúdos, seria uma fonte muito rica de informação, de conteúdo, de exercício e tudo mais que fosse complementar. Então, para ser aplicado nas escolas, eu acho que seria muito bom os professores, por exemplo, criarem diretrizes também de da forma como eles deveriam deveriam usar também com penalidades, se fosse criar resposta pronta, porque é muito, muito bom, é algo realmente uma uma, a gente tem a faca e o queijo que pode muito bem facilitar e ajudar no nosso processo acadêmico, como também pode prejudicar, porque um aluno que só pega resposta pronta do do chat GPT, ele pode tirar nota muito boa, mas ele não vai ser um bom aluno, bom profissional, porque ele só está copiando aquilo que não foi ele que fez e o ensino, ele não é baseado nisso. Então se se a gente souber realmente usar da forma correta, o, a IA, ela é muito, muito promissora na educação. Alguém tem mais algo a comentar? Vamos para a terceira pergunta para o para a debatedora 3, de que maneira a propriedade intelectual deve ser tratada quando o conteúdo é gerado por IA, por exemplo, se um usuário gerou uma música usando IA, o crédito pela criação deve ser deste usuário, da plataforma de IA utilizada ou do criador dos dados originais com os quais a IA foi treinada? No caso, a IA aplicada da mesma forma que um agrupamento de de conteúdo com musica, por exemplo? Entendi, eu não sei, eu não tenho opinião formada sobre isso porque imagem, a pessoa só colocou, só escreveu o texto e ela gerou lá um agrupamento de várias coisas, mas a criatividade ela é a junção de várias ideias juntas. Então não tem nada de novo e extraordinário. É tudo coisas que já foram criadas, então se é a pessoa criou uma música usando o IA, eu acho que o crédito pode ser dela, mas não totalmente, não tenho uma opinião formada sobre isso. Alguém tem algo a comentar sobre a resposta dela? Sobre a parte do do criador dos dados originais com o qual a IA foi treinada, eu acho que assim, varia muito assim. É a principal questão, na minha opinião, porque se você for ver os dados que foi treinado a IA, muitas vezes você pega, tenta pegar o, puts pera aí, tenta gerar alguma coisa com a IA e a maioria das vezes é só os dados originais, só que embaralhados. Então assim, é grande parte dos dados originais que é criado essas essas novas coisas. Então. Então você acha que é o direito autoral é do dado original? Se for, se o banco de dados foi, foi, por exemplo, só de um autor, eu acho que sim. É que nem o cover, a gente, o cover de uma música, ela tem uma forma diferente, pode até usar, você usa as mesmas notas e tals, usar instrumento diferente, tem um estilo diferente. Só que a música original é do do cantor que do do cantor, do compositor que escreveu aquela música. Acho que tem a mesma, o mesmo significado. Alguém tem algo a comentar sobre a resposta, sobre a pergunta? Tá, vamos para a pergunta 4, então, para o debatedor 4. Como garantir que conteúdos gerados por IA não sejam usados para espalhar informações tendenciosas, errôneas ou maliciosos, por exemplo, quando este tipo de informação é propagada maximamente por bots em uma rede social, a responsabilidade deve ser da empresa que administra a Rede Social, dos programadores da IA ou de quem produziu aquele conteúdo usando a IA. Tá, vamos lá. Acho que a primeira parte é como garantir que esses esses conteúdos são, são reguladas, são não são espalhados, são contidos. Eu acho que criando mais tecnologia para prever isso, uma IA que por exemplo, vê se é ver se a informação é verdadeira, ver se há se alguma coisa é um deep fake ou algo do tipo ou e acho que na parte da responsabilidade, são um pouco da rede social que sempre tem que melhorar a sua parte de segurança de análise para ver se é um bot ou não, e etc, mas eu acho que, principalmente da parte de do quem produziu o conteúdo também, porque produziu um conteúdo falso, obviamente você está querendo que se querendo fazer uma coisa que não é dentro das partes legais, na minha opinião. Alguém tem algo a comentar sobre a resposta que ele deu? Além da de quem produziu ser responsabilizado, eu acho que também a rede social, porque quase tudo que a gente entra hoje em dia tem aquele caption, né, que é meio para evitar isso e também algumas redes sociais também fazem, inclusive acho que o tipo o WhatsApp fez isso que limita as mensagens ou quantidade de mensagens que você manda. Então meio que se foi disparado massivamente, então o canal de por onde isso foi espalhado e também tem uma certa culpa de não ter segurança o suficiente para isso. Alguém tem mais algo a comentar? Assim, eu concordo com isso, que também a empresa que administra tem um pouco de culpa, mas também do mesmo jeito que é a empresa vai se melhorando para é vigiar isso, os bots também vão melhorando, porque muitas vezes criam-se bots orgânicos que se parecem ser perfis de pessoas, etc, que, por exemplo, não são, não é um bote que manda várias mensagens. São vários bots que vão individualmente mandando mensagens, que assim cria-se várias várias, uma compartilhação massiva de fake news. Acho que, obviamente, a rede docial tem também um pouco de parte da da culpa, mas também não dá para se culpar grande parte dela, porque é é é algo que é o é o gato e rato, um vai caçar e sempre o outro vai ter que conseguir escapar. Não só, só para complementar, quando tem notícia assim, falsa, espalhada, principalmente que eu vejo no Twitter e no Instagram. De vez em quando o Instagram, mas é mais no Twitter, tem uma tarjazinha que alguém verificado, uma autoridade sobre o assunto, coloca se é falso ou verdadeiro e a descrição do que porque é falso ou verdadeiro. No Instagram eu vi isso, mas foi mais no período eleitoral, no Twitter, é mais assuntos gerais assim. Alguém tem mais alguma colocação? Nessa parte da do de tarjas e e etc. Assim, no Twitter, eu eu sei que é por parte dos próprios usuários, ou seja, não é algo algo que a rede social administra, são os próprios os próprios usuários que regulam os próprios usários que muitas vezes os usuários que regulam não estão também certos. Eu já vi, por exemplo, tarjas que são falsas e que a, aí sim, a rede social tem que estar na culpa de ver se é verdadeiro ou não. Alguém tem mais algo a comentar? Não, ok. Nesse último momento, vou passar para uma pergunta que essa pergunta é geral, é livre e todo mundo pode responder, não é direcionada a ninguém, certo? O uso e desenvolvimento de IAs generativas devem ser fortemente fiscalizados por órgãos governamentais ou elas são apenas mais um tipo de software comum, como milhares de outras existências? Alguém quer responder? Eu acho que se o governo tem que meter a mão, eu acho que ele tem que meter a mão meio que de longe, não incisivamente, porque como assim, isso também, como eu estava falando, vai atrapalhar a liberdade criativa da IA, e de quem cria essas IA, além de que vai ficar algo muito burocrático e muito ineficiente. Não vai, acho que aflorar muito, se falar de Brasil, especificamente do Brasil, acho que países que tendem a ter uma liberdade maior para os desenvolvedores meio que vai desenvolver mais esse conceito e essa ferramenta IA generativa. Então eu acho que sim, é tipo mais um software como qualquer outro, mas se for para fiscalizar, que seja meio que punitivamente e não fiscalizar de fato a produção e meter a mão na produção e esse tipo de coisa. Alguém tem algo a comentar sobre a resposta que ele deu? É sobre sobre os direitos humanos, né? Eu vou utilizar essa essa plataforma para, enfim, como naquela pergunta de algo algo racista, sexista ou algo assim, não precisa de ser uma coisa estrita, até porque, por exemplo, o Instagram não tem um artigo na Constituição sobre como a gente deve usar o Instagram, existe as diretrizes da própria da própria plataforma, sobre como aquele aplicativo deve funcionar, o que é que a gente pode ou não pode fazer? Então eu acho que deveria ser fiscalizado como ele disse, de longe assim no sentido de a ferir direitos humanos, mas também as diretrizes, enfatizar as diretrizes criadas pela própria plataforma como um filtro e regras mesmo de como aquela plataforma deve ser utilizada, que é até então, nesse primeiro momento como ela é nova, ainda está muito liberal assim, então a gente está vendo, está vendo como as coisas vão acontecendo, que vai ser necessário mesmo ter mais um algo mais regrado, não é ditatoriamente, mas de forma a manter a passividade. Alguém tem mais alguma coisa a comentar? Sobre a pergunta, sobre a resposta que ela deu. Certo, agora a gente vai ter outro momento que é da mesma forma que vocês deram a opinião inicial de vocês no debate, agora quero opinião final de vocês. Se vocês acham que tem algo a apresentar, acrescentar, eu vou passar a palavra, cada um de vocês e aí esse é um momento de dar opinião final de vocês depois do debate, começar pelo o debatedor um. Não acho que. É o que eu falei no começo, tem pontos positivos, negativos. A gente debateu vários pontos importantes aqui, essa questão da fiscalização, tem que tomar bastante cuidado, porque às vezes envolve interesse da instituição ou ou pessoa que está fiscalizando, isso pode acabar, mas acho que a gente debateu pontos importantes e não sei mais o que falar, minha opinião permanece a mesma, mas gostei de ouvir a opinião de cada um. Pode, pode ser que tenha mudado minha opinião de certa forma, só não sei externar ainda de que forma. Ok, debatedor 2. Acho que eu compartilho da mesma opinião do um, só que eu ainda acho que acho que tem algumas considerações que eu não falei que eu ainda acho que fica meramente nesse trabalho repetitivo mesmo, a IA ela nunca vai conseguir ser ou expressar algo que um humano de fato faz, porque por filosofia das coisas e jeito das coisas serem mesmo, porque a IA de fato não tem vontade, nem ela é um ser de fato, ela basicamente um idiota útil, muito rápido e que consegue mimetizar dados que as pessoas colocam, ela até pode meio que desenvolver um falso afeto ou um falso sentimento em algum futuro, mas isso não vai ser de fato algo humano e real. Então, quanto a substituir os humanos, eu acho que isso nunca vai acontecer no no fato de intelectualizar e de sentimento e esse tipo de coisa, mas manualmente, provavelmente, mas é porque muitas coisas que a gente conversou aqui foge um pouco do escopo só IA e vão para escopo como educação, como moral, como ética e são assuntos de uma forma geral, então não fica só na IA isso, até em relação ao filtro da IA, que de fato, o sujeito define como verdade ou falso e desse tipo de coisa toda é meio subjetivo, subjetivista demais tudo isso. Acho que é muito importante esse debate, eu acho até que a gente deve levar isso até nós enquanto profissionais, né? Da computação, a gente tem que levar esse assunto mais em pauta para a sociedade, tanto pela importância disso quanto por trazer a verdade, porque as pessoas, elas são muito enganadas por fake news e tal e a gente realmente mostrar o que realmente significa, o que é de verdade, os benefícios que pode trazer e os malefícios. Isto vai trazer muito um melhor uso da da plataforma. Eu acho que o IA é muito importante, mas também a gente não pode endeusar tanto a ponto de de achar que que vai substituir o humano e que a gente não tem que usar, que isso daí tem que ser fiscalizado pelo governo, que isso não é bom, não é bom, não é bom, mas eu também não acho que a gente deva deva terceirizar todas as nossas responsabilidades, tudo do ser humano numa inteligência artificial, que é como o o 2 falou, existem coisas que só nós, humanos, a gente tem capacidade de fazer, uma IA ela pode reproduzir um som, mas ela não vai transmitir a emoção daquela voz, os sentimentos, a mensagem que ela quer passar. Então é realmente foi como a roda para para os primeiros homens aqui, facilitou, ajudou, então se a gente souber utilizar essa ferramenta de uma forma útil e de uma forma benéfica para a gente, a gente vai ter muitos benefícios e também eu volto a enfatizar, a criação de diretrizes da própria plataforma para evitar que danos maiores eles possam acontecer, como ferir os danos Morais, direitos humanos e todas essas questões que a gente abordou. Debatedor 4: Assim, completamente um pouco do que a 3 disso, eu acho que, principalmente na parte de, pera aí, putz, deu um branco aqui, mas principalmente essa parte de de autoridade e tal, assim o, como posso colocar em palavra? Deixa eu pensar. O banco de dados da IA sempre vai pegar algo humano, se você ficar só utilizando IA IAI IA, você não vai ter coisas novas para incrementar nesse próprio banco de IA humanas. Então acho que assim é é o que eu falei no começo e acho que mantenho, a principal pauta da IA é você está pegando uma uma base de dados autoral e vai mais ou menos reorganizar para criar coisas novas. Então o quão, o quão ético é pegar isso e de outra pessoa e reorganizar, acho que isso é o principal pauta da IA, em relação a principalmente entretenimento, basicamente. Mais alguma coisa? Massam. Então é isso, vou finalizar a gravação agora, tudo certo.\n","\n","A limpeza foi feita em  128.02785682678223\n"]}]},{"cell_type":"markdown","source":["## prompt"],"metadata":{"id":"1f4c3_qd8lIr"}},{"cell_type":"code","source":["prompt2 = \"\"\"Gravação iniciada. Minha identificação é o número aluno um, estou contribuindo para a pesquisa no Brasil. Minha identificação é aluno 2, estou contribuindo para a pesquisa no Brasil. Minha identificação é a número 3. Estou contribuindo com a pesquisa no Brasil. Minha eficação é o número 4. Estou contribuindo com a pesquisa do Brasil. Minha identificação número 5, estou contribuindo com a pesquisa no Brasil. Excelente. Pois bem, agora eu explicarei as regras deste debate, e então, antes de mergulharmos em nossa discussão, é essencial. Todos compreendam e sigam as reuniões de debate. Essas regras foram ampliadas para garantir um debate justo e ordenado para todos os envolvidos. A única principal regra é: sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando. Se você deseja contribuir para alguma discussão ou oferecer um contra argumento, por favor, levante a mão e aguarde um moderador, no caso eu lhe conceder a palavra, uma vez que tenha sido autorizada a palavra, você terá a palavra e poderá expressar seus pensamentos ou responder aos outros. Vamos seguir um formato estruturado dividido em 3 momentos distintos, cada um com seu propósito e regras específicas. No primeiro momento abordaremos a questão principal no debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central. Que foi aquele tema que lhes foi enviado. No segundo momento teremos uma rodada de perguntas direcionadas para cada um dos debatedores. Abriremos espaço para outros participantes contra argumentar, ou espressarem as suas opiniões sobre a resposta dada após as perguntas direcionadas, teremos uma última pergunta que será direcionada a todos os participantes, nesse momento, vocês têm a Liberdade de escolher se desejam responder ou não, e só caso tenham algo no caso sintam que tem algo relevante a acrescentar. Por fim, no terceiro momento, será perguntado se os participantes têm alguma outra colocação final sobre o tema. Então cada um de vocês terá esse movimento inicial para expressar suas principais opiniões e pensamentos sobre o tema. E o tema é, esse que aí está e que foi também lhes enviado, então começando do debatedor número 1. Quais são as suas opiniões iniciais sobre o tema? Uma opinião inicial é que, conforme vai crescendo na inteligência artificial e se não for, não foi controlado o público que a utiliza, as pessoas vão acabar se dependendo, de mais dela, por causa de vai acabar usando ela para fazer qualquer coisa na, vamos ver, o estudante vai usar a inteligência artificial para fazer as questões por, de algum professor e vai acabar não se dedicando para aprender o assunto. Assim vai acabar sendo muito dependente dela e não vai acabar crescendo quase nada, na sociedade. Debatedor número 2. Eu acredito que o uso da inteligência artificial de forma benigna, pode como o próprio já diz, causar um bem no sentido, por exemplo, aplicativos que utilizam da inteligência artificial, da IA, para produzir, por exemplo, na questão da construção civil, que pode utilizar para a questão de produção de planta baixa ou de outros projetos arquitetônicos nesse sentido olhando essa visão, eu acredito que é um uso, com um bem explícito, mas que também depende, por exemplo, do seu uso como o debatedor 1 falou poderia no caso do estudante que ele começa a depender demais da inteligência artificial, no nosso caso mais atual, por exemplo, o ChatGPT que para responder as perguntas de seja de exercício ou atividades, enfim, começa a depender o uso demasiado da inteligência artificial e pelo contrário não provocam bem a si mesmo. Ele está degenerando a si mesmo. Está seu tá agravando seu processo de de desconstrução de conhecimento, é isso que é isso que eu defendo, é a questão do uso mais moderado. Debatedor número 3. Eu acredito que a IA como qualquer outra tecnologia, ela vai ela vai ser útil para facilitar a nossa vida, mas como nas outras tecnologias, também tem que ser usado de uma, da forma certa. Durante a guerra a gente viu que usou a tecnologia para fazer mal para a sociedade, a IA pode ser a mesma, pode ser usado para a mesma coisa e pode fazer um mal para você próprio. Então acho que ela deve ser usada, mas também tem que ser empregado no ponto de como usar ela da maneira certa, tem que ensinar as pessoas a usar da maneira correta. Debatedor número 4 Sinto que é necessário criar uma verificação no que está sendo passada para ela, uma vez que sem um limite eu posso infringir a própria ética no caso de criar, por exemplo, deep face, né? Fake news que é desenvolver né imagens né alteradas, então foi pelo. Acho que é bom é que exista uma evolução na na IA, mas deve ter assim, uma verificação, para que que está sendo passado para ela não seja nada que infrinja a ética, a moral, como um todo. Debatedor número 5 Bem, eu acredito que esse, na verdade, é um assunto bastante delicado, né? É pessoas de diversas áreas, vão ter opiniões que divergem uma das outras É, mas como qualquer outra coisa, é o seu uso de forma imprópria é pode causar desses problemas, né? Então, é o uso de inteligência artificial, tem que ser definitivamente, tem que ser pensado antes de ser usado, né? Você não pode usar de uma forma indevida, ainda mais que ainda não está dentro de um de uma lei. Se, como você pode usar, como você não pode, então imagino que seja um assunto bem delicado. Pois bem, nós estaremos agora, então a rodada de perguntas, certo? A primeira rodada de perguntas. E nela eu irei realizar uma pergunta para cada um dos participantes, que terá seu tempo de resposta ao final da sua, ao final da sua resposta, onde os demais terão, é espaço para comentar algo sobre a pergunta ou a resposta dada. Então, vamos começar. A primeira pergunta para o levantador número 1. Se o sistema de IA generativo criar algo prejudicial ou ofensivo, por exemplo, uma imagem com conteúdo racista, quem deve ser responsabilizada? Desenvolvedor da IA, o usuário, a plataforma que hospeda com alguma outra instituição pessoa? Debatedor número 1. Acredito que seja um único, acredito que seja o usuário, que seja responsabilizado por causa que como já foi dito, pelo debatedor 3,  número 3 a sobre a opinião dele, que a inteligência artificial se for utilizada de forma errada, acaba sendo mais a culpa da pessoa que está usando ela não de alguém que desenvolver, porque a pessoa que desenvolveu a internet artificial fez para com intuito de beneficiar a sociedade. Mas a pessoa que usou o usuário usou de forma errada e acaba fazendo alguma coisa prejudicial. Alguém tem algo a comentar sobre a resposta do debatedor um ou a pergunta em si. Tá, então passemos para a segunda pergunta para o debatedor número 2. IAs generativas podem ser usadas nos processos educacionais, por exemplo, em aulas, atividades ou provas, o ou a aluno ou a aluna deve reportar ao professor ou professora sobre o uso de IAs generativas em suas atividades? Eu acredito que pode ser utilizado sim, como qualquer outra tecnologia, a gente utiliza, por exemplo, em nossas atividades escolares acadêmicas. A questão do do uso da internet, por exemplo em sites de pesquisa,e a gente pode encontrar informações. Como a IA se baseia em um banco de dados gigante eu acredito que nós podemos utilizar no sentido de que podemos utilizá-la como fonte dessas informações, certo? Por exemplo, eu quero pesquisar, supondo, de uma forma bem grotesca sobre a questão da história da do Brasil. Eu Acredito que a IA vai nos fornecer é informações que serão necessárias ou muito importantes para o nosso crescimento, para o nosso crescimento intelectual de conhecimento e outra pergunta, o aluno deve reportar ao professor sobre o uso das IAs generativas em suas atividades? Eu lembro que se Eu Acredito que sim, como qualquer outro banco de dados que nós já vemos referir, da onde a gente pegou essas informações. Eu acredito que é necessário também reportar ao professor, ao docente, o da onde a gente tirou essas informações. Alguém gostaria de comentar algo sobre a resposta dada ou a pergunta em si? Então passemos pra pergunta 3, ao debatedor número 3. De que maneira a propriedade intelectual deve ser tratada quando um conteúdo é gerado por uma IA? Por exemplo, se um usuário gerou uma música usando IA, o crédito pela criação deve ser o deste usuário? Da plataforma de IA utilizada? Do criador dos dados originais, com os quais a IA foi treinada? Ou de que?\n"," Não acredito que deva ser da IA porque a IA gerativa, ela é feita como uma base de dados muito gigantesca e ela vai fazer as coisas coisas novas, não vai replicar o que tem, ela vai aprender e vai replicar e vai criar coisas novas. Então, uma criação dela e uma criação de outras pessoas, ela, o crédito deve ser dela. Debatedor número 5 Eu imagino que seja, tenha créditos à inteligência artificial, mas que não totalmente, já que ela utiliza de um banco de dados, possivelmente ela vai estar pegando algo de outra pessoa e reutilizando, é de certa forma, então possivelmente, se você identifica, é seus direitos autorais no que ela gerou, eu imagino que é o os direitos autorais você também tenha participação disso. Debatedor número 2. Como o debatedor falou, número 5, ele falou, é como se fosse uma árvore, né? Se a gente puxar, é de onde está havendo as informações sempre vai ter um crédito como ele falou, na questão do do do grande banco de dados, O o artistao músico que está procurando, é, criar uma nova música utilizando a inteligência artificial também deve ter seu crédito de certa forma, mas acredito também tanto os conteúdos é que estão dentro É da IA, do do banco de dados da IA também devem ser procurados de de onde foi que ela utilizou essas informações E, de certa forma, acredito que também até o os criadores do da IA também. Alguém mais, tem algo a comentar sobre a pergunta, sobre as respostas dadas? Não? Então sigamos para a pergunta 4 debatedor número 4. Como garantir que conteúdo gerados por IA não sejam usados para espelhar informações tendenciosas, errôneas ou maliciosas, por exemplo, quando esse tipo de informação é propagada massivamente por bots em uma rede social, a responsabilidade deve ser da empresa que administra a rede social, dos programadores da IA, de quem produziu aquele conteúdo usando a IA?   Eu prevejo que seja de quem produziu aquele conteúdo.  Porque não minto que seja do da empresa o cara tem domínio né, daquela rede social de propagar aquilo que ela está passando. Então se passa uma informação que ela não consegue verificar, não consegue analisar que é justamente tendenciosa é errônea, né? Como uma imagem, né? Uma fake news, uma, um som, uma até uma, música que passe por assim sem ela perceber essa essa falha, né? Que pode dar na ética. Eu vejo que seja dela a essa essa falha, né não de que ade que a produziu, assim, quem produziu também, mas seria mais ela, que tá propagando. Debatedor 2 Eu Acredito também, assim como o debatedor 4, falou É, tem uma parcela em culpa da empresa em talvez propagar essa esse conteúdo de forma errônea ou de forma é replicada, mas também do próprio usuário que que produziu o conteúdo usando da IA. Acredito que a IA ela  Não, não, não tem essa, tanto, essa parcela de culpa que que eu comparo com se fosse o carro, por exemplo, de forma grotesca, claro. Um carro, o criador de um automóvel, no caso ele não pensou naquelas pessoas, talvez muito provavelmente nas pessoas que poderiam utilizálo como veículo de de de rachas na rua, por exemplo. Mas como uma forma de locomoção das pessoas e  para um lugar, outros lugares et cetera, et cetera, mas que devido aos seus usuários, por exemplo, nós, quando nós utilizamos o nosso automóvel, assumimos essa essa responsabilidade de que, caso venha, venhamos a desrespeitar, leis de trânsito perdão e assumirmos essas responsabilidades, assumimos essa culpa de talvez provocar um acidente e comparando de forma com o usuário que utiliza essa IA eu acredito que ele também deve ser responsabilizado. Por quê? Porque ele está assumindo de que quando ele produz esse conteúdo, é claro, é evidência evidencialmente vai ser um conteúdo é pejorativo, um conteúdo que é traz mal para a sociedade. Debatedor 5 Eu já para mim, eu não imagino que a empresa, a rede social que administra ela seria responsável, já que possivelmente vai haver algum algoritmo ele vai identificar aquilo, claro que existem métodos de filtragem para identificar se se é um, se é uma informação falsa ou não, mas é o algoritmo, só vai repassar para outras pessoas se as pessoas concordarem e curtirem compartilharem, repassarem para outras pessoas, então, eu imagino que é mais das pessoas que veem aquele conteúdo e de quem produziu esse conteúdo É a culpa de informações tendenciosas serem repassadas do que mesmo da responsabilidade da rede social, né? Já que, teoricamente, a rede social não foi feita para isso. Alguém tem algo a comentar sobre o que tinha dito ou sobre a pergunta? Então passemos a quinta pergunta ao debatedor número 5. Quais os impactos da IA no ambiente de trabalho, você acha que o uso de IAs generativas irá gerar ou destruir empregos, por exemplo, uma IA generativa que consegue fazer um trabalho de um arquiteto ou publicitário de forma mais rápida fará um trabalho totalmente confiável. É, eu imagino que E vai existir impactos dessa inteligência artificial, né no mercado de trabalho, mas isso acontece hoje em dia sempre aconteceu com diversas outras coisas existem diversos empregos que não existem mais porque foi criado algo novo, que é melhor, que é superado hoje em dia, por exemplo, não tem mais antigamente tinha um emprego nas naqueles lugares de jogar boliche, tinha um pessoal que organizava os pinos para você jogar de novo. Hoje em dia não é assim, mais não. Esse emprego não existe mais. Então, é enquanto a inteligência artificial estiver sendo é desenvolvida, é claro que você não pode confiar totalmente, né? É preciso que você tenha a é a inspeção de um arquiteto, de um cara que estudou para isso. Possivelmente a inteligência artificial vai ter arquitetos que vão ter, vão estar trabalhando em conjunto com programadores para desenvolver essa inteligência. Então, eu imagino que enquanto a inteligência artificial estiver evoluindo, a tendência é que ela esteja mais e mais confiável E diante disse empregos, se não forem atualizados, se não tiverem mais a eficácia deixaram de existir. Alguém tem algo a comentar sobre esse ponto ou sobre a resposta dada? Bem, então passamos agora para a pergunta livre. A, lembrando que vocês podem responder ou não. Uso e o desenvolvimento de áreas narrativas devem ser fortemente fiscalizados por órgãos governamentais ou elas são apenas mais um tipo de software comum, como milhares de outros existentes? Debatedor número 5. É bastante adverso. Sim, elas devem ser fiscalizadas, mas não fortemente. Até porque tem que ter algum, alguma parte criativa naquilo, né? Se for totalmente fiscalizado, talvez você trave você pare o desenvolvimento daquilo, que você torne lento. O desenvolvimento disso, se você não, claro que a fiscalização é importante justamente por outros motivos, direitos autorais, tudo mais, mas é, se for fortemente, é fiscalizado, é A gente vai deixar de evoluir? Basicamente a gente vai deixar de ter um desenvolvimento mais rápido simplesmente por conta que o governo está fiscalizando e ele não deixa por conta N motivos, né? Então, imagino que deve ser fiscalizado, mas até certo ponto. Alguém mais gostaria de responder a pergunta ou comentar sobre o que foi dito? Bem, então agora cada participante terá um momento para falar suas considerações finais sobre o tema, sua opinião ou visão sobre o tema mudou depois do debate? Começando do debatedor número 1, você tem alguma coisa sobre para falar mais sobre o tema? Tem alguma concentração final, senão, você sua ou visão ou opinião mudou sobre o tema de IAs generativas depois do debate? Não. Debatedor 2 Eu acredito, só, para, a título de conclusão final, acredito que a inteligência artificial, assim como qualquer outra tecnologia, assim como na comparação que eu fiz como automóveis, de forma, grotesca, é claro, mas, ela pode auxiliar, ela vai auxiliar a sociedade na criação de, de, na produção de, de n coisas. No entanto, que deve ter assim um cuidado sim, uma fiscalização para que não torne essa, essa produção de forma demasiada ou que acabe por gerar, é, algo algo que não produza benefícios, pelo contrário, produza malefícios para a sociedade na questão, por exemplo, de criação de imagens utilizando fotos de pessoas e aí parece com que uma pessoa está em um canto que não está ou que está fazendo algo que não, nunca fez. Eu acho que isso acredito que isso deve ser considerado na fiscalização da, da IA para que não ocorra, por exemplo, se, se a IA, um usuário utiliza a minha imagem, usando também a IA e coloque a minha imagem como se eu tivesse fazendo algo ilícito. Não, claro que isso traz no benefício para mim, como pessoa, porque eu nunca fiz aquilo, porque eu nunca estive naquele lugar, et cetera, et cetera. Então deve ser fiscalizado sim, para que não ocorra esse tipo de produção. Debatedor 3 Não Debatedor 4 Prevejo que ela é uma ferramenta, uma conquista, na verdade, em toda espaço da, da, da, da computação, por exemplo, e que, sim, é, deve existir, né, uma fiscalização ali, não fortemente, é claro, mas para barrar justamente problemas, pois uma ferramenta como ela, é, ela é aberta ao público, é vai do usuário, né? O seu intuito, né? O que ele quer trazer, o que quer que a IA faça e retorne. Então, para não ter problemas como direitos autorais ou de problemas que infrinjam a ética, então é algo racista, né, algo homofóbico, por exemplo, uma imagem. Eu vejo que tem que ter um, um, um, limite, né? Um órgão que verifique, né, passe de parâmetro para a IA e o cara retorna. Debatedor 5. Só para finalizar, é, eu imagino que é um conteúdo, é um, é um, é um tema que, é, traz bastante medo na sociedade, né? Principalmente porque, a sociedade em geral, não conhece como a inteligência artificial funciona, o que que ela pode fazer, o que que ela não pode fazer. Então é preciso entender corretamente o que, que ela pode fazer, até onde ela vai chegar, o que é que ela pode te causar. E a partir disso, é a inteligência artificial vai ser mais aceita, né? Principalmente por gerações que já vem, né? E é isso. Então utilizem este QR Code para acessar e responder a um questionário, que é uma avaliação e avaliação geral do debate. Suas respostas são confidenciais e serão usadas para fins de avaliação e aprimoramento. Dito isto, obrigado pela participação de vocês no experimento, iremos fazermos um sorteio de um brinde no final de todos os experimentos. Fiquem atentos, portanto, ao e-mail que vocês cadastraram no formulário de inscrição.\n","\"\"\""],"metadata":{"id":"U4BRFRqb707M","executionInfo":{"status":"ok","timestamp":1725287943454,"user_tz":180,"elapsed":10,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# Prompt 2.1 (Few shot some context)"],"metadata":{"id":"vxLYKlXCFu3b"}},{"cell_type":"code","source":["prompt = f\"\"\"\n","Context: The text below is a transcription in Portuguese from a Speech-to-Text (STT) model of a debate. In these transcriptions, disfluencies such as hesitations, repetitions, and corrections are common.\n","\n","- **Repetitions**: These occur when a word or phrase is repeated consecutively without adding any new meaning or value to the sentence. Repetitions are often present in speech but they do not contribute any additional information to the context. For example, in the phrase \"o ambiente da da tecnologia,\" the word \"da\" is repeated twitce without adding anything meaningful to the sentence, only one occurence of \"da\" would be sufficient to get what the phrase is trying to transmit.\n","\n","- **Hesitations**: These are non-verbal expressions or fillers used in speech to indicate a pause or hesitation. Common hesitations include sounds like \"ahh,\" \"ehh,\" \"um,\", \"hmm\" or \"uh.\" They serve as verbal placeholders while the speaker thinks or searches for the right words. Although they can indicate thought processes, they do not add substantive meaning to the text and should be removed for clarity. For example, in the phrase \"Eu estava, ahh, pensando sobre isso,\" the term \"ahh\" is a hesitation that can be removed.\n","\n","- **Corrections**: These occur when a speaker makes an initial error in their speech and then corrects it. The correction typically involves an initial incorrect phrase followed by a revised version of the same phrase. For instance, in the phrase \"que isso é, quer dizer, isso foi,\" the speaker initially says \"que isso é,\" makes a correction by saying \"quer dizer,\" and finally provides the corrected phrase \"isso foi.\" The goal is to remove the error, leaving only the final corrected version.\n","\n"," The example below shows the same transcription in three stages. The first stage, \"Original,\" is the raw transcription as it comes from the STT model. The second stage, \"Marked,\" is the same transcription with tags identifying the disfluencies in the text, such as \"<hes\" for hesitations, \"<erro\" for errors, \"<corr\" for corrections that come after an error, and \"<rep\" for repeated words. The third and final stage shows the text without the marked transcriptions, cleaned of these so-called disfluencies.\n","\n","Example:\n","\n","\"Original\": \"Excelente. Oi, bem, agora eu eu IA explicar as regras deste debate, e então, antes de de mergulharmos em nossa discussão, é essencial. Todos compreendam e sigam as reuniões de debate. Essas regras foram ampliadas para garantir um debate justo e ordenado para todos os envolvidos. A única principal regra é essa, sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando. Se você deseja contribuir para contra discussão ou oferecer um contra argumento, por favor, levando-se a mão e aguarde em moderador caso eu lhe conceder a palavra, uma vez que tenha sido autorizada a palavra, você terá a palavra e poderá ingressar seus pensamentos. Ou responder aos outros? Ah, vamos seguir um formato estruturado? Deveria em 3 momentos distintos, cada um com seu propósito e regras específicas. O primeiro momento abordaremos a questão principal no debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central foi a medida que isso foi *****. O segundo momento teremos uma rodada de bernanke direcionadas para cada um dos debatedores. Abriremos espaço para outros participantes contra argumentar, eu experçarem as suas opiniões sobre a resposta dada após as Pendências direcionadas, teremos uma última pergunta que será direcionada a todos os participantes, nesse momento, vocês têm a Liberdade de escolher se desejam responder ou não? Ah, e só caso tenham muito algo no caso simples, que tem algo relevante a acrescentar. Por fim, no no terceiro momento, será perguntado se os participantes têm alguma outra colocação ao sobre o tema então. Cada um de vocês terá esse movimento inicial para lhes pensar suas principais opiniões e pensamentos sobre o terminal e o tema é, disse que aí está e que foi também seguido então, começando do debatedor número 1. Quais são as suas opiniões iniciais sobre o tema?\"\n","\n","\"Marked\": \"Excelente. Pois bem, agora <rep eu eu/> explicarei as regras deste debate, e então, antes <rep de de/> mergulharmos em nossa discussão, é essencial. Todos compreendam e sigam as reuniões de debate. Essas regras foram ampliadas para garantir um debate justo e ordenado para todos os envolvidos. A única principal regra é: sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando. Se você deseja contribuir para alguma discussão ou oferecer um contra argumento, por favor, levante a mão e aguarde um moderador, no caso eu lhe conceder a palavra, uma vez que tenha sido autorizada a palavra, você terá a palavra e poderá expressar seus pensamentos ou responder aos outros. <hes ahh/>, vamos seguir um formato estruturado dividido em 3 momentos distintos, cada um com seu propósito e regras específicas. No primeiro momento abordaremos a questão principal no debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central. Que foi aquele tema que lhes foi enviado. No segundo momento teremos uma rodada de perguntas direcionadas para cada um dos debatedores. Abriremos espaço para outros participantes contra argumentar, ou expressarem as suas opiniões sobre a resposta dada após as perguntas direcionadas, teremos uma última pergunta que será direcionada a todos os participantes, nesse momento, vocês têm a Liberdade de escolher se desejam responder ou não <hes ahh/>, <erro e só caso tenham algo /> <corr no caso sintam que tem algo/> relevante a acrescentar. Por fim, <rep no no/> terceiro momento, será perguntado se os participantes têm alguma outra colocação final sobre o tema. Então cada um de vocês terá esse movimento inicial para expressar suas principais opiniões e pensamentos sobre o tema. E o tema é, esse que aí está e que foi também lhes enviado, então começando do debatedor número 1. Quais são as suas opiniões iniciais sobre o tema?\"\n","\n","\"Cleaned\": \"Excelente. Pois bem, agora eu explicarei as regras deste debate, e então, antes de mergulharmos em nossa discussão, é essencial. Todos compreendam e sigam as reuniões de debate. Essas regras foram ampliadas para garantir um debate justo e ordenado para todos os envolvidos. A única principal regra é: sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando. Se você deseja contribuir para alguma discussão ou oferecer um contra-argumento, por favor, levante a mão e aguarde um moderador, no caso de lhe concederem a palavra. Uma vez que tenha sido autorizado a falar, você terá a palavra e poderá expressar seus pensamentos ou responder aos outros. Vamos seguir um formato estruturado dividido em 3 momentos distintos, cada um com seu propósito e regras específicas. No primeiro momento, abordaremos a questão principal no debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central. No segundo momento, teremos uma rodada de perguntas direcionadas a cada um dos debatedores. Abriremos espaço para outros participantes contra-argumentarem ou expressarem suas opiniões sobre as respostas dadas. Após as perguntas direcionadas, teremos uma última pergunta que será direcionada a todos os participantes. Nesse momento, vocês têm a liberdade de escolher se desejam responder ou não. Caso sintam que têm algo relevante a acrescentar. Por fim, no terceiro momento, será perguntado se os participantes têm alguma outra colocação final sobre o tema. Então, cada um de vocês terá esse momento inicial para expressar suas principais opiniões e pensamentos sobre o tema. Começando pelo debatedor número 1, quais são suas opiniões iniciais sobre o tema?\"\n","\n","Following the example presented to you, remove all disfluencies from the following text without altering the original meaning or structure. You should NOT change text that does not refer to disfluencies. ANY text that is not in one of those three categories of disfluencies should not be changed. Return only the cleaned text with no additional information. Remember the text must be in its original full size, but without the disfluencies in it.\n","\n","Text: {texto_disfluente}\n","\"\"\"\n","\n","response3, duration3 = get_response_and_time(prompt)\n","\n","print(response3.text)\n","print('A limpeza foi feita em ', duration3)"],"metadata":{"id":"IJidpx6aFySS","colab":{"base_uri":"https://localhost:8080/","height":585},"executionInfo":{"status":"ok","timestamp":1725288069832,"user_tz":180,"elapsed":126387,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"outputId":"e1cd7672-319f-4a26-fd72-316f1ac28566"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Vamos lá, é boa tarde todo mundo. Bem-vindos a este debate promovido pelo grupo de pesquisa do Lacina, debate em educação. Eu me chamo David e gostaria de apresentar aqui quem está comigo, Klaywert, que também faz parte do grupo. Mas aí a gente tem também Bryan e Hellen, que são, tirando Hellen, a maioria estudantes do mestrado. Hellen é estudante da graduação. E esse projeto está sobre orientação do professor Campelo, que é o professor que vocês conhecem, que vocês conheceram agorinha, que vocês viram agora, certo? OK. A razão pela qual nos reunimos aqui hoje é gerar uma base de dados de voz que posteriormente será transcrita e utilizada para avaliação e treinamento de modelos de inteligência artificial. Nosso foco está entre vários tópicos relacionados a debates, fazendo dessa iniciativa não apenas oportunidade de aprendizado e crescimento, mas também uma contribuição valiosa para o avanço da IA.\n","Vocês assinaram o termo, né? Todo mundo já assinou o termo, então a gente pode pular essa parte. Cada debatedor vai receber uma identificação, né? Vocês já receberam e essa vai ser a identificação de vocês como os debatedores. Aqui a gente não estava interessado nos dados pessoais de vocês, então o processo vai ser identificado dessa forma com esses IDs, certo? A gente vai gravar a voz de vocês. Minha identificação número um, estou contribuindo com a pesquisa no Brasil. Minha identificação número dois, estou contribuindo com a pesquisa no Brasil. Minha identificação número três, estou contribuindo com a pesquisa no Brasil. Minha identificação número quatro, estou contribuindo com a pesquisa no Brasil.\n","Explicando as regras do debate, antes da gente começar o debate é essencial que todos compreendam e sigam as regras do debate. Essas regras foram criadas para garantir um debate justo e ordenado para todos os envolvidos. Primeira regra: sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando. Se você deseja contribuir para a discussão, oferecer algum contra-argumento, por favor, levante a mão e aguarde o moderador, eu, lhe conceder a palavra. Uma vez que tenha sido autorizado a falar, você terá a palavra, poderá expressar seus pensamentos e responder aos outros também.\n","Certo, explicando o funcionamento do debate, vamos seguir em formato estruturado de três momentos distintos, cada um com seu propósito e regras específicas. Momento um: expressão inicial de suas opiniões. No primeiro momento, abordaremos a questão principal do debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central. Momento dois: rodada de perguntas. Num segundo momento, teremos uma rodada de perguntas direcionada para cada um dos debatedores. Abriremos espaço para os outros participantes contra-argumentarem ou expressarem suas opiniões sobre a resposta dada. Após as perguntas direcionadas, teremos uma outra pergunta, que será direcionada a todos os participantes. Neste momento, vocês terão a liberdade de escolher se desejam responder, caso tenham algo relevante a acrescentar. No momento três: colocações finais. Um terceiro e último momento será perguntado se os participantes têm alguma outra colocação final sobre o tema.\n","Certo? OK, então a gente vai começar agora. Ficou alguma dúvida antes de tudo? Deu para entender? Vão ser três momentos o debate, então vai ser um debate semi-estruturado. Se alguém quiser falar, tem que pedir a vez, não pode estar interrompendo o outro e é basicamente essas regras que vocês devem seguir e a gente vai ter umas perguntas para nortear o debate também, que eu vou mostrar, vou botar ali na tela e vou ler para vocês também essas perguntas, OK?\n","Certo, como vocês já sabem, o nosso tema é inteligência artificial generativa e seus impactos na sociedade, OK? Para começar, primeiramente, cada um terá um momento inicial para expressar seus principais opiniões e pensamentos sobre o tema. Cada participante terá um momento para fazer isso, certo? Vamos começar com o debatedor 1. Você gostaria de expressar sua opinião? De forma geral, o que é que você pensa sobre o tema? Bom, as IAs generativas são bem dizer, uma faca de dois gumes, né? Tem aspectos positivos e muito negativos também. Positivos: tem automação de algumas atividades, pode auxiliar como ferramenta complementar em estudos. Como negativa, tem a questão de proteção de dados, de autenticidade de resposta, infração de direitos autorais. Então, dependendo da área, do argumento que quiser seguir, pode ser positivo ou negativo. \n","Agora o debatedor 2, olha em relação aos impactos positivos, as coisas repetitivas vão ser ao longo do tempo eliminadas, alguns trabalhos que precisam de muita repetição e o que meio que vai ficar é, acho que produção intelectualizada, que a IA não consegue fazer bem, inclusive os modelos atuais em relação a opiniões também. E também ele não, ele tem um filtro muito grande, então acho que deve, desde que não infrinja nenhuma lei, deve ter maior liberdade de criação. Os negativos, eu acho que problemas como o deep fake e geração de voz também pelo timbre, eu acho que vai ser um problema muito grande para as autoridades lidar e fazer contramedidas que reconheçam se aquilo é de fato verdade ou não e meio que impulsiona a desinformação. Em relação a estudo também, eu acho que tende a, dependendo da base de dados ou a piorar a situação ou a melhorar. Então acho que no futuro a especificação das IAs não ser uma IA geral, ser mais nichado com os vetores de informação, vai vir a melhorar esse problema de espalhar mentiras. \n","Debatedora três. É, embora esse seja um assunto, um conteúdo que já venha sendo tratado há muito tempo, várias pessoas já tenham trabalhado nisso, ultimamente está tendo uma abordagem maior sobre isso. Acho que até depois do Chat GPT ter vindo, né? E aí o pessoal ficou sabendo muito. Eu, por exemplo, quando eu não tinha esse conhecimento, eu não sabia da existência das IAs nesse sentido, nesse aspecto. Depois que eu conheci o chat, eu consegui compreender mais e como os meninos falaram, ele tem aspectos muito positivos e justamente pela automação, pela facilidade, pela agilidade. Mas eu acho também que os usos negativos dele podem impactar também na autenticidade do próprio ser humano, como o texto diz, mesmo a criatividade, a humanização. Os textos, por exemplo, quando a gente vai ver no TikTok e o pessoal está usando aquelas vozes fakes, são a voz que você jura que é uma pessoa real, só que não tem as expressões. E eu acho que uma expressão de ironia, de sarcasmo que o ser humano, ele consegue ter, isso é algo do ser humano, menos a IA não consegue obter. Então eu acho que pode ser útil sim, para facilitar a nossa vida mesmo, mas não como um substituto de coisas que só o ser humano consegue fazer.\n","Debatedor cinco, quatro, sobre as IAs assim, acho que o principal mesmo é em relação ao trabalho que vai ser, que não tem como você lutar contra esse crescimento da IAs em relação à substituição de empregos. É algo desde a Revolução Industrial, até antes, que a tecnologia sempre vai substituir o ser humano e algo que não pode ser parado. Sobre regulamentação, etc, eu acho que o principal ponto, na minha opinião, é sobre o uso de banco de dados com direitos autorais para geração de novas coisas, porque a maioria das vezes que nesses, essas IAs generativas usam banco de dados de coisas já existentes, como por exemplo, desenhos, já vozes e etc, para criar novas coisas. Então acho que a pauta na legalização de IAs vai ser principalmente nessa área de você poder ou não usar o desenho de alguém para gerar novos desenhos e etc. \n","Certo, vamos iniciar com a rodada de perguntas. Irei realizar uma pergunta para cada participante que terá seu tempo de resposta e ao final de sua resposta, os demais podem pedir espaço para comentar algo sobre a pergunta feita ou a resposta dada, OK? Vamos começar. A primeira pergunta é para o debatedor 1. Se um sistema de IA generativa cria algo prejudicial ou ofensivo, por exemplo, uma imagem com conteúdo racista, quem deve ser responsabilizado? O desenvolvedor da IA, o usuário, a plataforma que hospeda ou alguma outra instituição ou pessoa? O autor do texto da plataforma que hospeda, a plataforma e quase sempre o desenvolvedor da IA, porque querendo ou não, é ele que criou a ferramenta para conseguir filtrar o que ela deve ou não buscar, porque realmente, com as IAs, elas podem perpetuar preconceitos e estereótipos, porque eles fazem o filtro e podem nesses textos que elas estão filtrando, acabar inserindo no texto que ela vai enviar para o usuário certas falas que não são adequadas na sociedade atual. \n","Alguém tem algo a comentar sobre a resposta do debatedor? Mais alguém tem alguma outra colocação sobre essa pergunta específica que queira comentar? Pode dizer. Às vezes o banco de dados da IA que traz para a própria IA, às vezes já vem com alguns dados que podem ser preconceituosos, seja racistas ou sexistas e etc. Às vezes isso já vem do próprio banco de dados que gera novos dados que também são racistas, sexistas, etc. Acho que na minha visão. Então, tu acha que a pessoa culpada seria quem introduziu o dado? Não, eu não acho que a pessoa culpada seria quem produziu o dado assim. Não sei, sinceramente eu teria que pensar um pouco mais para saber quem seria punido nessa daí, porque realmente dentro das opções ali, eu pensei a priori no usuário, mas também o desenvolvedor. A plataforma pode inclinar o dado a sair como algo racista ou sexista, por exemplo, eu acho que seria mais ou menos como se fosse a política do Instagram que tem aquele filtro de palavras negativas e ofensivas que você usa em comentários que justamente já pela consciência de que isso pode ocorrer. Tanto o desenvolvedor já cria esse filtro, essas diretrizes de política, de respeito, de direitos humanos e tal, essas coisas, quanto também do usuário assim, que ele escrever, já ter tipo um bloqueio para isso não acontecer. Tanto a consciência do usuário para estar pesquisando essas coisas quanto do desenvolvedor. \n","Só para fazer um adendo à minha resposta, falei que podia punir a plataforma que hospeda, mas desde que, por exemplo, vamos supor, seja um site de crônicas, aí a pessoa tem autoridade dentro do site. Agora, se for, por exemplo, um Reddit, um fórum de discussão, aí eu já acho que não deva responsabilizar a plataforma e sim fazer como a debatedora 3 falou e fazer a questão do filtro antes da mensagem ser enviada, já evita problemas posteriores. A culpa maior seria de usuário em si, da pessoa? Sim. Pode dizer, debatedor 4. Porque também varia muito do conteúdo que está sendo gerado. Por exemplo, um texto é algo um pouco mais direto. Agora, uma imagem, um dado, às vezes pode ser um pouco mais indireto, mais sutil esse preconceito. Eu acho que a principal responsabilidade deve ser o usuário. Eu acho que o desenvolvedor da IA, ele não, assim, a gente sabe que o usuário, muitas vezes ele é muito criativo em quebrar as coisas. Então se uma IA é muito generalista, talvez o usuário seja muito criativo em fazer com que esse conteúdo seja produzido. Então eu acho que é meio que foge um pouco do escopo do que o desenvolvedor consegue ou não pensar, porque assim, desde que a internet é internet, tem gente só pensando em como quebrar aquela coisa que está disposta ali. Então eu acho que o principal problema é o usuário e não o desenvolvedor. É a mesma coisa de ter um carro e o usuário do carro, meio que o motorista decidir se ele vai sair batendo em tudo ou vai seguir o fluxo normal, acho que é basicamente isso. \n","Até porque o propósito dessa IA criada pelo desenvolvedor é auxiliar, trazendo manutenção, facilidade para a pessoa de modo benéfico. Então seria realmente culpa do usuário o mau uso da plataforma. Então por isso que seria necessário, justamente por causa de, talvez não fosse necessário se o usuário não fizesse isso, mas como a gente sabe que isso já é um histórico muito grande de que as pessoas usam isso para quebrar as regras, então seria necessário já umas diretrizes para evitar que esse problema viesse acontecer, que a culpa, o pessoal iria culpar a marca também, né? A plataforma em si. Alguém tem mais alguma coisa a comentar? \n","Certo, vamos para a pergunta 2. Para o debatedor 2. IAs generativas podem ser usadas nos processos educacionais, por exemplo, em aulas, atividades ou provas? O aluno deve reportar ao professor sobre o uso de IA generativa em suas atividades? São duas perguntas, né? Não, três no caso. A primeira, eu acho que sim, pode ajudar mais do que atrapalhar, desde que seja usado da forma correta. Inclusive, acho que está tendo um movimento na academia, acho que foi uma professora está falando que estão desenvolvendo papers para que isso seja incentivado e não desincentivado como foi em um primeiro momento, porque é mais pelo uso mesmo do usuário, porque tem gente que só coloca lá e pede para ele já vim na resposta direta, mas se você, por exemplo, às vezes eu até uso isso, você coloca a sua resposta para ele incrementar algo ou então fazer com que ele mude a forma como aquilo está sendo visto e na maioria das vezes funciona. Então isso agrega conhecimento se for uma coisa que parta de você, mas se você só manda ele fazer e meio que você só copia e cola, isso não tem conhecimento nenhum sendo gerado. Então acho que pode sim, responder a segunda pergunta também. Em aulas, atividades e provas fica até mais dinâmica, eu acho, não fica algo muito engessado como normalmente o ensino tradicional é e eu acho que deve reportar sim, também para o professor ter ciência de que aquilo está sendo usado e como isso foi usado, inclusive se você perguntar, pegar uma resposta pronta da inteligência artificial e devolver para ele, perguntar se ela foi que ela fez isso, se eu me engano, ela diz que foi ela, então acho que sim. \n","Alguém tem algum comentário sobre a resposta do debatedor 2? Só um ponto bem assim simples, no negócio específico que ele falou, ele falou que se você colocar uma resposta que a IA gerou, ela responde que foi ela que fez, mas assim, isso é algo também que ainda está um pouco em desenvolvimento, porque existe, por exemplo, certas respostas criadas por humanos que se colocar, por exemplo, no Chat GPT, ele disse que foi ele que fez, então ainda é uma coisa um pouco falha que eu acho que tem que se melhorar. Tem algo a comentar sobre a resposta dele? Não, eu acho que é isso mesmo, até porque está tudo meio que começando, ainda está dando os primeiros passos, então normal ter falhas e imprecisões. \n","Também acho que ela pode ser utilizada, estava vendo no fórum da do IF de Santa Catarina, o professor de lá falou que podia ser usado na discussão do assunto, porque às vezes você joga lá uma pergunta e ele pode responder uma coisa que não tem sentido com a realidade. Ele, quando vai filtrar lá, ele pode acabar criando uma teoria, entre aspas, que não existe. Ele falou que a pessoa fala assim: é mais interessante você focar na pergunta da qualidade, na qualidade da pergunta que você vai fazer para IA do que a resposta em si que ela vai dar, que ajuda a ampliar a discussão dentro do diálogo, dentro da sala. Infelizmente, a gente sabe que no mundo atual, a maioria das pessoas usam só para obter uma resposta pronta, mas se fosse usado, se a gente tivesse no mundo ideal, ajudaria muito nos processos de estudo. Ajudaria nos processos de estudo porque como ele é, como a IA junta, agrupa vários complementos, vários conteúdos, seria uma fonte muito rica de informação, de conteúdo, de exercício e tudo mais que fosse complementar. Então para ser aplicado nas escolas, eu acho que seria muito bom os professores, por exemplo, criarem diretrizes também da forma como eles deveriam usar, também com penalidades se fosse criar resposta pronta, porque é muito bom, é algo realmente, a gente tem a faca e o queijo que pode muito bem facilitar e ajudar no nosso processo acadêmico, como também pode prejudicar, porque um aluno que só pega resposta pronta do Chat GPT, ele pode tirar nota muito boa, mas ele não vai ser um bom aluno, bom profissional, porque ele só está copiando aquilo que não foi ele que fez e o ensino ele não é baseado nisso. Então se a gente souber realmente usar da forma correta, a IA, ela é muito promissora na educação. \n","Alguém tem mais algo a comentar? Vamos para a terceira pergunta para a debatedora 3. De que maneira a propriedade intelectual deve ser tratada quando o conteúdo é gerado por IA? Por exemplo, se um usuário gerou uma música usando IA, o crédito pela criação deve ser deste usuário, da plataforma de IA utilizada ou do criador dos dados originais com os quais a IA foi treinada? No caso, a IA é aplicada da mesma forma que um agrupamento de conteúdo com música, por exemplo? Entendi, eu não sei, eu não tenho opinião formada sobre isso porque imagem, a pessoa só colocou, só escreveu o texto e ela gerou lá um agrupamento de várias coisas, mas a criatividade, ela é a junção de várias ideias juntas. Então não tem nada de novo e extraordinário, é tudo coisas que já foram criadas. Então se é a pessoa criou uma música usando IA, eu acho que o crédito pode ser dela, mas não totalmente, não tenho uma opinião formada sobre isso. \n","Alguém tem algo a comentar sobre a resposta dela? Sobre a parte do criador dos dados originais com o qual a IA foi treinada, eu acho que assim, varia muito assim, é a principal questão na minha opinião, porque se você for ver os dados que foi treinado a IA, muitas vezes você pega, tenta pegar o, tenta gerar alguma coisa com a IA e a maioria das vezes é só os dados originais, só que embaralhados. Então assim, é grande parte dos dados originais que é criado essas novas coisas, então. Então você acha que o direito autoral é do dado original? Se for, se o banco de dados foi, por exemplo, só de um autor, eu acho que sim. É que nem o cover, a gente, o cover de uma música, ela tem uma forma diferente, pode até usar, você usa as mesmas notas e tal, usar instrumento diferente, tem um estilo diferente, só que a música original é do cantor que, do cantor, do compositor que escreveu aquela música. Acho que tem a mesma, o mesmo significado. \n","Alguém tem algo a comentar sobre a resposta, sobre a pergunta? Tá, vamos para a pergunta 4 então, para o debatedor 4. Como garantir que conteúdos gerados por IA não sejam usados para espalhar informações tendenciosas, errôneas ou maliciosas? Por exemplo, quando este tipo de informação é propagada massivamente por bots em uma rede social, a responsabilidade deve ser da empresa que administra a rede social, dos programadores da IA ou de quem produziu aquele conteúdo usando a IA? Tá, vamos lá. Acho que a primeira parte é como garantir que esses conteúdos são regulados, são, não são espalhados, são contidos. Eu acho que criando mais tecnologia para prever isso, uma IA que, por exemplo, vê se a informação é verdadeira, vê se há, se alguma coisa é um deep fake ou algo do tipo. E acho que na parte da responsabilidade são um pouco da rede social que sempre tem que melhorar a sua parte de segurança de análise para ver se é um bot ou não e etc, mas eu acho que principalmente da parte de quem produziu o conteúdo também, porque produziu um conteúdo falso, obviamente você está querendo, querendo fazer uma coisa que não é dentro das partes legais, na minha opinião. \n","Alguém tem algo a comentar sobre a resposta que ele deu? Além da de quem produziu ser responsabilizado, eu acho que também a rede social, porque quase tudo que a gente entra hoje em dia tem aquele caption, né, que é meio para evitar isso e também algumas redes sociais também fazem, inclusive acho que o WhatsApp fez isso, que limita as mensagens ou quantidade de mensagens que você manda. Então meio que se foi disparado massivamente, então o canal por onde isso foi espalhado também tem uma certa culpa de não ter segurança o suficiente para isso. Alguém tem mais algo a comentar? Assim, eu concordo com isso que também a empresa que administra tem um pouco de culpa, mas também do mesmo jeito que a empresa vai se melhorando para vigiar isso, os bots também vão melhorando, porque muitas vezes criam-se bots orgânicos que se parecem ser perfis de pessoas, etc, que por exemplo, não são, não é um bot que manda várias mensagens, são vários bots que vão individualmente mandando mensagens que assim, cria-se várias, uma compartilhação massiva de fake news. Acho que obviamente a rede social tem também um pouco de parte da culpa, mas também não dá para se culpar grande parte dela, porque é algo que é o gato e rato, um vai caçar e sempre o outro vai ter que conseguir escapar. \n","Não só, só para complementar, quando tem notícia assim falsa espalhada, principalmente que eu vejo no Twitter e no Instagram, de vez em quando o Instagram, mas é mais no Twitter, tem uma tarjazinha que alguém verificado, uma autoridade sobre o assunto, coloca se é falso ou verdadeiro e a descrição do que, porque é falso ou verdadeiro. No Instagram eu vi isso, mas foi mais no período eleitoral, no Twitter é mais assuntos gerais assim. Alguém tem mais alguma colocação? Nessa parte da tarja e etc, assim, no Twitter eu sei que é por parte dos próprios usuários, ou seja, não é algo que a rede social administra, são os próprios usuários que regulam os próprios usuários, que muitas vezes os usuários que regulam não estão também certos. Eu já vi, por exemplo, tarjas que são falsas e que aí sim, a rede social tem que estar na culpa de ver se é verdadeiro ou não. Alguém tem mais algo a comentar? Não, OK. \n","Nesse último momento, vou passar para uma pergunta que essa pergunta é geral, é livre e todo mundo pode responder, não é direcionada a ninguém, certo? O uso e desenvolvimento de IAs generativas devem ser fortemente fiscalizados por órgãos governamentais ou elas são apenas mais um tipo de software comum, como milhares de outras existências? Alguém quer responder? Eu acho que se o governo tem que meter a mão, eu acho que ele tem que meter a mão meio que de longe, não incisivamente, porque como assim, isso também como eu estava falando, vai atrapalhar a liberdade criativa da IA e de quem cria essas IAs, além de que vai ficar algo muito burocrático e muito ineficiente, não vai acho que aflorar muito, se falar de Brasil, especificamente do Brasil. Acho que países que tendem a ter uma liberdade maior para os desenvolvedores, meio que vai desenvolver mais esse conceito e essa ferramenta IA generativa. Então eu acho que sim, é tipo mais um software como qualquer outro, mas se for para fiscalizar, que seja meio que punitivamente e não fiscalizar de fato a produção e meter a mão na produção e esse tipo de coisa. \n","Alguém tem algo a comentar sobre a resposta que ele deu? É sobre os direitos humanos, né? Eu vou utilizar essa plataforma para, enfim, como naquela pergunta de algo racista, sexista ou algo assim, não precisa ser uma coisa estrita, até porque por exemplo, o Instagram não tem um artigo na Constituição sobre como a gente deve usar o Instagram, existe as diretrizes da própria plataforma sobre como aquele aplicativo deve funcionar, o que é que a gente pode ou não pode fazer. Então eu acho que deveria ser fiscalizado como ele disse, de longe assim, no sentido de ferir direitos humanos, mas também as diretrizes, enfatizar as diretrizes criadas pela própria plataforma como um filtro e regras mesmo de como aquela plataforma deve ser utilizada, que é até então nesse primeiro momento, como ela é nova, ainda está muito liberal assim, então a gente está vendo, está vendo como as coisas vão acontecendo, que vai ser necessário mesmo ter mais um, algo mais regrado, não é ditatoriamente, mas de forma a manter a passividade. \n","Alguém tem mais alguma coisa a comentar sobre a pergunta, sobre a resposta que ela deu? Certo, agora a gente vai ter outro momento que é da mesma forma que vocês deram a opinião inicial de vocês no debate, agora quero opinião final de vocês, se vocês acham que tem algo a apresentar, acrescentar, eu vou passar a palavra a cada um de vocês e aí esse é um momento de dar opinião final de vocês depois do debate, começar pelo debatedor 1. Não acho que, é o que eu falei no começo, tem pontos positivos, negativos. A gente debateu vários pontos importantes aqui, essa questão da fiscalização, tem que tomar bastante cuidado, porque às vezes envolve interesse da instituição ou pessoa que está fiscalizando, isso pode acabar, mas acho que a gente debateu pontos importantes e não sei mais o que falar, minha opinião permanece a mesma, mas gostei de ouvir a opinião de cada um. Pode ser que tenha mudado minha opinião de certa forma, só não sei externar ainda de que forma. \n","Ok, debatedor 2. Acho que eu compartilho da mesma opinião do 1, só que eu ainda acho que, acho que tem algumas considerações que eu não falei que eu ainda acho que fica meramente nesse trabalho repetitivo mesmo, a IA, ela nunca vai conseguir ser ou expressar algo que um humano de fato faz, porque por filosofia das coisas e jeito das coisas serem mesmo, porque a IA de fato não tem vontade, nem ela é um ser de fato, ela basicamente é um idiota útil muito rápido e que consegue mimetizar dados que as pessoas colocam. Ela até pode meio que desenvolver um falso afeto ou um falso sentimento em algum futuro, mas isso não vai ser de fato algo humano e real. Então quanto a substituir os humanos, eu acho que isso nunca vai acontecer no fato de intelectualizar e de sentimento e esse tipo de coisa, mas manualmente provavelmente, mas é porque muitas coisas que a gente conversou aqui foge um pouco do escopo só IA e vão para escopo como educação, como moral, como ética e são assuntos de uma forma geral, então não fica só na IA isso, até em relação ao filtro da IA que de fato o sujeito define como verdade ou falso e esse tipo de coisa toda, é meio subjetivo, subjetivista demais tudo isso. \n","Acho que é muito importante esse debate, eu acho até que a gente deve levar isso até nós enquanto profissionais, né, da computação, a gente tem que levar esse assunto mais em pauta para a sociedade, tanto pela importância disso quanto por trazer a verdade, porque as pessoas, elas são muito enganadas por fake news e tal e a gente realmente mostrar o que realmente significa, o que é de verdade, os benefícios que pode trazer e os malefícios. Isso vai trazer muito um melhor uso da plataforma. Eu acho que a IA é muito importante, mas também a gente não pode endeusar tanto a ponto de achar que vai substituir o humano e que a gente não tem que usar, que isso daí tem que ser fiscalizado pelo governo, que isso não é bom, não é bom, não é bom, mas eu também não acho que a gente deva endeusar algo no ponto de terceirizar todas as nossas responsabilidades, tudo do ser humano numa inteligência artificial, que é como o 2 falou, existem coisas que só nós humanos, a gente tem capacidade de fazer. Uma IA, ela pode reproduzir um som, mas ela não vai transmitir a emoção daquela voz, os sentimentos, a mensagem que ela quer passar. Então é realmente foi como a roda para os primeiros homens aqui, facilitou, ajudou. Então se a gente souber utilizar essa ferramenta de uma forma útil e de uma forma benéfica para a gente, a gente vai ter muitos benefícios e também eu volto a enfatizar a criação de diretrizes da própria plataforma para evitar que danos maiores eles possam acontecer, como ferir os danos morais, direitos humanos e todas essas questões que a gente abordou. \n","Debatedor 4. Assim, complementando um pouco do que a 3 disse, eu acho que principalmente na parte de, peraí, principalmente essa parte de autoridade e tal, assim o, como posso colocar em palavras? Deixa eu pensar. O banco de dados da IA sempre vai pegar algo humano, se você ficar só utilizando IA, você não vai ter coisas novas para incrementar nesse próprio banco de IA humanas. Então acho que assim, é o que eu falei no começo e acho que mantenho, a principal pauta da IA é você está pegando uma base de dados autoral e vai mais ou menos reorganizar para criar coisas novas. Então o quão ético é pegar isso de outra pessoa e reorganizar? Acho que isso é a principal pauta da IA em relação a principalmente entretenimento, basicamente. \n","Mais alguma coisa? Mas então é isso, vou finalizar a gravação agora, tudo certo.\n","\n","A limpeza foi feita em  126.40120720863342\n"]}]},{"cell_type":"markdown","source":["# Chain-of-Thought Prompt"],"metadata":{"id":"ekjL9_-gBrXC"}},{"cell_type":"code","source":["prompt = f\"\"\"\n","Context: The text below is a transcription in Portuguese from a Speech-to-Text (STT) model of a debate. In these transcriptions, disfluencies such as hesitations, repetitions, and corrections are common.\n","\n","- **Repetitions**: These occur when a word or phrase is repeated consecutively without adding any new meaning or value to the sentence. Repetitions are often present in speech but they do not contribute any additional information to the context. For example, in the phrase \"o ambiente da da tecnologia,\" the word \"da\" is repeated twitce without adding anything meaningful to the sentence, only one occurence of \"da\" would be sufficient to get what the phrase is trying to transmit.\n","\n","- **Hesitations**: These are non-verbal expressions or fillers used in speech to indicate a pause or hesitation. Common hesitations include sounds like \"ahh,\" \"ehh,\" \"um,\", \"hmm\" or \"uh.\" They serve as verbal placeholders while the speaker thinks or searches for the right words. Although they can indicate thought processes, they do not add substantive meaning to the text and should be removed for clarity. For example, in the phrase \"Eu estava, ahh, pensando sobre isso,\" the term \"ahh\" is a hesitation that can be removed.\n","\n","- **Corrections**: These occur when a speaker makes an initial error in their speech and then corrects it. The correction typically involves an initial incorrect phrase followed by a revised version of the same phrase. For instance, in the phrase \"que isso é, quer dizer, isso foi,\" the speaker initially says \"que isso é,\" makes a correction by saying \"quer dizer,\" and finally provides the corrected phrase \"isso foi.\" The goal is to remove the error, leaving only the final corrected version.\n","\n","Your task is to identify and remove these disfluencies while maintaining the original meaning and structure of the text. We will do this step by step, identifying and removing each type of disfluency.\n","\n","Example 1:\n","\n","Step 1: Identify Repetitions\n","\n","Original: \"Oi, eu eu acho que que é importante começar.\"\n","Marked: \"Oi, <rep eu eu/> acho que <rep que que/> é importante começar.\"\n","Action: Remove repeated words.\n","Cleaned: \"Oi, eu acho que é importante começar.\"\n","\n","Step 2: Identify Hesitations\n","\n","Original: \"Ah, bem, então...\"\n","Marked: \"<hes Ah,/> bem, então...\"\n","Action: Remove hesitation fillers like \"Ah,\" \"é,\" etc.\n","\n","Step 3: Identify Corrections\n","\n","Original: \"Esse é, quero dizer, isso é essencial.\"\n","Marked: \"<erro Esse é, quero dizer,/> <corr isso é essencial./>\"\n","Action: Remove filler words during corrections.\n","Cleaned: \"isso é essencial.\"\n","\n","Example 2:\n","\n","Step 1: Identify Repetitions\n","\n","Original: \"Bem, a gente tem que, ah, analisar mais profundamente.\"\n","Marked: \"Bem, a gente tem que, <rep analisar analisar/> mais profundamente.\"\n","Action: No repetition to remove.\n","Cleaned: \"Bem, a gente tem que, analisar mais profundamente.\"\n","\n","\n","Step 2: Identify Hesitations\n","\n","Original: \"Ah, analisar mais profundamente.\"\n","Marked: \"<hes Ah,/> analisar mais profundamente.\"\n","Action: Remove hesitation \"Ah.\"\n","Cleaned: \"analisar mais profundamente.\"\n","\n","\n","Step 3: Identify Corrections\n","\n","Original: \"e só caso tenham algo, no caso sintam que tem algo\"\n","Marked: \" <erro e só caso tenham algo /> <corr no caso sintam que tem algo/>\"\n","Action: Remove errors and keep the corrections\".\n","Marked: \"no caso sintam que tem algo\"\n","\n","Instructions: Using the step-by-step method demonstrated in the examples, identify and remove all disfluencies from the following text. Ensure to maintain the original transcription and structure. You should NOT change text that does not refer to disfluencies. ANY text that is not in one of those three categories of disfluencies should not be changed. Return only the cleaned text with no additional information. Remember the text must be in its original full size, but without the disfluencies in it.\n","\n","Text: {texto_disfluente}\n","\"\"\"\n","\n","response4, duration4 = get_response_and_time(prompt)\n","\n","print(response4.text)\n","print('A limpeza foi feita em ', duration4)"],"metadata":{"id":"iwPZYNRJBrF5","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1725288197249,"user_tz":180,"elapsed":127422,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"outputId":"5f06838b-fc85-44bd-db71-690ec291056c"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Vamos lá, boa tarde todo mundo. Bem-vindos a este debate. Promovido pelo grupo de pesquisa do lacina debate em educação. Eu me chamo David e gostaria de apresentar aqui, quem está comigo, Klaywert que também faz parte do grupo. Mas aí a gente tem também Bryan e Hellen, que são tirando Hellen, a maioria estudante do mestrado, Hellen é estudante da graduação. E esse projeto está sobre orientação do professor Campelo, que é o professor que vocês conhecem que vocês conheceram agorinha. que vocês viram agora certo, okay, a razão pela qual nos reunimos aqui hoje, é gerar uma base de dados de voz que posteriormente será transcrita e utilizada para avaliação e treinamento de modelos de inteligência artificial. Nosso foco está entre vários tópicos relacionados a debates, fazendo dessas iniciativa não apenas oportunidade de aprendizado e crescimento mas também uma contribuição valiosa para avanço de IA. \n","Vocês assinaram o termo, né? Todo mundo já assinou o termo, então a gente pode pular essa parte cada debatedor vai receber uma identificação, né? Vocês já receberam e essa vai ser a identificação de vocês, como os debatedores, aqui a gente não estava interessado nos dados pessoais de vocês, então o processo vai ser identificado dessa forma com esses IDs, certo? a gente vai gravar a voz de vocês.\n","Minha identificação número um. Estou contribuindo com a pesquisa no Brasil. Minha identificação número dois, estou contribuindo com a pesquisa no Brasil. Minha identificação número tres, estou contribuindo com a pesquisa no Brasil. Minha identificação número quatro, estou contribuindo com a pesquisa no Brasil. Explicando as regras do debate. Antes da gente começar o debate é essencial, que todos compreendam e sigam as regras do debate, essas regras foram criadas para garantir um debate justo e ordenado para todos os envolvidos. Primeira regra sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando. Se você deseja contribuir para a discussão, oferecer algum contra argumento, por favor, levante a mão e aguarde o moderador, eu, lhe conceder a palavra, uma vez que tenha sido autorizado a falar, você terá a palavra poderá expressar seus pensamentos e responder aos outros também.\n","Certo, explicando o funcionamento do debate, vamos seguir em formato estruturado de três momentos distintos, cada um com seu propósito e regras específicas. Momento um expressão inicial de suas opiniões. No primeiro momento, abordaremos a questão principal do debate e objetivo é que cada participante expresse sua opinião inicial sobre o tema central. Momento dois, rodada de perguntas. Num segundo momento teremos uma rodada de perguntas direcionada para cada um dos debatedores, abriremos espaço para os outros participantes contra argumentarem ou expressarem suas opiniões sobre a resposta dada após as perguntas direcionadas, teremos uma outra pergunta, que será direcionadas a todos os participante, neste momento, vocês terão a liberdade de escolher se desejam responder, caso que tenha algo relevante a acrescentar. No momento três é colocações finais, um terceiro e ultimo momento, será perguntado se os participantes têm alguma outra colocação final sobre o tema.\n","Certo? OK, então a gente vai começar agora. Ficou alguma duvida antes de tudo? deu para entender. Vão ser três momentos o debate, então, vai ser um debate semi estruturado, se alguém quiser falar, tem que pedir a vez, não pode estar interrompendo o outro e é basicamente essas regras que vocês devem seguir e a gente vai ter umas perguntas para nortear o debate também, que eu vou mostrar, vou botar ali na tela e vou ler para vocês também essas perguntas, OK?\n","Certo, como vocês já sabem, o nosso tema é inteligência artificial generativa e seus impactos na sociedade. OK? Para começar, primeiramente, cada um terá um momento inicial para expressar seus principais cada opiniões e pensamentos sobre o tema, cada participante terá um momento para fazer isso, certo? Vamos começar com o debatedor 1, você gostaria de expressar a sua opinião? De forma geral, o que é que você pensa sobre o tema? Bom, as IAs generativas são bem dizer uma faca de dois gumes, né? Tem aspectos positivos e muito negativos também, positivos tem automação de algumas atividades pode auxiliar como ferramenta complementar em estudos como negativa, tem a questão de proteção de dados, de autenticidade, de resposta, infração de direitos autorais. Então, dependendo da área do argumento que quiser seguir, pode ser positivo ou negativo. Agora o debatedor 2 olha em relação a os impactos positivos que as coisas repetitivas vão ser ao longo do tempo eliminadas alguns trabalhos que precisam de muita repetição e o que meio que vai ficar acho que produção intelectualizada que a IA não consegue fazer bem, inclusive os modelos atuais em relação a opiniões também e também ele não, ele tem um filtro muito grande, então acho que deve, desde que não infrija nenhuma lei deve ter maior liberdade de criação. Os negativos, eu acho que problemas como o deep fake e geração de voz também pelo timbre. Eu acho que vai ser um problema muito grande para as autoridades lidar e fazer contra medidas que reconheçam se aquilo é de fato verdade ou não, e meio que impulsiona a desinformação em relação a estudo também, eu acho que tende a, dependendo da base de dados ou a piorar a situação ou a melhorar, então acho que no futuro a especificação das IAs não ser um aí a geral, ser mais nichado é com os vetores de informação, vai vir a melhorar esse problema de espalhar mentiras. Debatedora três É embora esse seja um assunto, um conteúdo que já venha sido tratado há muito tempo, várias pessoas já tenham trabalhado nisso ultimamente está tendo uma uma abordagem maior sobre isso. Acho que até depois do do chat GPT ter vindo, né? E aí o pessoal ficou sabendo muito. Eu, por exemplo, quando eu não tinha esse conhecimento, eu não sabia da existecia das IAs nesse sentido. Nesse aspecto, depois que eu conheci o chat, eu consegui compreender mais e como os meninos falaram, ele tem aspectos muito positivos, e justamente pela pela automação, pela facilidade, pela agilidade, mas eu acho também que os usos negativos dele pode impactar também na autenticidade do próprio ser humano, como o texto diz, mesmo a criatividade, a humanização os textos por exemplo, quando a gente vai ver no TikTok e o pessoal está usando aquelas vozes fakes tem são, são a voz que você jura que é uma pessoa real, só que não tem as expressões e eu acho que um expressão de ironia, de sarcasmo, que o ser humano ele consegue ter, isso é algo do ser humano menos a IA, não consegue obter. Então eu acho que pode ser útil, sim, para facilitar a nossa vida mesmo, mas não com um substituto de coisas que só o ser humano consegue fazer. Debatedor cinco, quatro sobre, as IAs, assim acho que o principal mesmo é em relação ao trabalho que vai ser que não tem como você lutar contra esse crescimento da IAs em relação à substituição de empregos. É algo desde a revolução industrial, até antes que a tecnologia sempre vai substituir o ser humano e algo que é, não, não pode ser parado sobre regulamentação, etc. Eu acho que o principal ponto, na minha opinião, é sobre o uso de banco de dados de com direitos autorais para geração de novas coisas, porque a maioria da das vezes que nesses essas IAs gerativas usam banco de dados de coisas já existentes, como por exemplo, desenhos já vozes e etc, para criar novas coisas. Então acho que a pauta na legalização de IAs vai ser principalmente nessa área de você poder ou não usar o desenho de alguém para gerar novos desenhos, e etc. Certo, vamos iniciar com a rodada de perguntas irei realizar uma pergunta para cada participante que terá seu tempo de resposta e ao final de sua resposta, os demais podem pedir espaço para comentar algo sobre a pergunta feita ou a resposta dada? OK, vamos começar. A primeira pergunta é pro debatedor 1, se um sistema de IA generativa cria algo prejudicial ou ofensivo. Por exemplo, uma imagem com conteúdo racista. Quem deve ser responsabilizado? O desenvolvedor da IA, o usuário, a plataforma a plataforma que hospeda ou alguma outra instituição ou pessoa. O autor do texto da plataforma que hospeda, a plataforma e quase sempre o desenvolvedor da Ia, porque querendo ou não, é ele que criou a ferramenta para conseguir filtrar o que ela deve ou não buscar, porque realmente, com o as IAs, elas podem perpetuar preconceitos e estereótipo, porque eles fazem o filtro e podem, nesses textos que elas estão filtrando, acabar inserindo no texto que ela vai enviar para o usuário certas falas que não são adequadas no na sociedade atual. Alguém tem algo a comentar sobre a resposta do debatedor? Mais alguém tem alguma outra colocação sobre essa pergunta específica que queira comentar? Pode dizer. Às vezes o banco de dados da IA, que que traz para a propria IA, às vezes já vem com alguns dados que que podem ser preconceituosos. Seja racistas ou sexistas, e etc. Às vezes isso já vem do próprio banco de dados, que gera novos dados que também são racistas, sexistas, etc. Acho que na minha na minha visão. Então tu acha que a pessoa culpada seria quem introduziu o dado? Não, eu não acho que a pessoa culpada seria que produziu o dado assim não sei sinceramente eu teria que pensar um pouco mais para saber quem seria punido nessa daí, porque realmente. Dentro das opções ali é eu pense a Pri, a priori, eu pensei no usuário, mas também o desenvolvedor. A plataforma pode inclinar o o dado a sair como como algo racista ou sexista por exemplo eu acho que é, seria mais ou menos como se fosse a política do Instagram que tem aquele filtro de palavras negativas e ofensivas que você usa em comentários que justamente já pela consciência de que isso pode ocorrer. Tanto o desenvolvedor já cria esse filtro, essas diretrizes de de política, de respeito, de direitos humanos e tal, essas coisas, quanto também do usuário, assim ele escrever já ter, tipo um bloqueio pra pra isso não acontecer. Tanto a consciência do usuário pra estar pesquisando essas coisas quanto do desenvolvedor. Só para fazer um adendo minha resposta falei que pudia punir plataforma que hospeda, mas desde que, por exemplo, vamos supor seja um site de crônicas, ai a pessoa tem autoridade dentro do site. Agora, se for, por exemplo, um reddit, um fórum de discussão, aí eu já acho que não deva responsabilizar a plataforma e sim fazer como a debatedora 3 falou e fazer a questão do filtro antes da mensagem ser enviada. já evita problemas posteriores A culpa maior, seria de usuário, em si, da pessoa? Sim Pode dizer debatedor 4 Porque também varia muito do conteúdo que está sendo gerado. Por exemplo, um texto é algo um pouco mais direto. Agora, uma imagem, um dado às vezes pode ser um pouco mais indireto, mais sutil, esse preconceito. Eu acho que o principal responsabilidade deve ser o usuário. Eu acho que o desenvolvedor da IA, ele não, assim a gente sabe que o usuário muitas vezes ele é muito criativo em quebrar as coisas. Então, se uma IA é muito generalista, talvez o usuário seja muito criativo em fazer com que esse conteúdo seja produzido. Então eu acho que é meio que foge um pouco do escopo do que o desenvolvedor consegue ou não pensar. Porque assim, desde que a internet é internet, tem gente, só pensando em como quebrar aquela coisa que está disposta ali, então eu acho que o principal problema é o usuário e não o desenvolvedor. É a mesma coisa de ter um carro e usuário do carro meio, que o motorista decidir se ele vai sair batendo em tudo ou vai seguir o fluxo normal, acho que é basicamente isso Até porque o propósito desse dessa IA criada pelo desenvolvedor é auxiliar, trazendo, manutenção, facilidade para a pessoa de modo benéfico. Então seria realmente culpa do usuário o mau uso do do da plataforma. Então, por isso que seria necessário, justamente por causa de talvez não fosse necessário. Se o usuário não fizesse isso, mas como a gente sabe que isso já é um histórico muito grande de que as pessoas usam isso para quebrar as regras, então seria necessário já uma umas diretrizes, para evitar que esse problema viesse acontecer. Que a culpa, o pessoal iria culpar a marca também, né? A plataforma em si. Alguém tem mais alguma coisa a comentar? Certo, vamos para a pergunta 2. Para o debatedor 2, IAs generativas podem ser usadas nos processos educacionais, por exemplo, em aulas, atividades ou provas. O ou a aluna devem reportar o professor sobre o uso de IA generativa em suas atividades. São duas perguntas, né não três no caso, a primeira, eu acho que sim. Pode ajudar mais do que atrapalhar, desde que seja usado da forma correta. Inclusive acho que está tendo um movimento na academia. Acho foi que uma professora está falando que estão desenvolvendo papers para que isso seja incentivado e não desincentivado como foi em um primeiro momento, porque é mais pelo uso mesmo do usuário, porque tem gente que só coloca lá e pede para ele. Já vim na resposta direta, mas se você, por exemplo, às vezes eu até uso isso, você coloca a sua resposta. Pra Ele incrementar algo, ou então fazer com que ele mude a forma como aquilo tá sendo visto e na maioria das vezes funciona, então isso, agrega conhecimento. Se for uma coisa que parta de você, mas se você só manda ele fazer e meio que você só copia e cola, isso não tem conhecimento nenhum sendo gerado. Então acho que pode sim responder a segunda pergunta também em aulas, atividades e provas, fica até mais dinâmica, eu acho não fica algo muito engessado, como normalmente o ensino tradicional é, e eu acho que deve reportar, sim, também para o professor ter ciência de que aquilo está sendo usado e como isso foi usado, inclusive se você perguntar, pegar uma resposta pronta da inteligência artificial e devolver para ele perguntar se ela foi que ela fez isso, se eu me engano, ela diz que foi ela, então acho que sim. Alguém tem algum comentário sobre a resposta do debatedor 2? Só um ponto bem assim, simples no negócio específico que ele falou, ele falou que se você colocar uma resposta que a IA gerou, ela responde que foi ela que fez, mas assim isso é algo também que ainda está um pouco um pouco em desenvolvimento, porque existe, por exemplo, certas respostas criadas por humanos que se colocar, por exemplo, no chat GPT. Ele disse que foi ele que fez, então ainda é uma coisa um pouco falha, que eu acho que tem que se melhorar. Tem algo a comentar sobre a resposta dele? Não, eu acho que é isso mesmo, até porque está tudo meio que começando, ainda está dando os primeiros passos, então, normal ter falhas e imprecisões. Também acho que ela pode ser utilizada, estava vendo no fórum da do IF de Santa Catarina, o professor de lá falou que podia ser usado na discussão do assunto, porque às vezes você joga lá uma pergunta e ele pode responder uma coisa que não tem sentido com a realidade. Ele quando vai filtrar lá ele pode acabar, criando uma teoria, entre aspas, que não existe. Ele falou que a pessoa fala assim, é mais interessante você focar na pergunta da qualidade, na qualidade da pergunta que você vai fazer para IA do que a resposta em si que ela vai dar, que ajuda a ampliar a discussão dentro do diálogo dentro da sala. Infelizmente a gente sabe que no mundo atual, a maioria das pessoas usam só para obter uma resposta pronta, mas se fosse usado, se a gente tivesse no mundo ideal, ajudaria muito nos processos de estudo. Ajudaria nos processos de estudo porque como ele é, como a IA junta, agrupa vários complementos, vários conteúdos, seria uma fonte muito rica de informação, de conteúdo, de exercício e tudo mais que fosse complementar. Então, para ser aplicado nas escolas, eu acho que seria muito bom os professores, por exemplo, criarem diretrizes também de da forma como eles deveriam deveriam usar também com penalidades, se fosse criar resposta pronta, porque é muito, muito bom, é algo realmente uma uma, a gente tem a faca e o queijo que pode muito bem facilitar e ajudar no nosso processo acadêmico, como também pode prejudicar, porque um aluno que só pega resposta pronta do do chat GPT, ele pode tirar nota muito boa, mas ele não vai ser um bom aluno, bom profissional, porque ele só tá copiando aquilo que não foi ele que fez e o ensino, Ele não é baseado nisso. Então se se a gente souber realmente usar da forma correta, o, a IA, ela é muito, muito promissora na educação. Alguém tem mais algo a comentar? Vamos para a terceira pergunta para o para a debatedora 3, de que maneira a propriedade intelectual deve ser tratada quando o conteúdo é gerado por IA, por exemplo, se um usuário gerou uma música usando IA o crédito pela criação deve ser deste usuário ,da plataforma de IA utilizada ou do criador dos dados originais com os quais a IA foi treinada? No caso a IA aplicada da mesma forma que um agrupamento de de conteúdo com musica, por exemplo? Entendi, eu não sei, eu não tenho opinião formada sobre isso porque imagem, a pessoa só colocou, só, escreveu o texto. E ela gerou lá. Um agrupamento de várias coisas, mas a criatividade ela é a junção de várias ideias juntas. Então não tem nada de novo e extraordinário. É tudo coisas que já foram criadas, então se é a pessoa, criou uma música usando o IA. Eu acho que o crédito pode ser dela mas não totalmente, não tenho uma opinião formada sobre isso. Alguém tem algo a comentar sobre a resposta dela? Sobre a parte do do criador dos dados originais com o qual a IA foi treinada. Eu acho que assim. Varia muito. Assim. É a principal questão, na minha opinião, porque se você for ver os dados que foi treinado a IA, muitas vezes você pega, tenta pegar o, puts pera aí, tenta gerar alguma coisa com a IA e a maioria das vezes é só os dados originais, só que embaralhados. Então assim, é grande parte dos dados originais que é criado essas essas novas coisas. Então. Então você acha que é o direito autoral é do dado original? Se for, se o banco de dados foi foi, por exemplo, só de um autor, eu acho que sim. É que nem o cover a gente o cover de uma música, ela tem uma forma diferente, pode até usar, você usa as mesmas notas e tals, usar instrumento diferente, tem um estilo diferente. Só que a música original é do do cantor que do do cantor, do compositor que escreveu aquela música. Acho que tem a mesma o mesmo significado. Alguém tem algo a comentar sobre a resposta, sobre a pergunta? Tá, vamos para a pergunta 4, então, para o debatedor 4. Como garantir que conteúdos gerados por IA não sejam usados para espalhar informações tendenciosas, errêneas ou maliciosos, por exemplo, quando este tipo de informação é propagada maximamente por bots em uma rede social, a responsabilidade deve ser da empresa que administra a Rede Social, dos programadores da IA ou de quem produziu aquele conteúdo usando a IA. Tá, vamos lá. Acho que a primeira parte é como garantir que esses esses conteúdos são, são reguladas, são não são espalhados, são contidos. Eu acho que criando mais tecnologia para prever isso, uma IA que por exemplo, vê se é ver se a informação é verdadeira, ver se há, se alguma coisa é um deep fake ou algo do tipo ou e acho que na parte da responsabilidade, são um pouco da rede social que sempre tem que melhorar a sua parte de segurança de análise para ver se é um bot ou não, e etc, mas eu acho que, principalmente da parte de do quem produziu o conteúdo também porque produziu um conteúdo falso, obviamente você tá querendo que se querendo fazer uma coisa que não é dentro das partes legais, na minha opinião. Alguém tem algo a comentar sobre a resposta que ele deu? Além da de quem produziu ser responsabilizado, eu acho que também a rede social, porque quase tudo que a gente entra hoje em dia tem aquele caption, né, que é meio para evitar isso e também algumas redes sociais também fazem, inclusive acho que o tipo o WhatsApp fez isso que limita as mensagens ou quantidade de mensagens que você manda. Então meio que se foi disparado massivamente, então o canal de por onde isso foi espalhado e também tem uma certa culpa de não ter segurança o suficiente para isso. Alguém tem mais algo a comentar? Assim, eu concordo com isso, que também a empresa que administra tem um pouco de culpa, mas também do mesmo jeito que é a empresa vai se melhorando pra é vigiar isso, os bots também vão melhorando, porque muitas vezes criam-se bots orgânicos que se parecem ser perfis de pessoas, etc, que, por exemplo, não são, não é um bote que manda várias mensagens. São vários bots que vão individualmente mandando mensagens, que assim cria-se várias, várias, uma compartilhação massiva de fake news. Acho que, obviamente, a rede docial tem também um pouco de parte da da culpa, mas também não dá para se culpar grande parte dela, porque é é é algo que é o é o gato e rato um vai caçar e sempre o outro vai ter que conseguir escapar. Não só, só pra complementar, quando tem notícia assim, falsa, espalhada, principalmente que eu vejo no Twitter e no Instagram. De vez em quando o Instagram mas é mais no Twitter, tem uma tarjazinha que alguém verificado uma autoridade sobre o assunto, coloca se é falso ou verdadeiro e a descrição do que porque é falso ou verdadeiro. No Instagram eu vi isso, mas foi mais no período eleitoral, no Twitter, é mais assuntos gerais assim. Alguém tem mais alguma colocação? Nessa parte da do de tarjas e e etc. Assim, no Twitter, eu eu sei que é por parte dos próprios usuários, ou seja, não é algo algo que a rede social administra, são os próprios os próprios usuários que regulam os próprios usários que muitas vezes os usuários que regulam não estão também certos. Eu já vi, por exemplo, tarjas que são falsas e que a, aí sim, a rede social tem que estar na culpa de ver se é verdadeiro ou não. Alguém tem mais algo a comentar? Não, okay. Nesse último momento, vou passar pra uma pergunta que essa pergunta é geral, é livre e todo mundo pode responder, não é direcionada a ninguém, certo? O uso e desenvolvimento de IAs generativas devem ser fortemente fiscalizados por órgãos governamentais ou elas são apenas mais um tipo de software comum, como milhares de outras existências? Alguém quer responder? Eu acho que se o governo tem que meter a mão, eu acho que ele tem que meter a mão, meio que de longe, não incisivamente, porque como assim, isso também, como eu tava falando, vai atrapalhar a liberdade criativa da IA, e de quem cria essas IA, além de que vai ficar algo muito burocrático e muito ineficiente. Não vai, acho que aflorar muito, se falar de Brasil, especificamente do Brasil, acho que países que tendem a ter uma liberdade maior para os desenvolvedores meio que vai desenvolver mais esse conceito e essa ferramenta IA generativa. Então eu acho que sim, é tipo mais um software como qualquer outro, mas se for para fiscalizar, que seja meio que punitivamente e não fiscalizar de fato a produção e meter a mão na produção e esse tipo de coisa. Alguém tem algo a comentar sobre a resposta que ele deu? É sobre sobre os direitos humanos, né? Eu vou utilizar essa essa plataforma para, enfim, como naquela pergunta de algo algo racista, sexista ou algo assim não precisa de ser uma coisa estrita, até porque, por exemplo, o Instagram não tem um artigo na Constituição sobre como a gente deve usar o Instagram, existe as diretrizes da própria da própria plataforma, sobre como aquele aplicativo deve funcionar, o que é que a gente pode ou não pode fazer? Então eu acho que deveria ser fiscalizado como ele disse, de longe assim no sentido de a ferir direitos humanos, mas também as diretrizes, enfatizar as diretrizes criadas pela própria plataforma como um filtro e regras mesmo de como aquela plataforma deve ser utilizada, que é até então, nesse primeiro momento como ela é nova, ainda tá muito liberal assim, então a gente tá vendo, tá vendo como as coisas vão acontecendo, que vai ser necessário mesmo ter mais um algo mais regrado não é ditatoriamente, mas de forma, a manter a passividade. Alguém tem mais alguma coisa a comentar? Sobre a pergunta, sobre a resposta que ela deu. Certo, agora a gente vai ter outro momento que é da mesma forma que vocês deram a opinião inicial de vocês no debate agora quero opinião final de vocês. Se vocês acham que tem algo a apresentar acrescentar eu vou passar a palavra, cada um de vocês e aí esse é um momento de dar opinião, final de vocês depois do debate, começar pelo o debatedor um. Não acho que. É o que eu falei no começo, tem pontos positivos, negativos. A gente debateu vários pontos importantes aqui, essa questão da fiscalização, tem que tomar bastante cuidado, porque às vezes envolve interesse da instituição ou ou pessoa que está fiscalizando isso pode acabar, mas acho que a gente debateu pontos importantes e não sei mais o que falar, minha opinião permanece a mesma, mas gostei de ouvir a opinião de cada um. Pode Pode ser que tenha mudado minha opinião de certa forma, só não sei externar, ainda de que forma. Ok , debatedor 2. Acho que eu compartilho da mesma opinião do um, só que eu ainda acho que acho que tem algumas consideração que eu não falei que eu ainda acho que fica meramente nesse trabalho repetitivo mesmo a IA ela nunca vai conseguir ser ou expressar algo que um humano de fato faz, porque por filosofia das coisas e jeito das coisas serem mesmo porque a IA de fato, não tem vontade, nem ela é um ser de fato, ela, basicamente um idiota útil, muito rápido e que consegue mimetizar dados que as pessoas colocam, ela até pode meio que desenvolver um falso afeto ou um falso sentimento em algum futuro, mas isso não vai ser de fato algo humano e real. Então, quanto a substituir os humanos, eu acho que isso nunca vai acontecer. No no fato de intelectualizar e de sentimento e esse tipo de coisa, mas manualmente, provavelmente, mas é porque muitas coisas que a gente conversou aqui foge um pouco do escopo só IA e vão para escopo como educação, como moral, como ética e são assuntos de uma forma geral, então não fica só na IA isso, até em relação ao filtro da IA, que de fato, o sujeito define como verdade ou falso e desse tipo de coisa toda é meio subjetivo subjetivista demais tudo isso. Acho que é muito importante esse debate, eu acho até que a gente deve levar isso até nós enquanto profissionais, né? Da computação, a gente tem que levar esse assunto mais em pauta para a sociedade, tanto pela importância disso quanto por trazer a verdade, porque as pessoas, elas são muito enganadas por fake news e tal e a gente realmente mostrar o que realmente significa, o que é de verdade, os benefícios que pode trazer e os malefícios. Isto vai trazer muito um melhor uso da da plataforma. Eu acho que o IA é muito importante, mas também a gente não pode endeusar tanto a ponto de de achar que que vai substituir o humano e que a gente não tem que usar, que isso daí tem que ser fiscalizado pelo governo, que isso não é bom, não é bom, não é bom mas eu também não acho que a gente deva deva terceirizar todas as nossas responsabilidades, tudo do ser humano numa inteligência artificial, que é como o o 2 falou, existem coisas que só nós, humanos, a gente tem capacidade de fazer uma IA ela pode reproduzir um som, mas ela não vai transmitir a emoção daquela voz, os sentimentos, a mensagem que ela quer passar. Então é realmente foi como a roda para para os primeiros homens aqui facilitou, ajudou, então, se a gente souber utilizar essa ferramenta, de uma forma útil e de uma forma benéfica para a gente a gente vai ter muitos benefícios e também eu volto a enfatizar, a criação de diretrizes da própria plataforma para evitar que danos maiores eles possam acontecer, como ferir os danos Morais, direitos humanos e todas essas questões que a gente abordou. Debatedor 4 Assim, completamente um pouco do que a 3 disso, eu acho que, principalmente na parte de, pera aí, putz deu um branco aqui mas principalmente essa parte de de autoridade e tal, assim o, como posso colocar em palavra? Deixa eu pensar. O O banco de dados da IA sempre vai pegar algo humano, se você ficar só utilizando IA IAI IA, você não vai ter coisas novas para incrementar nesse próprio banco de IA humanas. Então, acho que assim é é o que eu falei no começo e acho que mantenho a principal pauta da IA é você está pegando uma uma base de dados autoral e vai mais ou menos reorganizar para criar coisas novas. Então o quão, o quão etico é pegar isso e de outra pessoa e reorganizar, acho que isso é o principal pauta da´IA, em relação a principalmente entretenimento, basicamente. Mais alguma coisa? Massam Então é isso, vou finalzar a gravação agora, tudo certo.\n","\n","A limpeza foi feita em  127.21660804748535\n"]}]},{"cell_type":"markdown","source":["# Verificando a quantidade de disfluências removidas por cada prompt em comparação com o texto original"],"metadata":{"id":"YGmDaQIhqU0V"}},{"cell_type":"code","source":["hes_original, rep_original, erro_original, corr_original = count_disfluencias_in_clean(texto_limpo, hes, rep, erro, corr)"],"metadata":{"id":"tGI4QFJZgwYh","executionInfo":{"status":"ok","timestamp":1725288197250,"user_tz":180,"elapsed":11,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["# Texto limpo por LLM Prompt 1.1 (Zero-shot no context)"],"metadata":{"id":"25yQtxt2gukF"}},{"cell_type":"markdown","source":["## Resultado"],"metadata":{"id":"xhTIO-1U0DmF"}},{"cell_type":"code","source":["\n","levenshtein_data = calculate_metrics(texto_limpo, response1.text)\n","print(levenshtein_data)\n","print()\n","hes_llm, rep_llm, erro_llm, corr_llm = count_disfluencias_in_clean(response1.text, hes, rep, erro, corr)\n","\n","matches_repetições, length_of_incorrect_matches_repeticoes = count_matches(rep_original, rep_llm)\n","matches_hesitações, length_of_incorrect_matches_hesitações = count_matches(hes_original, hes_llm)\n","matches_erros, length_of_incorrect_matches_erros = count_matches(erro_original, erro_llm)\n","matches_correções, length_of_incorrect_matches_correções = count_matches(corr_original, corr_llm)\n","\n","resultados = {\n","    'Repetições': (matches_repetições, len(rep_original)),\n","    'Hesitações': (matches_hesitações, len(hes_original)),\n","    'Erros': (matches_erros, len(erro_original)),\n","    'Correções': (matches_correções, len(corr_original))\n","}\n","\n","total_length_of_incorrect_matches = (length_of_incorrect_matches_repeticoes + length_of_incorrect_matches_hesitações + length_of_incorrect_matches_erros + length_of_incorrect_matches_correções)\n","print(adjust_levenshtein_distance(levenshtein_data, total_length_of_incorrect_matches))\n","print(total_length_of_incorrect_matches)\n","print(exibir_metricas(resultados))"],"metadata":{"id":"se_kXpjdKoVT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725288197251,"user_tz":180,"elapsed":11,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"outputId":"ced8bbe7-73ff-48a1-9f3e-1909770b3999"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Levenshtein Distance': '1,708', 'Levenshtein Similarity': '96.57%', 'Edit Distance': '1,708', 'Original Length': '28,394', 'Processed Length': '28,590', 'Original Word Count': '5,022', 'Processed Word Count': '5,034'}\n","\n","{'Adjusted Levenshtein Distance': 1243, 'Adjusted Levenshtein Similarity': '95.65%'}\n","465\n","Repetições:\n","  Acertos da LLM: 27\n","  Total de chaves no manual: 39\n","  Porcentagem de acertos: 69.23%\n","  Número de chaves não corretamente identificadas: 12\n","\n","Hesitações:\n","  Acertos da LLM: 6\n","  Total de chaves no manual: 8\n","  Porcentagem de acertos: 75.00%\n","  Número de chaves não corretamente identificadas: 2\n","\n","Erros:\n","  Acertos da LLM: 4\n","  Total de chaves no manual: 25\n","  Porcentagem de acertos: 16.00%\n","  Número de chaves não corretamente identificadas: 21\n","\n","Correções:\n","  Acertos da LLM: 10\n","  Total de chaves no manual: 26\n","  Porcentagem de acertos: 38.46%\n","  Número de chaves não corretamente identificadas: 16\n","\n","Média de porcentagem de acertos entre Hesitações, Erros e Repetições: 51.39%\n","None\n"]}]},{"cell_type":"markdown","source":["# Texto limpo por LLM Prompt 1.2 (Zero-shot some context)"],"metadata":{"id":"9pEcG8dCwoWa"}},{"cell_type":"markdown","source":["## Texto"],"metadata":{"id":"Rr7BwHdC0My9"}},{"cell_type":"markdown","source":["## Resultado"],"metadata":{"id":"Y8AHKD9q0LKF"}},{"cell_type":"code","source":["\n","levenshtein_data = calculate_metrics(texto_limpo, response2.text)\n","print(levenshtein_data)\n","print()\n","hes_llm, rep_llm, erro_llm, corr_llm = count_disfluencias_in_clean(response2.text, hes, rep, erro, corr)\n","\n","matches_repetições, length_of_incorrect_matches_repeticoes = count_matches(rep_original, rep_llm)\n","matches_hesitações, length_of_incorrect_matches_hesitações = count_matches(hes_original, hes_llm)\n","matches_erros, length_of_incorrect_matches_erros = count_matches(erro_original, erro_llm)\n","matches_correções, length_of_incorrect_matches_correções = count_matches(corr_original, corr_llm)\n","\n","resultados = {\n","    'Repetições': (matches_repetições, len(rep_original)),\n","    'Hesitações': (matches_hesitações, len(hes_original)),\n","    'Erros': (matches_erros, len(erro_original)),\n","    'Correções': (matches_correções, len(corr_original))\n","}\n","\n","total_length_of_incorrect_matches = (length_of_incorrect_matches_repeticoes + length_of_incorrect_matches_hesitações + length_of_incorrect_matches_erros + length_of_incorrect_matches_correções)\n","print(adjust_levenshtein_distance(levenshtein_data, total_length_of_incorrect_matches))\n","print(total_length_of_incorrect_matches)\n","print(exibir_metricas(resultados))"],"metadata":{"id":"khDlapzskQO2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725288197251,"user_tz":180,"elapsed":10,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"outputId":"2b5b4602-7747-4b90-a453-84b341529010"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Levenshtein Distance': '1,365', 'Levenshtein Similarity': '97.47%', 'Edit Distance': '1,365', 'Original Length': '28,394', 'Processed Length': '28,616', 'Original Word Count': '5,022', 'Processed Word Count': '5,073'}\n","\n","{'Adjusted Levenshtein Distance': 680, 'Adjusted Levenshtein Similarity': '97.62%'}\n","685\n","Repetições:\n","  Acertos da LLM: 13\n","  Total de chaves no manual: 39\n","  Porcentagem de acertos: 33.33%\n","  Número de chaves não corretamente identificadas: 26\n","\n","Hesitações:\n","  Acertos da LLM: 6\n","  Total de chaves no manual: 8\n","  Porcentagem de acertos: 75.00%\n","  Número de chaves não corretamente identificadas: 2\n","\n","Erros:\n","  Acertos da LLM: 3\n","  Total de chaves no manual: 25\n","  Porcentagem de acertos: 12.00%\n","  Número de chaves não corretamente identificadas: 22\n","\n","Correções:\n","  Acertos da LLM: 13\n","  Total de chaves no manual: 26\n","  Porcentagem de acertos: 50.00%\n","  Número de chaves não corretamente identificadas: 13\n","\n","Média de porcentagem de acertos entre Hesitações, Erros e Repetições: 30.56%\n","None\n"]}]},{"cell_type":"markdown","source":["# Texto limpo por LLM Prompt 2.1 (Few shot some context)"],"metadata":{"id":"ADaxbS2qwvQx"}},{"cell_type":"markdown","source":["## Resultado"],"metadata":{"id":"P13vKE6c0Sc_"}},{"cell_type":"code","source":["\n","levenshtein_data = calculate_metrics(texto_limpo, response3.text)\n","print(levenshtein_data)\n","print()\n","hes_llm, rep_llm, erro_llm, corr_llm = count_disfluencias_in_clean(response3.text, hes, rep, erro, corr)\n","\n","matches_repetições, length_of_incorrect_matches_repeticoes = count_matches(rep_original, rep_llm)\n","matches_hesitações, length_of_incorrect_matches_hesitações = count_matches(hes_original, hes_llm)\n","matches_erros, length_of_incorrect_matches_erros = count_matches(erro_original, erro_llm)\n","matches_correções, length_of_incorrect_matches_correções = count_matches(corr_original, corr_llm)\n","\n","resultados = {\n","    'Repetições': (matches_repetições, len(rep_original)),\n","    'Hesitações': (matches_hesitações, len(hes_original)),\n","    'Erros': (matches_erros, len(erro_original)),\n","    'Correções': (matches_correções, len(corr_original))\n","}\n","\n","total_length_of_incorrect_matches = (length_of_incorrect_matches_repeticoes + length_of_incorrect_matches_hesitações + length_of_incorrect_matches_erros + length_of_incorrect_matches_correções)\n","print(adjust_levenshtein_distance(levenshtein_data, total_length_of_incorrect_matches))\n","print(total_length_of_incorrect_matches)\n","print(exibir_metricas(resultados))"],"metadata":{"id":"aNglAFD20VWS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725288197677,"user_tz":180,"elapsed":433,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"outputId":"077c6db1-be78-46c2-c834-451c7b05a275"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Levenshtein Distance': '1,652', 'Levenshtein Similarity': '96.68%', 'Edit Distance': '1,652', 'Original Length': '28,394', 'Processed Length': '28,201', 'Original Word Count': '5,022', 'Processed Word Count': '4,959'}\n","\n","{'Adjusted Levenshtein Distance': 1291, 'Adjusted Levenshtein Similarity': '95.42%'}\n","361\n","Repetições:\n","  Acertos da LLM: 34\n","  Total de chaves no manual: 39\n","  Porcentagem de acertos: 87.18%\n","  Número de chaves não corretamente identificadas: 5\n","\n","Hesitações:\n","  Acertos da LLM: 7\n","  Total de chaves no manual: 8\n","  Porcentagem de acertos: 87.50%\n","  Número de chaves não corretamente identificadas: 1\n","\n","Erros:\n","  Acertos da LLM: 5\n","  Total de chaves no manual: 25\n","  Porcentagem de acertos: 20.00%\n","  Número de chaves não corretamente identificadas: 20\n","\n","Correções:\n","  Acertos da LLM: 13\n","  Total de chaves no manual: 26\n","  Porcentagem de acertos: 50.00%\n","  Número de chaves não corretamente identificadas: 13\n","\n","Média de porcentagem de acertos entre Hesitações, Erros e Repetições: 63.89%\n","None\n"]}]},{"cell_type":"markdown","source":["# Texto limpo por LLM Prompt COT"],"metadata":{"id":"rdGbaAgryVk6"}},{"cell_type":"markdown","source":["## Resultado"],"metadata":{"id":"T_V-Qdks0pAR"}},{"cell_type":"code","source":["\n","levenshtein_data = calculate_metrics(texto_limpo, response4.text)\n","print(levenshtein_data)\n","print()\n","hes_llm, rep_llm, erro_llm, corr_llm = count_disfluencias_in_clean(response4.text, hes, rep, erro, corr)\n","\n","matches_repetições, length_of_incorrect_matches_repeticoes = count_matches(rep_original, rep_llm)\n","matches_hesitações, length_of_incorrect_matches_hesitações = count_matches(hes_original, hes_llm)\n","matches_erros, length_of_incorrect_matches_erros = count_matches(erro_original, erro_llm)\n","matches_correções, length_of_incorrect_matches_correções = count_matches(corr_original, corr_llm)\n","\n","resultados = {\n","    'Repetições': (matches_repetições, len(rep_original)),\n","    'Hesitações': (matches_hesitações, len(hes_original)),\n","    'Erros': (matches_erros, len(erro_original)),\n","    'Correções': (matches_correções, len(corr_original))\n","}\n","\n","total_length_of_incorrect_matches = (length_of_incorrect_matches_repeticoes + length_of_incorrect_matches_hesitações + length_of_incorrect_matches_erros + length_of_incorrect_matches_correções)\n","print(adjust_levenshtein_distance(levenshtein_data, total_length_of_incorrect_matches))\n","print(total_length_of_incorrect_matches)\n","print(exibir_metricas(resultados))"],"metadata":{"id":"j_OhF968ydsB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725288197677,"user_tz":180,"elapsed":5,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"outputId":"afaa55fe-3e56-49fe-9527-475260afee68"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Levenshtein Distance': '1,196', 'Levenshtein Similarity': '97.85%', 'Edit Distance': '1,196', 'Original Length': '28,394', 'Processed Length': '28,551', 'Original Word Count': '5,022', 'Processed Word Count': '5,073'}\n","\n","{'Adjusted Levenshtein Distance': 500, 'Adjusted Levenshtein Similarity': '98.25%'}\n","696\n","Repetições:\n","  Acertos da LLM: 9\n","  Total de chaves no manual: 39\n","  Porcentagem de acertos: 23.08%\n","  Número de chaves não corretamente identificadas: 30\n","\n","Hesitações:\n","  Acertos da LLM: 6\n","  Total de chaves no manual: 8\n","  Porcentagem de acertos: 75.00%\n","  Número de chaves não corretamente identificadas: 2\n","\n","Erros:\n","  Acertos da LLM: 3\n","  Total de chaves no manual: 25\n","  Porcentagem de acertos: 12.00%\n","  Número de chaves não corretamente identificadas: 22\n","\n","Correções:\n","  Acertos da LLM: 12\n","  Total de chaves no manual: 26\n","  Porcentagem de acertos: 46.15%\n","  Número de chaves não corretamente identificadas: 14\n","\n","Média de porcentagem de acertos entre Hesitações, Erros e Repetições: 25.00%\n","None\n"]}]}]}