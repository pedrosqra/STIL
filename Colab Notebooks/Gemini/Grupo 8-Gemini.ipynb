{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["6CoLDMkY4Ew2","o2W-_Q-x7gKr","PJS9yuGDHpk8","UWQ8xRwaE6f6","vxLYKlXCFu3b","ekjL9_-gBrXC"],"authorship_tag":"ABX9TyPJGBdfrrwPqJgu5JyL606e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"Ahuma_oVQHth"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"Bgf8bXUlF7jD","executionInfo":{"status":"ok","timestamp":1725285895877,"user_tz":180,"elapsed":28023,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"093ff6a9-8d18-4737-af9b-711102dabda7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting diff-match-patch\n","  Downloading diff_match_patch-20230430-py3-none-any.whl.metadata (5.2 kB)\n","Downloading diff_match_patch-20230430-py3-none-any.whl (42 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: diff-match-patch\n","Successfully installed diff-match-patch-20230430\n","Collecting python-Levenshtein\n","  Downloading python_Levenshtein-0.25.1-py3-none-any.whl.metadata (3.7 kB)\n","Collecting Levenshtein==0.25.1 (from python-Levenshtein)\n","  Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n","Collecting rapidfuzz<4.0.0,>=3.8.0 (from Levenshtein==0.25.1->python-Levenshtein)\n","  Downloading rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Downloading python_Levenshtein-0.25.1-py3-none-any.whl (9.4 kB)\n","Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n","Successfully installed Levenshtein-0.25.1 python-Levenshtein-0.25.1 rapidfuzz-3.9.6\n"]}],"source":["!pip install -U -q google-generativeai\n","!pip install diff-match-patch\n","!pip install python-Levenshtein\n","import google.generativeai as genai\n","from google.colab import userdata\n","import pandas as pd\n","import Levenshtein\n","import json\n","import difflib\n","import time\n","import re\n","import unicodedata\n","from difflib import SequenceMatcher"]},{"cell_type":"code","source":["GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n","genai.configure(api_key=GOOGLE_API_KEY)\n","model = genai.GenerativeModel('gemini-1.5-pro-exp-0827')\n","\n","def get_response_and_time(prompt):\n","  start_time = time.time()\n","  response = model.generate_content(prompt)\n","  end_time = time.time()\n","  return response, end_time - start_time\n","response, duration = get_response_and_time(\"Say 'hello world' and nothing else\")\n","print(response.text)\n","print(duration)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"RAHxHBzql_B9","executionInfo":{"status":"ok","timestamp":1725285906426,"user_tz":180,"elapsed":10558,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"outputId":"1953e645-48b4-4ec1-d67b-6f7813939c23"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["hello world\n","2.041144847869873\n"]}]},{"cell_type":"code","source":["df2 = pd.read_excel('/content/grupo 8 (revisado).xlsx')\n","marked = \" \".join(df2.iloc[:, 0].astype(str).tolist())\n","print(marked)"],"metadata":{"id":"bmOZaBWpGFGG","executionInfo":{"status":"ok","timestamp":1725285907454,"user_tz":180,"elapsed":1032,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fb60ec3c-c914-4a2c-ca59-c5d876ff14a3"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Minha identificação é a número 1. Estou contribuindo com a pesquisa no Brasil. Minha identificação é a número 2. Estou contribuindo com a pesquisa no Brasil. Minha identificação é a número 3. Estou contribuindo com a pesquisa no Brasil. <hes a/>  Então agora eu vou explicar basicamente, <hes a/> principal regra do debate, que é antes de mergulharmos em nossa discussão, é essencial. Todos compreendam o ensino, as regras de debate. Essas regras foram criadas para garantir o debate justo e ordenado para todos os envolvidos. A principal e a essencial regra é seminterrupções. Os debates não devem interromper uns aos outros entre nós alguém estiver falando.\n","Se você deseja contribuir para a discussão ou oferecer um contrato médio, por favor, levante a mão e aguarde o moderador lhe conceder a palavra. Caso eu, uma vez que tenha sido autorizado a falar, você terá a palavra do Bandeirantes prestar seus pensamentos ou responder aos outros.\n","<hes a/> Então, explicando o funcionamento, né? Do debate, nós vamos seguir ele, levar para o formato estruturado deveria ter, em 3 momentos distintos, cada um com seu propósito em regras específicas. No momento 1 <hes é/> abordaremos a questão principal do debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central, que é aquele que eu lhes mandei no momento. 2 haverá uma rodada de perguntas e respostas direcionadas para cada um dos debatedores abriramos espaço para os outros participantes contra-argumentários prestarem as suas opiniões sobre a resposta dada.\n","Após as perguntas direcionadas, teremos uma última pergunta que será direcionada a todos, e nesse momento, vocês têm a Liberdade de escolher se desejam responder ou não e caso sintam, tem algo relevante a acrescentar também ou não?\n","E no fim,  <hes é/> o último momento será de de uma pergunta  <hes a/>.\n","Sobre a sua <erro colocação final sobre o exemplo, se tem algo que é, enfim, /> <corr colocação final./> \n","Então a gravação já está sendo executada, certo? Quando alguém.\n"," <hes E/> primeiramente, para não terá um momento inicial para para expressar as suas principais opiniões e pensamento sobre o Temer. No caso, IA generativa a e cada participante terá um momento para fazer isso, começando pelo debatedor 1. Eu acho que com, num certo controle, ela contribuiu muito, principalmente pra a gente que é estudante, por ter um tutor particular, basicamemte.  <hes E/> pras outras pessoas também, inclusive. <erro Não só/> <corr a IA generativa,/> ela contribui no campo acadêmico, só que você com a IA, tem que também ter esse controle porque como ela aprende com a gente, também pode aprender coisa errada. Isso é um problema porque quando você tem um negócio, por exemplo o ChatGPT, como um público, que várias pessoas contribuiem, vai chegar um momento que vira bagunça <hes e/> , porque você pode contribuir com verdade mas pode vir alguém e cair por terra sua fala, então aí vira uma bagunça.  <erro e não é nem controle/> <corr acho que é importante a fiscalização/>  é muito importante pro avanço de muita coisa. Acho que é isso, por hora. OK, agora o debatedor número 2.  Então, eu acho que tem gente que é muito conservador em relação a IA, que é: \"Ah, eu sou contra totalmente, isso está acabando com a gente\". Mas como o debatedor 1 falou, tem que ser usado na medida certa e não só o chat GPT, mas também a IA para a formação de áudio de vídeo, de imagem. Tudo isso eu acho que tem muito a contribuir. Tipo, a gente, ajuda muita gente, só que No campo ético, eu acho que <erro tem gente,/> tem que ser muito bem pensado, porque <hes é/> pode ser usada para construir a <rep grandes grandes/> coisas, tipo em relação <hes aaaah/>, sei lá, a uma cidade pode criar uma história de uma mentira que pode acabar com a vida assim, na sociedade, na cidade, aí no campo académico, eu também acho que tem gente que se aproveita exacerbadamente do uso da IA e <rep não não/> ajuda a IA raciocinar mais, raciocina Por ela, entendeu? Agora o Debatedor 3. <hes É/>Pois bem, eu compactuo diretamente com a opinião do número 1 e do número 2 <hes e/> mas penso que deva haver alguma meio de fiscalizar que essas IAs estão fazendo, porque elas vão seguir ao pé da letra o que você mandar, o que você programar para ela fazer. <hes E/> acho que é aí que mora o provável problema, né? Porque a partir do momento que uma pessoa programa uma IA pra fazer algo que em teoria traria o bem, mas se for seguido ao pé da letra pode fazer muito muito mal. Aí temos problemas. Um exemplo retirado direto da IA, que eu perguntei pro Chat GPT <hes é/>: Por exemplo, se uma empresa <hes é/>, mandou uma pessoa criar um código fontezinho só para implementar numa IA <hes é/> de maneira de acabar com a fome no mundo. Aí vai, implementa. Show de bola, começa a colocar esse IA. Poucos Meses depois alguns navios vão mudar de rota, porque eles são guiados pela IA, aviões que deveriam chegar com alimentos em lugares não vão chegar e algumas regiões vão ser dizimadas. Mas a IA tá cumprindo o papel dela. Se não há pessoas, não há fome. <hes Ah/>, eu acho que partindo dessa lógica, né? Tem que se haver o policiamento do que essas IAs estão fazendo. A partir do momento que começar a fazer mal à humanidade, tem que ter uma maneira de parar, dar um break, né? Vamos iniciar uma rodada de perguntas irei realizar uma pergunta para cada participante, que terá seu tempo de resposta e ao final de sua resposta, os demais podem pedir espaço para comentar algo sobre a pergunta feita ou então a resposta dada certo? Vamos começar.  A primeira pergunta para o debatedor 1. Se um sistema Ia generativa criar criar algo prejudicial ou ofensivo, por exemplo, uma imagem com conteúdo racista, quem deve ser responsabilizado? O desenvolvedor da IA? usuário? a plataforma que hospeda ou alguma outra instituição ou pessoa. É isso. Aí você me pega porque é muita gente. É inteligência artificial, ela, aprende com a gente. Então, <rep se se/> alguém ensinou ela fazer uma coisa específica, ela vai aprender. Então assim foi, por exemplo, você criou IA para determinada coisa eu vou lá ensino outra coisa, isso fica armazenado. Então se a IA gera uma coisa que é um problema, por exemplo, aí tem que ver, né? Porque, tipo, até onde eu vou apontar o dedo, pra quem eu vou apontar o dedo? até onde eu tolero quem fez isso? quem fez isso?  Então, eu não acho que dá para perguntar o dedo para uma pessoa específica, porque pode ter sido culpa do criador, pode ter sido culpa do usuário ou da empresa. Pode ser dos 3. Ou de todos. Debatedor 3. Não só complementar que pode ter sido culpa de tudinho e tudinho pra responder, né? pelo crime. Aí eu acho que entra no âmbito de fiscalização, criar regras. Porque <erro quando ela cria/> quando a IA cria um problema ou alguma coisa que fere direito de alguém, quem vai ser culpado? Não tem isso, não tem uma regra falando, ninguém deve ser culpado e eu acho que não tem lei também, né? Então assim fica complicado culpar alguém. Eu acho <hes que/> é também acho que é complicado culpar alguém. Mas, por exemplo, se um usuário <hes é/> pedir para a gente, <hes é/> gerar uma coisa de caráter racista, o usuário tem parte de culpa nisso, mas ele, <rep a IA a IA/> tá gerando esse conteúdo, porque tem uma base de dados que tem esse caráter racista. Então, como o debatedor 1 falou, eu acho que pode ser culpa de de qualquer pessoa. Qualquer um, o desenvolvedor, a plataforma ou o usuário. E também acho que é aquilo que eu falei da ética na IA do da fiscalização, porque é todos os crimes assim <hes é/>, < erro podem gerar/> <corr podem ser/> gerados por  IA, porque como debatedor 3 falou , por exemplo, a história de acabar com a fome no mundo, <hes é/> pode gerar um crime <erro pelo/><corr pela/> IA. Indo para outra perspectiva, a gente pode ver parte de culpa do criador, porque como ele criou, ele pode limitar também. Ele pode limitar a IA, então porque ele não limitou isso? Para quando ele recebesse, ela retorna: \"não, isso aqui não é legal, então não vou te responder, não vou aprender isso\". Então eu acho que é assim, parte tem como eu não criar. <erro Não/> <corr pode ter sido tipo/>, não intencionalmente, mas porque não me limitar se vai ver ferir o direito de alguém, se não é construtivo para ninguém? Nem para a IA, nem para ele. Debatedor 3. Mas e porquê limitar? Porque limitando você está limitando o processo de desenvolvimento. Logo, talvez ela desenvolvesse para fazer algo, ficaria patinando no mesmo ciclo, não desenvolvesse como a IA tivesse toda a liberdade, poderia desenvolver. Eu acho que se tiver alguma coisa assim, que fere algum direito de alguém, é poderia ser, não limitado, <rep mas mas/>, dado uma resposta, por exemplo: \"Ah, não vou é... criar conteúdos desse caráter, por conta disso, disso e disso, <hes é/>, mas ele vai ter a base de dados. O debatedor 3, falou sobre liberdade do aprendizado da IA. Mas até que ponto uma Liberdade para aprender uma coisa que não é construtiva para ninguém, que fere o direito do outro, até onde isso é liberdade de aprender? Porque não faz sentido. Tu pega, por exemplo, saindo de IA, aplicativo como Instagram, como Twitter, eles já reconhecem conteúdos que são racistas, conteúdos com teor pornográfico. Eles reconhecem. Então IA pode muito bem reconhecer isso. E assim: \"não, bloqueia isso. Eu não vou reter esse conhecimento e não vou retornar nada\", mesmo que o usuário volte lhe pedindo, ele não retorne nada, até porque não faz sentido. Que tipo de conhecimento amplo, é esse que você pode aprender uma coisa que fere o outro? Alguém mais quer falar sobre esse ponto? Pois bem, vamos para a segunda pergunta para o debatedor 2.  IAs generativas podem ser usadas nos processos educacionais? por exemplo, em aulas em aula, atividades ou provas, o  ou a aluna deve reportar ao professor sobre o uso de IA generativas em  suas atividades. Eu imagino que sim, que pode ser usado, que a IA, por exemplo, eu estava com dúvida em uma questão, e eu estava pensando de uma forma e ela me ajudou a ter um raciocínio de outra forma, mas não copiando tudo. Pode ser, pode ser usado para <hes é/> ajuda de raciocínios, mas eu acho que nos processos educacionais, os professores, os docentes, qualquer coisa, eles estão se restringindo muito do leque de possibilidades que a IA poderia dar <hes ao/> a aulas, por exemplo, é uma aula mais interativa ou ajuda, ou pesquisas com os alunos por meio da IA, como uma ferramenta tipo Google. Só que usando GPT, por exemplo, eu acho que ele se restringe muito. No sentido de restrição, não deve ser restringido, mas aí a gente volta pra ética e pro pro seu senso de uso, tanto de professor como do aluno, porque você está usando para quê? Até que ponto aquilo ali é seu? Até que ponto lhe ajudou? então, dependendo do que você pediu, quanto que você fez? você pegou o resultado que a IA  deu para quê? Então tem que ser <rep eu eu/> não acho que tem que ser restringido, tem que ser aberto a todo a todos, tanto para professor quanto ao aluno, mas com uso responsável. OK, é, eu não vou generalizar tanto. 50% das pessoas não fazem. Eu conheço um bocado de pessoas que, ah, não sei pergunta do chatGPT, me bota a resposta lá, né, Atividade, principalmente no momento de pandemia, é essa coisa muito, muito mais forms lá da vida que só queria a resposta, não importava como você fez.Eu vi muita gente usando desses artifício para passar, tirar notas boas e depois no final, não saber nem o que fez. E inclusive, questão de redações que é, é um negócio que eu tive uma experiência bem de perto mesmo. Algumas pessoas pegam, mandam chatGPT, fazem a redação de qualquer tema. Ele vai fazer, põe outro, 3 palavrinha, inverte o parágrafo outro e manda, tira notas boas. Acho que o conselho acadêmico, deveria haver um jeito também de fazer o chatGPT não dá a resposta pronta, mas mostrar como faz. Eu acho que é tipo um chatGPT acadêmico, né? Seria inovador, diria.  Então o debatedor 3 concorda que deveria ser restringido? Não, restringido não, criada uma nova ferramenta específica para a educação. Mas isso é restringir o uso das IAs, não? Você poderá restringir dentro da escola, mas você vai ter a outra justamente de provas. Eu acho que seria importante. Mas o <hes que/> garante que você mesmo entenda essa nova ferramenta assim, tipo, um filtros limitadores, o que garante que a pessoa não vai usar a outra. É muito leve e aberto. Mas quando você, você parte para a ética, o uso de uma IA normal sem ter filtro nem limitação, você usando com ética é responsabilidade já seria uso correto, não concorda?  Por exemplo, tem o chatGPT como exemplo. Ele é uma base de dados, então ele não está 100% correto o tempo todo. Então eu já vi gente reclamando: \"Ah, eu usei uma IA generativa e a resposta deu estava errada.\" Só que você é, além de você, tem que ter o seu senso e saber o que você está falando. Exatamente o que ela falou, porque se tu pega, se tu pega e se tu pergunta uma coisa e tu tem um resultado e tu pega ali e usa, tu vai estar pondo em risco tua integridade, a tua ética. <hes E/> você não está confirmando se aquilo ali é realmente completamente verídico, porque como já a como eu já havia falado, ela está aprendendo, ela está aprendendo coisa errada também. Eu não estou sempre dando resultado e tu não verifica a  responsabilidade é tua. Alguém mais gostaria de falar algo sobre? Pois bem, então passaremos a terceira pergunta para o debatedor 3, de que maneira a propriedade intelectual deve ser tratada quando o conteúdo é gerado por uma IA, por exemplo, se o usuário gerou uma música usando IA, o crédito pela criação deve ser o deste usuário? da plataforma utilizada? do criador dos dados originais com o com os quais aí já foi treinada? Eis uma grande dúvida. <hes É/> há muita discussão sobre isso. Modéstia à parte, eu acho que como a IA aprende com quem está interagindo com ela eu acho que Mesmo que houvesse uma divisão, não, eu que fiz a IA eu quero 20%, sei lá, 10% dos créditos da música. Acho que a maior parte deve deve ser para uma pessoa que ela Foi treinada mesmo, mesmo que uma parte pequena, assim 10, 5% for para a plataforma e outros 10% por criador da IA acho que a maior parte tem que ir para quem a treinou. O usuário que interagiu com ela para criar essa música.  Eu acho que a criação de música pelo IA, usando outras músicas de ser pensado da mesma forma que, por exemplo, na indústria da música, atualmente eles usam a interpolação. Eu acho que <hes É/> uma parte, vai para o criador original e a outra o útil parte dos números da música vai para quem fez uma pegada diferente com essa música, por exemplo. Só que eu acho que tem que partir para essa parte legal é da mesma forma que as interpolações são feitas e eu não acho que ainda deve, <hes aí/>,  dinheiro para a plataforma de IA, porque ela é só um meio que o usuário está usando para criar aquilo. Acho uma pergunta um pouco aberta, porque quando você usa uma plataforma, por exemplo, de IA, mais difundido chatGPT, ela tem, ela tem regras, tem condições que você aceita. Então, dependendo do que tem nessas condições, nessas regras que ela passa e você vai está lá e aceita, do que você aceitou, você, você, se você não lembra, você está se propondo a correr o risco de, dependendo do que ela gerou, você vai partir para ela, para o criador. <hes E/> outra coisa, por exemplo, se um usuário gerar uma música, usando IA, aí é o questionamento, até onde, aliás, gerou a música e que partes ela fez. Ela adicionou palavras? ela ajudou você no raciocínio? como é que a gente, como é que isso vai ser fiscalizado? Então eu acho eu tem que ser vários pontos analisados até chegar ao veredito de quem vai ser quem vai ser creditado por isso. Agora eu vou fazer uma pergunta direcionada a todo grupo, qualquer um dos debatedores podem responder. O uso e o desenvolvimento de IA generativas devem ser fortemente fiscalizados por órgãos governamentais, ou elas são apenas mais um tipo de software comum como milhares de outros existentes?  Eu acho que uma resposta deve ser fortemente fiscalizada como a música , porque até como todo o nosso impacto foi o debate foi em relação a isso que deve haver a fiscalização da deve-se usar os IAs, mas com a forte fiscalização. Mas a fiscalização tem que ser governamental? porque, porque a no país, no Brasil, onde estamos, a fiscalização governamental é falha. Então assim, eu acho que ele é um software comum e dependendo do seu uso, dependendo do que você fez, você tem uma consequência. Eu acho que o onde é que o governo tem que entrar, dependendo da situação, da conjuntura atual ou do futuro, criar regras, alguma regra ou ou algo do tipo, mas não fiscalizar fortemente, porque essa fiscalização fortemente em algum momento, ela vai vir, ela vai ser limitante pra IA. Então, até que ponto fiscalizar fortemente? <hes É/>, eu vou concordar com ele que falou, no Brasil que nós vivemos o pessoal joga o lixo fora do lixo do lado do lixo, então não vai funcionar aí eu acho que, como os países <hes têm/>  vou caçar aqui a  <hes palavra/> culturas diferentes de cada um puder definir de uma forma diferente, até que ponto nós temos um IA porque cada cultura tem seus princípios seus, seus culturas, <hes suas/> a cultura em geral. Cada povo tem sua cultura e para algumas culturas, pode ser bom algo e para outros não. Aí, tipo, num país a IA é fiscalizada pelo governo e o governo disse não, você não pode ensinar o pessoal como criar um avião. E a outra disse que tem que ensinar o pessoal. Acho que vai dar errado, vai dar errado. Vão ter duas IAs diferentes no caso, viu? Eu acho que para dar fé tem que ser uma IA universal e as mesmas regras em todos os países. Aí que se tem alguns que podem ser moldadas, né? De acordo com a situação, mas, <hes nesse/> partindo desse eu acho que tem que ser pouco... pouco fiscalizada, mas tem algumas regras, sejam universais para todas. Tem que existir lá a regra universal para todas, OK? Mas eu não [INAUDÍVEL]. Nenhuma pessoa de assunto informando o governo porque porque pode ser falha, pode ser instintiva e pode é de Liberdade. Mais alguém gostaria de comentar algo? Não? Pois bem, então agora, certo, nós partimos para a última fase do debate em que cada participante terá um momento para falar suas considerações finais sobre o tema, sua opinião ou visão sobre o tema. No geral, então sua opinião ou visão sobre o tema mudou depois do debate ou se fortaleceu ou ou algum tipo? Fortaleceu. Opinião é a mesmo: uso aberto, uso livre, uso consciente, consciente de consequência, uma regra ou outra. Fiscalização governador não. Continua a mesma também, mas eu acredito na fiscalização governamental, porque <hes é/> se não houver uma fiscalização, que órgão, que vai, é... ser geral para toda a sociedade?. Por que que você acha de que para o  governo?  porque as próprias empresas, criadores de IA, não criam um meio, um órgão que que fiscalize e que e que reja? porque tem que vir no governo, sabes? Essa, esse órgão vindo de empresas não seria facilmente burlado, não? Mas o que que? Mas o que garante que <hes a/> fiscalização governamental seria menos falha do que uma privada? Porque eu penso em uma fiscalização privada, como talvez tinha que ter, talvez um pouquinho do dedo do governo para ser um mediador de todas as empresas que criam IAs por exemplo, aí pode ser OK, mas só o governo fiscalizado não é pouco, é inviável. Pensando nisso, tá partindo da daquele exemplo, lá é do que eu falei logo no início, da fome aí a pessoa manda um processo generativo lá para a empresa e ela passa pelo governo e o governo olha. Tá bacana? Vai, vai solucionar a fome. A empresa vai aí a empresa começar a distribuir essa IA e implementar nos computadores. Dentro do governo dá certo? A pergunta é um pouco vaga porque o nosso plano de governo atual é bonito. Só que na prática que a gente vê coisa, então é. É a fiscalização em si. Por isso que eu falei, eu acho que o governo teria minimamente só consciência, no máximo. Entrar como mediador? talvez. Porque não faz sentido, porque nada garante seja uma situação só o governamental, seja fiscalização de empresa privada ou um consenso mundial. De qualquer forma, ela vai ser falha. Ninguém garante que ela vai ser completamente uma fiscalização completamente OK. Porque outra coisa, tu acha que a fiscalização, ela seria melhor pelo governo? Não, eu acho que seria ruim, mas impô-las em alguns cantos. Acho que vai depender muito do governo que está regendo a região, porque se for um governo que vai implementa as leis eprocura resolver os problemas, pode ser uma fiscalização plausível, né? Mas aí, se um governo agir com descaso, não, vai ser muito invariável. Até eu pensei agora uma junção dos 2, fase um fazer dois, passou pela fase do governo, aí passa pelos testes, entre aspas, da empresa que criou. Eu pensei na fiscalização do governo porque traz a universalidade em todas essas empresas, de IA entendeu? Como os debatedores Estavam falando, é, cada empresa pode ter diferentes morais e éticas que podem passando por diferentes coisas, não? E eu coloquei, em tese na minha fala, um governo que funciona perfeitamente, então pensei normal, Que é falho. Talvez, talvez iniciativa público-privada seria uma boa assim, a depender da circunstância e da forma que ela vai ser criada. Porque falar de fiscalização de IA, principalmente na época atual, que a gente está vivendo, que ela estão tendo o boom que está começando a ser estudado amplamente. Entao não seja uma boa hora, Agora. Mas em algum momento deve-se existir e deve ser adversado. Como isso vai funcionar? Como isso vai agir? Não dá para você chegar e falar:  \"Ah, eu acho que a fiscalização tem que ser assim, assim\" porque ele nunca vai, nunca vai abrir todo o mundo vai ter pontos negativos sempre, sempre. Bem, nesse caso, retomamos a pergunta final, né? Porque a gente acabou voltando ao assunto anterior, é? Houve uma mudança de visão? quais são as suas considerações finais sobre o tema? Essa mudança ocorreu depois do debate? poder livre, aberto, talvez um dedo do governo aí e possivelmente uma fiscalização público-privada. continua a mesmo, mas eu pensei na ideia dos debatedores, e é, eu ainda acredito na fiscalização governamental por conta da universalidade. Mas tem que ter o dedo de mais pessoas. Mudou-se um pouco a minha ideia.<hes É/> Levando em conta que ainda IA estar aprendendo muito ainda. <hes É/>, eu concordei que não agora, né? Mas depois de um certo conhecimento de como essa IA vai se comportar e entender melhor. Ela. Talvez existe uma certa fiscalização público privada. Entendi. Pois bem, gente, estamos chegando ao final, né? Do nosso debate. Então vocês podem é escanear esse quer para um formulário de autoavaliação, bemrapidinho. E as respostas são confidenciais e serão utilizadas só para os fins de avaliação e aprimoramento, no geral, não.\n"]}]},{"cell_type":"markdown","source":["# Código que limpa o texto marcado de disfluências e armazena elas em um array"],"metadata":{"id":"SYY6CaVlv64h"}},{"cell_type":"code","source":["def produz_array(text):\n","    tags_pattern = r'<(rep|corr|erro|hes) ([^<>]*)/?>'\n","\n","    disfluencias = []  # Para armazenar todas as disfluências\n","\n","    def replace_tags(match):\n","\n","        tag = match.group(1)\n","        content = match.group(2).strip()\n","\n","        # Remove '/', '/>', '/>>', '//>' do final do conteúdo\n","        content = re.sub(r'[/]+>?$', '', content).strip()\n","\n","        # Adiciona a disfluência à lista\n","        if tag in ['rep', 'hes', 'erro', 'corr']:\n","            disfluencias.append((tag, content))\n","\n","        return content\n","\n","    # Aplicando a substituição de todas as tags no texto\n","    texto_disfluente = re.sub(tags_pattern, replace_tags, text)\n","\n","    return texto_disfluente, disfluencias\n","\n","texto_disfluente, disfluencias = produz_array(marked)\n","\n","print(\"Texto Disfluente:\\n\", texto_disfluente)\n","print(\"\\nDisfluências Encontradas:\\n\", disfluencias)\n"],"metadata":{"id":"0kf-p0jevJuR","executionInfo":{"status":"ok","timestamp":1725285907455,"user_tz":180,"elapsed":20,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"eb92641f-9d2d-489a-f882-a35019138ecb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Texto Disfluente:\n"," Minha identificação é a número 1. Estou contribuindo com a pesquisa no Brasil. Minha identificação é a número 2. Estou contribuindo com a pesquisa no Brasil. Minha identificação é a número 3. Estou contribuindo com a pesquisa no Brasil. a  Então agora eu vou explicar basicamente, a principal regra do debate, que é antes de mergulharmos em nossa discussão, é essencial. Todos compreendam o ensino, as regras de debate. Essas regras foram criadas para garantir o debate justo e ordenado para todos os envolvidos. A principal e a essencial regra é seminterrupções. Os debates não devem interromper uns aos outros entre nós alguém estiver falando.\n","Se você deseja contribuir para a discussão ou oferecer um contrato médio, por favor, levante a mão e aguarde o moderador lhe conceder a palavra. Caso eu, uma vez que tenha sido autorizado a falar, você terá a palavra do Bandeirantes prestar seus pensamentos ou responder aos outros.\n","a Então, explicando o funcionamento, né? Do debate, nós vamos seguir ele, levar para o formato estruturado deveria ter, em 3 momentos distintos, cada um com seu propósito em regras específicas. No momento 1 é abordaremos a questão principal do debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central, que é aquele que eu lhes mandei no momento. 2 haverá uma rodada de perguntas e respostas direcionadas para cada um dos debatedores abriramos espaço para os outros participantes contra-argumentários prestarem as suas opiniões sobre a resposta dada.\n","Após as perguntas direcionadas, teremos uma última pergunta que será direcionada a todos, e nesse momento, vocês têm a Liberdade de escolher se desejam responder ou não e caso sintam, tem algo relevante a acrescentar também ou não?\n","E no fim,  é o último momento será de de uma pergunta  a.\n","Sobre a sua colocação final sobre o exemplo, se tem algo que é, enfim, colocação final. \n","Então a gravação já está sendo executada, certo? Quando alguém.\n"," E primeiramente, para não terá um momento inicial para para expressar as suas principais opiniões e pensamento sobre o Temer. No caso, IA generativa a e cada participante terá um momento para fazer isso, começando pelo debatedor 1. Eu acho que com, num certo controle, ela contribuiu muito, principalmente pra a gente que é estudante, por ter um tutor particular, basicamemte.  E pras outras pessoas também, inclusive. Não só a IA generativa, ela contribui no campo acadêmico, só que você com a IA, tem que também ter esse controle porque como ela aprende com a gente, também pode aprender coisa errada. Isso é um problema porque quando você tem um negócio, por exemplo o ChatGPT, como um público, que várias pessoas contribuiem, vai chegar um momento que vira bagunça e , porque você pode contribuir com verdade mas pode vir alguém e cair por terra sua fala, então aí vira uma bagunça.  e não é nem controle acho que é importante a fiscalização  é muito importante pro avanço de muita coisa. Acho que é isso, por hora. OK, agora o debatedor número 2.  Então, eu acho que tem gente que é muito conservador em relação a IA, que é: \"Ah, eu sou contra totalmente, isso está acabando com a gente\". Mas como o debatedor 1 falou, tem que ser usado na medida certa e não só o chat GPT, mas também a IA para a formação de áudio de vídeo, de imagem. Tudo isso eu acho que tem muito a contribuir. Tipo, a gente, ajuda muita gente, só que No campo ético, eu acho que tem gente, tem que ser muito bem pensado, porque é pode ser usada para construir a grandes grandes coisas, tipo em relação aaaah, sei lá, a uma cidade pode criar uma história de uma mentira que pode acabar com a vida assim, na sociedade, na cidade, aí no campo académico, eu também acho que tem gente que se aproveita exacerbadamente do uso da IA e não não ajuda a IA raciocinar mais, raciocina Por ela, entendeu? Agora o Debatedor 3. ÉPois bem, eu compactuo diretamente com a opinião do número 1 e do número 2 e mas penso que deva haver alguma meio de fiscalizar que essas IAs estão fazendo, porque elas vão seguir ao pé da letra o que você mandar, o que você programar para ela fazer. E acho que é aí que mora o provável problema, né? Porque a partir do momento que uma pessoa programa uma IA pra fazer algo que em teoria traria o bem, mas se for seguido ao pé da letra pode fazer muito muito mal. Aí temos problemas. Um exemplo retirado direto da IA, que eu perguntei pro Chat GPT é: Por exemplo, se uma empresa é, mandou uma pessoa criar um código fontezinho só para implementar numa IA é de maneira de acabar com a fome no mundo. Aí vai, implementa. Show de bola, começa a colocar esse IA. Poucos Meses depois alguns navios vão mudar de rota, porque eles são guiados pela IA, aviões que deveriam chegar com alimentos em lugares não vão chegar e algumas regiões vão ser dizimadas. Mas a IA tá cumprindo o papel dela. Se não há pessoas, não há fome. Ah, eu acho que partindo dessa lógica, né? Tem que se haver o policiamento do que essas IAs estão fazendo. A partir do momento que começar a fazer mal à humanidade, tem que ter uma maneira de parar, dar um break, né? Vamos iniciar uma rodada de perguntas irei realizar uma pergunta para cada participante, que terá seu tempo de resposta e ao final de sua resposta, os demais podem pedir espaço para comentar algo sobre a pergunta feita ou então a resposta dada certo? Vamos começar.  A primeira pergunta para o debatedor 1. Se um sistema Ia generativa criar criar algo prejudicial ou ofensivo, por exemplo, uma imagem com conteúdo racista, quem deve ser responsabilizado? O desenvolvedor da IA? usuário? a plataforma que hospeda ou alguma outra instituição ou pessoa. É isso. Aí você me pega porque é muita gente. É inteligência artificial, ela, aprende com a gente. Então, se se alguém ensinou ela fazer uma coisa específica, ela vai aprender. Então assim foi, por exemplo, você criou IA para determinada coisa eu vou lá ensino outra coisa, isso fica armazenado. Então se a IA gera uma coisa que é um problema, por exemplo, aí tem que ver, né? Porque, tipo, até onde eu vou apontar o dedo, pra quem eu vou apontar o dedo? até onde eu tolero quem fez isso? quem fez isso?  Então, eu não acho que dá para perguntar o dedo para uma pessoa específica, porque pode ter sido culpa do criador, pode ter sido culpa do usuário ou da empresa. Pode ser dos 3. Ou de todos. Debatedor 3. Não só complementar que pode ter sido culpa de tudinho e tudinho pra responder, né? pelo crime. Aí eu acho que entra no âmbito de fiscalização, criar regras. Porque quando ela cria quando a IA cria um problema ou alguma coisa que fere direito de alguém, quem vai ser culpado? Não tem isso, não tem uma regra falando, ninguém deve ser culpado e eu acho que não tem lei também, né? Então assim fica complicado culpar alguém. Eu acho que é também acho que é complicado culpar alguém. Mas, por exemplo, se um usuário é pedir para a gente, é gerar uma coisa de caráter racista, o usuário tem parte de culpa nisso, mas ele, a IA a IA tá gerando esse conteúdo, porque tem uma base de dados que tem esse caráter racista. Então, como o debatedor 1 falou, eu acho que pode ser culpa de de qualquer pessoa. Qualquer um, o desenvolvedor, a plataforma ou o usuário. E também acho que é aquilo que eu falei da ética na IA do da fiscalização, porque é todos os crimes assim é, < erro podem gerar/> podem ser gerados por  IA, porque como debatedor 3 falou , por exemplo, a história de acabar com a fome no mundo, é pode gerar um crime pelopela IA. Indo para outra perspectiva, a gente pode ver parte de culpa do criador, porque como ele criou, ele pode limitar também. Ele pode limitar a IA, então porque ele não limitou isso? Para quando ele recebesse, ela retorna: \"não, isso aqui não é legal, então não vou te responder, não vou aprender isso\". Então eu acho que é assim, parte tem como eu não criar. Não pode ter sido tipo, não intencionalmente, mas porque não me limitar se vai ver ferir o direito de alguém, se não é construtivo para ninguém? Nem para a IA, nem para ele. Debatedor 3. Mas e porquê limitar? Porque limitando você está limitando o processo de desenvolvimento. Logo, talvez ela desenvolvesse para fazer algo, ficaria patinando no mesmo ciclo, não desenvolvesse como a IA tivesse toda a liberdade, poderia desenvolver. Eu acho que se tiver alguma coisa assim, que fere algum direito de alguém, é poderia ser, não limitado, mas mas, dado uma resposta, por exemplo: \"Ah, não vou é... criar conteúdos desse caráter, por conta disso, disso e disso, é, mas ele vai ter a base de dados. O debatedor 3, falou sobre liberdade do aprendizado da IA. Mas até que ponto uma Liberdade para aprender uma coisa que não é construtiva para ninguém, que fere o direito do outro, até onde isso é liberdade de aprender? Porque não faz sentido. Tu pega, por exemplo, saindo de IA, aplicativo como Instagram, como Twitter, eles já reconhecem conteúdos que são racistas, conteúdos com teor pornográfico. Eles reconhecem. Então IA pode muito bem reconhecer isso. E assim: \"não, bloqueia isso. Eu não vou reter esse conhecimento e não vou retornar nada\", mesmo que o usuário volte lhe pedindo, ele não retorne nada, até porque não faz sentido. Que tipo de conhecimento amplo, é esse que você pode aprender uma coisa que fere o outro? Alguém mais quer falar sobre esse ponto? Pois bem, vamos para a segunda pergunta para o debatedor 2.  IAs generativas podem ser usadas nos processos educacionais? por exemplo, em aulas em aula, atividades ou provas, o  ou a aluna deve reportar ao professor sobre o uso de IA generativas em  suas atividades. Eu imagino que sim, que pode ser usado, que a IA, por exemplo, eu estava com dúvida em uma questão, e eu estava pensando de uma forma e ela me ajudou a ter um raciocínio de outra forma, mas não copiando tudo. Pode ser, pode ser usado para é ajuda de raciocínios, mas eu acho que nos processos educacionais, os professores, os docentes, qualquer coisa, eles estão se restringindo muito do leque de possibilidades que a IA poderia dar ao a aulas, por exemplo, é uma aula mais interativa ou ajuda, ou pesquisas com os alunos por meio da IA, como uma ferramenta tipo Google. Só que usando GPT, por exemplo, eu acho que ele se restringe muito. No sentido de restrição, não deve ser restringido, mas aí a gente volta pra ética e pro pro seu senso de uso, tanto de professor como do aluno, porque você está usando para quê? Até que ponto aquilo ali é seu? Até que ponto lhe ajudou? então, dependendo do que você pediu, quanto que você fez? você pegou o resultado que a IA  deu para quê? Então tem que ser eu eu não acho que tem que ser restringido, tem que ser aberto a todo a todos, tanto para professor quanto ao aluno, mas com uso responsável. OK, é, eu não vou generalizar tanto. 50% das pessoas não fazem. Eu conheço um bocado de pessoas que, ah, não sei pergunta do chatGPT, me bota a resposta lá, né, Atividade, principalmente no momento de pandemia, é essa coisa muito, muito mais forms lá da vida que só queria a resposta, não importava como você fez.Eu vi muita gente usando desses artifício para passar, tirar notas boas e depois no final, não saber nem o que fez. E inclusive, questão de redações que é, é um negócio que eu tive uma experiência bem de perto mesmo. Algumas pessoas pegam, mandam chatGPT, fazem a redação de qualquer tema. Ele vai fazer, põe outro, 3 palavrinha, inverte o parágrafo outro e manda, tira notas boas. Acho que o conselho acadêmico, deveria haver um jeito também de fazer o chatGPT não dá a resposta pronta, mas mostrar como faz. Eu acho que é tipo um chatGPT acadêmico, né? Seria inovador, diria.  Então o debatedor 3 concorda que deveria ser restringido? Não, restringido não, criada uma nova ferramenta específica para a educação. Mas isso é restringir o uso das IAs, não? Você poderá restringir dentro da escola, mas você vai ter a outra justamente de provas. Eu acho que seria importante. Mas o que garante que você mesmo entenda essa nova ferramenta assim, tipo, um filtros limitadores, o que garante que a pessoa não vai usar a outra. É muito leve e aberto. Mas quando você, você parte para a ética, o uso de uma IA normal sem ter filtro nem limitação, você usando com ética é responsabilidade já seria uso correto, não concorda?  Por exemplo, tem o chatGPT como exemplo. Ele é uma base de dados, então ele não está 100% correto o tempo todo. Então eu já vi gente reclamando: \"Ah, eu usei uma IA generativa e a resposta deu estava errada.\" Só que você é, além de você, tem que ter o seu senso e saber o que você está falando. Exatamente o que ela falou, porque se tu pega, se tu pega e se tu pergunta uma coisa e tu tem um resultado e tu pega ali e usa, tu vai estar pondo em risco tua integridade, a tua ética. E você não está confirmando se aquilo ali é realmente completamente verídico, porque como já a como eu já havia falado, ela está aprendendo, ela está aprendendo coisa errada também. Eu não estou sempre dando resultado e tu não verifica a  responsabilidade é tua. Alguém mais gostaria de falar algo sobre? Pois bem, então passaremos a terceira pergunta para o debatedor 3, de que maneira a propriedade intelectual deve ser tratada quando o conteúdo é gerado por uma IA, por exemplo, se o usuário gerou uma música usando IA, o crédito pela criação deve ser o deste usuário? da plataforma utilizada? do criador dos dados originais com o com os quais aí já foi treinada? Eis uma grande dúvida. É há muita discussão sobre isso. Modéstia à parte, eu acho que como a IA aprende com quem está interagindo com ela eu acho que Mesmo que houvesse uma divisão, não, eu que fiz a IA eu quero 20%, sei lá, 10% dos créditos da música. Acho que a maior parte deve deve ser para uma pessoa que ela Foi treinada mesmo, mesmo que uma parte pequena, assim 10, 5% for para a plataforma e outros 10% por criador da IA acho que a maior parte tem que ir para quem a treinou. O usuário que interagiu com ela para criar essa música.  Eu acho que a criação de música pelo IA, usando outras músicas de ser pensado da mesma forma que, por exemplo, na indústria da música, atualmente eles usam a interpolação. Eu acho que É uma parte, vai para o criador original e a outra o útil parte dos números da música vai para quem fez uma pegada diferente com essa música, por exemplo. Só que eu acho que tem que partir para essa parte legal é da mesma forma que as interpolações são feitas e eu não acho que ainda deve, aí,  dinheiro para a plataforma de IA, porque ela é só um meio que o usuário está usando para criar aquilo. Acho uma pergunta um pouco aberta, porque quando você usa uma plataforma, por exemplo, de IA, mais difundido chatGPT, ela tem, ela tem regras, tem condições que você aceita. Então, dependendo do que tem nessas condições, nessas regras que ela passa e você vai está lá e aceita, do que você aceitou, você, você, se você não lembra, você está se propondo a correr o risco de, dependendo do que ela gerou, você vai partir para ela, para o criador. E outra coisa, por exemplo, se um usuário gerar uma música, usando IA, aí é o questionamento, até onde, aliás, gerou a música e que partes ela fez. Ela adicionou palavras? ela ajudou você no raciocínio? como é que a gente, como é que isso vai ser fiscalizado? Então eu acho eu tem que ser vários pontos analisados até chegar ao veredito de quem vai ser quem vai ser creditado por isso. Agora eu vou fazer uma pergunta direcionada a todo grupo, qualquer um dos debatedores podem responder. O uso e o desenvolvimento de IA generativas devem ser fortemente fiscalizados por órgãos governamentais, ou elas são apenas mais um tipo de software comum como milhares de outros existentes?  Eu acho que uma resposta deve ser fortemente fiscalizada como a música , porque até como todo o nosso impacto foi o debate foi em relação a isso que deve haver a fiscalização da deve-se usar os IAs, mas com a forte fiscalização. Mas a fiscalização tem que ser governamental? porque, porque a no país, no Brasil, onde estamos, a fiscalização governamental é falha. Então assim, eu acho que ele é um software comum e dependendo do seu uso, dependendo do que você fez, você tem uma consequência. Eu acho que o onde é que o governo tem que entrar, dependendo da situação, da conjuntura atual ou do futuro, criar regras, alguma regra ou ou algo do tipo, mas não fiscalizar fortemente, porque essa fiscalização fortemente em algum momento, ela vai vir, ela vai ser limitante pra IA. Então, até que ponto fiscalizar fortemente? É, eu vou concordar com ele que falou, no Brasil que nós vivemos o pessoal joga o lixo fora do lixo do lado do lixo, então não vai funcionar aí eu acho que, como os países têm  vou caçar aqui a  palavra culturas diferentes de cada um puder definir de uma forma diferente, até que ponto nós temos um IA porque cada cultura tem seus princípios seus, seus culturas, suas a cultura em geral. Cada povo tem sua cultura e para algumas culturas, pode ser bom algo e para outros não. Aí, tipo, num país a IA é fiscalizada pelo governo e o governo disse não, você não pode ensinar o pessoal como criar um avião. E a outra disse que tem que ensinar o pessoal. Acho que vai dar errado, vai dar errado. Vão ter duas IAs diferentes no caso, viu? Eu acho que para dar fé tem que ser uma IA universal e as mesmas regras em todos os países. Aí que se tem alguns que podem ser moldadas, né? De acordo com a situação, mas, nesse partindo desse eu acho que tem que ser pouco... pouco fiscalizada, mas tem algumas regras, sejam universais para todas. Tem que existir lá a regra universal para todas, OK? Mas eu não [INAUDÍVEL]. Nenhuma pessoa de assunto informando o governo porque porque pode ser falha, pode ser instintiva e pode é de Liberdade. Mais alguém gostaria de comentar algo? Não? Pois bem, então agora, certo, nós partimos para a última fase do debate em que cada participante terá um momento para falar suas considerações finais sobre o tema, sua opinião ou visão sobre o tema. No geral, então sua opinião ou visão sobre o tema mudou depois do debate ou se fortaleceu ou ou algum tipo? Fortaleceu. Opinião é a mesmo: uso aberto, uso livre, uso consciente, consciente de consequência, uma regra ou outra. Fiscalização governador não. Continua a mesma também, mas eu acredito na fiscalização governamental, porque é se não houver uma fiscalização, que órgão, que vai, é... ser geral para toda a sociedade?. Por que que você acha de que para o  governo?  porque as próprias empresas, criadores de IA, não criam um meio, um órgão que que fiscalize e que e que reja? porque tem que vir no governo, sabes? Essa, esse órgão vindo de empresas não seria facilmente burlado, não? Mas o que que? Mas o que garante que a fiscalização governamental seria menos falha do que uma privada? Porque eu penso em uma fiscalização privada, como talvez tinha que ter, talvez um pouquinho do dedo do governo para ser um mediador de todas as empresas que criam IAs por exemplo, aí pode ser OK, mas só o governo fiscalizado não é pouco, é inviável. Pensando nisso, tá partindo da daquele exemplo, lá é do que eu falei logo no início, da fome aí a pessoa manda um processo generativo lá para a empresa e ela passa pelo governo e o governo olha. Tá bacana? Vai, vai solucionar a fome. A empresa vai aí a empresa começar a distribuir essa IA e implementar nos computadores. Dentro do governo dá certo? A pergunta é um pouco vaga porque o nosso plano de governo atual é bonito. Só que na prática que a gente vê coisa, então é. É a fiscalização em si. Por isso que eu falei, eu acho que o governo teria minimamente só consciência, no máximo. Entrar como mediador? talvez. Porque não faz sentido, porque nada garante seja uma situação só o governamental, seja fiscalização de empresa privada ou um consenso mundial. De qualquer forma, ela vai ser falha. Ninguém garante que ela vai ser completamente uma fiscalização completamente OK. Porque outra coisa, tu acha que a fiscalização, ela seria melhor pelo governo? Não, eu acho que seria ruim, mas impô-las em alguns cantos. Acho que vai depender muito do governo que está regendo a região, porque se for um governo que vai implementa as leis eprocura resolver os problemas, pode ser uma fiscalização plausível, né? Mas aí, se um governo agir com descaso, não, vai ser muito invariável. Até eu pensei agora uma junção dos 2, fase um fazer dois, passou pela fase do governo, aí passa pelos testes, entre aspas, da empresa que criou. Eu pensei na fiscalização do governo porque traz a universalidade em todas essas empresas, de IA entendeu? Como os debatedores Estavam falando, é, cada empresa pode ter diferentes morais e éticas que podem passando por diferentes coisas, não? E eu coloquei, em tese na minha fala, um governo que funciona perfeitamente, então pensei normal, Que é falho. Talvez, talvez iniciativa público-privada seria uma boa assim, a depender da circunstância e da forma que ela vai ser criada. Porque falar de fiscalização de IA, principalmente na época atual, que a gente está vivendo, que ela estão tendo o boom que está começando a ser estudado amplamente. Entao não seja uma boa hora, Agora. Mas em algum momento deve-se existir e deve ser adversado. Como isso vai funcionar? Como isso vai agir? Não dá para você chegar e falar:  \"Ah, eu acho que a fiscalização tem que ser assim, assim\" porque ele nunca vai, nunca vai abrir todo o mundo vai ter pontos negativos sempre, sempre. Bem, nesse caso, retomamos a pergunta final, né? Porque a gente acabou voltando ao assunto anterior, é? Houve uma mudança de visão? quais são as suas considerações finais sobre o tema? Essa mudança ocorreu depois do debate? poder livre, aberto, talvez um dedo do governo aí e possivelmente uma fiscalização público-privada. continua a mesmo, mas eu pensei na ideia dos debatedores, e é, eu ainda acredito na fiscalização governamental por conta da universalidade. Mas tem que ter o dedo de mais pessoas. Mudou-se um pouco a minha ideia.É Levando em conta que ainda IA estar aprendendo muito ainda. É, eu concordei que não agora, né? Mas depois de um certo conhecimento de como essa IA vai se comportar e entender melhor. Ela. Talvez existe uma certa fiscalização público privada. Entendi. Pois bem, gente, estamos chegando ao final, né? Do nosso debate. Então vocês podem é escanear esse quer para um formulário de autoavaliação, bemrapidinho. E as respostas são confidenciais e serão utilizadas só para os fins de avaliação e aprimoramento, no geral, não.\n","\n","Disfluências Encontradas:\n"," [('hes', 'a'), ('hes', 'a'), ('hes', 'a'), ('hes', 'é'), ('hes', 'é'), ('hes', 'a'), ('erro', 'colocação final sobre o exemplo, se tem algo que é, enfim,'), ('corr', 'colocação final.'), ('hes', 'E'), ('hes', 'E'), ('erro', 'Não só'), ('corr', 'a IA generativa,'), ('hes', 'e'), ('erro', 'e não é nem controle'), ('corr', 'acho que é importante a fiscalização'), ('erro', 'tem gente,'), ('hes', 'é'), ('rep', 'grandes grandes'), ('hes', 'aaaah'), ('rep', 'não não'), ('hes', 'É'), ('hes', 'e'), ('hes', 'E'), ('hes', 'é'), ('hes', 'é'), ('hes', 'é'), ('hes', 'Ah'), ('rep', 'se se'), ('erro', 'quando ela cria'), ('hes', 'que'), ('hes', 'é'), ('hes', 'é'), ('rep', 'a IA a IA'), ('hes', 'é'), ('corr', 'podem ser'), ('hes', 'é'), ('erro', 'pelo'), ('corr', 'pela'), ('erro', 'Não'), ('corr', 'pode ter sido tipo'), ('rep', 'mas mas'), ('hes', 'é'), ('hes', 'é'), ('hes', 'ao'), ('rep', 'eu eu'), ('hes', 'que'), ('hes', 'E'), ('hes', 'É'), ('hes', 'É'), ('hes', 'aí'), ('hes', 'E'), ('hes', 'É'), ('hes', 'têm'), ('hes', 'palavra'), ('hes', 'suas'), ('hes', 'nesse'), ('hes', 'é'), ('hes', 'a'), ('hes', 'É'), ('hes', 'É')]\n"]}]},{"cell_type":"markdown","source":["# Faz uma limpeza para que o texto corrigido humanamente sem anotações de disfluência fique 100% livre de ruídos"],"metadata":{"id":"6CoLDMkY4Ew2"}},{"cell_type":"code","source":["\n","\n","def limpar_texto(texto):\n","    # Remover todas as tags <hes .../> e <erro .../> junto com seus conteúdos\n","    texto = re.sub(r'<hes.*?/>', '', texto)\n","    texto = re.sub(r'<erro.*?/>', '', texto)\n","\n","    # Manter o conteúdo dentro de <corr .../> e remover a tag\n","    texto = re.sub(r'<corr (.*?)\\/>', r'\\1', texto)\n","\n","    def remove_repeticoes(match):\n","        # Captura o conteúdo da tag <rep> e converte para minúsculas\n","        conteudo = match.group(1).strip().lower()\n","        # Divide o conteúdo em uma lista de palavras\n","\n","        # Remove pontuação do conteúdo\n","        conteudo = re.sub(r'[^\\w\\s]', '', conteudo)\n","        palavras = conteudo.split()\n","\n","        # String para armazenar as palavras únicas\n","        ocorrencia_unica = \"\"\n","        # Set para armazenar palavras únicas\n","        palavras_armazenadas = set()\n","\n","        # Percorre cada palavra do conteúdo original\n","        for palavra in palavras:\n","            # Adiciona a palavra se ela ainda não estiver em palavras_armazenadas\n","            if palavra not in palavras_armazenadas:\n","                palavras_armazenadas.add(palavra)\n","                ocorrencia_unica += palavra + \" \"\n","\n","        # Remove o espaço extra no final e retorna o resultado\n","        return ocorrencia_unica.strip()\n","\n","\n","    texto = re.sub(r'<rep (.*?)\\/>', remove_repeticoes, texto)\n","\n","    # Remover espaços extras gerados após as substituições\n","    texto = re.sub(r'\\s+', ' ', texto).strip()\n","\n","    return texto\n","\n","texto_limpo = limpar_texto(marked)\n","print(texto_limpo)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NQiXJVEBb0Ad","executionInfo":{"status":"ok","timestamp":1725285907455,"user_tz":180,"elapsed":18,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"outputId":"011e4387-6006-45ed-9705-8f1add8cd449"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Minha identificação é a número 1. Estou contribuindo com a pesquisa no Brasil. Minha identificação é a número 2. Estou contribuindo com a pesquisa no Brasil. Minha identificação é a número 3. Estou contribuindo com a pesquisa no Brasil. Então agora eu vou explicar basicamente, principal regra do debate, que é antes de mergulharmos em nossa discussão, é essencial. Todos compreendam o ensino, as regras de debate. Essas regras foram criadas para garantir o debate justo e ordenado para todos os envolvidos. A principal e a essencial regra é seminterrupções. Os debates não devem interromper uns aos outros entre nós alguém estiver falando. Se você deseja contribuir para a discussão ou oferecer um contrato médio, por favor, levante a mão e aguarde o moderador lhe conceder a palavra. Caso eu, uma vez que tenha sido autorizado a falar, você terá a palavra do Bandeirantes prestar seus pensamentos ou responder aos outros. Então, explicando o funcionamento, né? Do debate, nós vamos seguir ele, levar para o formato estruturado deveria ter, em 3 momentos distintos, cada um com seu propósito em regras específicas. No momento 1 abordaremos a questão principal do debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central, que é aquele que eu lhes mandei no momento. 2 haverá uma rodada de perguntas e respostas direcionadas para cada um dos debatedores abriramos espaço para os outros participantes contra-argumentários prestarem as suas opiniões sobre a resposta dada. Após as perguntas direcionadas, teremos uma última pergunta que será direcionada a todos, e nesse momento, vocês têm a Liberdade de escolher se desejam responder ou não e caso sintam, tem algo relevante a acrescentar também ou não? E no fim, o último momento será de de uma pergunta . Sobre a sua colocação final. Então a gravação já está sendo executada, certo? Quando alguém. primeiramente, para não terá um momento inicial para para expressar as suas principais opiniões e pensamento sobre o Temer. No caso, IA generativa a e cada participante terá um momento para fazer isso, começando pelo debatedor 1. Eu acho que com, num certo controle, ela contribuiu muito, principalmente pra a gente que é estudante, por ter um tutor particular, basicamemte. pras outras pessoas também, inclusive. a IA generativa, ela contribui no campo acadêmico, só que você com a IA, tem que também ter esse controle porque como ela aprende com a gente, também pode aprender coisa errada. Isso é um problema porque quando você tem um negócio, por exemplo o ChatGPT, como um público, que várias pessoas contribuiem, vai chegar um momento que vira bagunça , porque você pode contribuir com verdade mas pode vir alguém e cair por terra sua fala, então aí vira uma bagunça. acho que é importante a fiscalização é muito importante pro avanço de muita coisa. Acho que é isso, por hora. OK, agora o debatedor número 2. Então, eu acho que tem gente que é muito conservador em relação a IA, que é: \"Ah, eu sou contra totalmente, isso está acabando com a gente\". Mas como o debatedor 1 falou, tem que ser usado na medida certa e não só o chat GPT, mas também a IA para a formação de áudio de vídeo, de imagem. Tudo isso eu acho que tem muito a contribuir. Tipo, a gente, ajuda muita gente, só que No campo ético, eu acho que tem que ser muito bem pensado, porque pode ser usada para construir a grandes coisas, tipo em relação , sei lá, a uma cidade pode criar uma história de uma mentira que pode acabar com a vida assim, na sociedade, na cidade, aí no campo académico, eu também acho que tem gente que se aproveita exacerbadamente do uso da IA e não ajuda a IA raciocinar mais, raciocina Por ela, entendeu? Agora o Debatedor 3. Pois bem, eu compactuo diretamente com a opinião do número 1 e do número 2 mas penso que deva haver alguma meio de fiscalizar que essas IAs estão fazendo, porque elas vão seguir ao pé da letra o que você mandar, o que você programar para ela fazer. acho que é aí que mora o provável problema, né? Porque a partir do momento que uma pessoa programa uma IA pra fazer algo que em teoria traria o bem, mas se for seguido ao pé da letra pode fazer muito muito mal. Aí temos problemas. Um exemplo retirado direto da IA, que eu perguntei pro Chat GPT : Por exemplo, se uma empresa , mandou uma pessoa criar um código fontezinho só para implementar numa IA de maneira de acabar com a fome no mundo. Aí vai, implementa. Show de bola, começa a colocar esse IA. Poucos Meses depois alguns navios vão mudar de rota, porque eles são guiados pela IA, aviões que deveriam chegar com alimentos em lugares não vão chegar e algumas regiões vão ser dizimadas. Mas a IA tá cumprindo o papel dela. Se não há pessoas, não há fome. , eu acho que partindo dessa lógica, né? Tem que se haver o policiamento do que essas IAs estão fazendo. A partir do momento que começar a fazer mal à humanidade, tem que ter uma maneira de parar, dar um break, né? Vamos iniciar uma rodada de perguntas irei realizar uma pergunta para cada participante, que terá seu tempo de resposta e ao final de sua resposta, os demais podem pedir espaço para comentar algo sobre a pergunta feita ou então a resposta dada certo? Vamos começar. A primeira pergunta para o debatedor 1. Se um sistema Ia generativa criar criar algo prejudicial ou ofensivo, por exemplo, uma imagem com conteúdo racista, quem deve ser responsabilizado? O desenvolvedor da IA? usuário? a plataforma que hospeda ou alguma outra instituição ou pessoa. É isso. Aí você me pega porque é muita gente. É inteligência artificial, ela, aprende com a gente. Então, se alguém ensinou ela fazer uma coisa específica, ela vai aprender. Então assim foi, por exemplo, você criou IA para determinada coisa eu vou lá ensino outra coisa, isso fica armazenado. Então se a IA gera uma coisa que é um problema, por exemplo, aí tem que ver, né? Porque, tipo, até onde eu vou apontar o dedo, pra quem eu vou apontar o dedo? até onde eu tolero quem fez isso? quem fez isso? Então, eu não acho que dá para perguntar o dedo para uma pessoa específica, porque pode ter sido culpa do criador, pode ter sido culpa do usuário ou da empresa. Pode ser dos 3. Ou de todos. Debatedor 3. Não só complementar que pode ter sido culpa de tudinho e tudinho pra responder, né? pelo crime. Aí eu acho que entra no âmbito de fiscalização, criar regras. Porque quando a IA cria um problema ou alguma coisa que fere direito de alguém, quem vai ser culpado? Não tem isso, não tem uma regra falando, ninguém deve ser culpado e eu acho que não tem lei também, né? Então assim fica complicado culpar alguém. Eu acho é também acho que é complicado culpar alguém. Mas, por exemplo, se um usuário pedir para a gente, gerar uma coisa de caráter racista, o usuário tem parte de culpa nisso, mas ele, a ia tá gerando esse conteúdo, porque tem uma base de dados que tem esse caráter racista. Então, como o debatedor 1 falou, eu acho que pode ser culpa de de qualquer pessoa. Qualquer um, o desenvolvedor, a plataforma ou o usuário. E também acho que é aquilo que eu falei da ética na IA do da fiscalização, porque é todos os crimes assim , < erro podem gerar/> podem ser gerados por IA, porque como debatedor 3 falou , por exemplo, a história de acabar com a fome no mundo, pode gerar um crime pela IA. Indo para outra perspectiva, a gente pode ver parte de culpa do criador, porque como ele criou, ele pode limitar também. Ele pode limitar a IA, então porque ele não limitou isso? Para quando ele recebesse, ela retorna: \"não, isso aqui não é legal, então não vou te responder, não vou aprender isso\". Então eu acho que é assim, parte tem como eu não criar. pode ter sido tipo, não intencionalmente, mas porque não me limitar se vai ver ferir o direito de alguém, se não é construtivo para ninguém? Nem para a IA, nem para ele. Debatedor 3. Mas e porquê limitar? Porque limitando você está limitando o processo de desenvolvimento. Logo, talvez ela desenvolvesse para fazer algo, ficaria patinando no mesmo ciclo, não desenvolvesse como a IA tivesse toda a liberdade, poderia desenvolver. Eu acho que se tiver alguma coisa assim, que fere algum direito de alguém, é poderia ser, não limitado, mas, dado uma resposta, por exemplo: \"Ah, não vou é... criar conteúdos desse caráter, por conta disso, disso e disso, , mas ele vai ter a base de dados. O debatedor 3, falou sobre liberdade do aprendizado da IA. Mas até que ponto uma Liberdade para aprender uma coisa que não é construtiva para ninguém, que fere o direito do outro, até onde isso é liberdade de aprender? Porque não faz sentido. Tu pega, por exemplo, saindo de IA, aplicativo como Instagram, como Twitter, eles já reconhecem conteúdos que são racistas, conteúdos com teor pornográfico. Eles reconhecem. Então IA pode muito bem reconhecer isso. E assim: \"não, bloqueia isso. Eu não vou reter esse conhecimento e não vou retornar nada\", mesmo que o usuário volte lhe pedindo, ele não retorne nada, até porque não faz sentido. Que tipo de conhecimento amplo, é esse que você pode aprender uma coisa que fere o outro? Alguém mais quer falar sobre esse ponto? Pois bem, vamos para a segunda pergunta para o debatedor 2. IAs generativas podem ser usadas nos processos educacionais? por exemplo, em aulas em aula, atividades ou provas, o ou a aluna deve reportar ao professor sobre o uso de IA generativas em suas atividades. Eu imagino que sim, que pode ser usado, que a IA, por exemplo, eu estava com dúvida em uma questão, e eu estava pensando de uma forma e ela me ajudou a ter um raciocínio de outra forma, mas não copiando tudo. Pode ser, pode ser usado para ajuda de raciocínios, mas eu acho que nos processos educacionais, os professores, os docentes, qualquer coisa, eles estão se restringindo muito do leque de possibilidades que a IA poderia dar a aulas, por exemplo, é uma aula mais interativa ou ajuda, ou pesquisas com os alunos por meio da IA, como uma ferramenta tipo Google. Só que usando GPT, por exemplo, eu acho que ele se restringe muito. No sentido de restrição, não deve ser restringido, mas aí a gente volta pra ética e pro pro seu senso de uso, tanto de professor como do aluno, porque você está usando para quê? Até que ponto aquilo ali é seu? Até que ponto lhe ajudou? então, dependendo do que você pediu, quanto que você fez? você pegou o resultado que a IA deu para quê? Então tem que ser eu não acho que tem que ser restringido, tem que ser aberto a todo a todos, tanto para professor quanto ao aluno, mas com uso responsável. OK, é, eu não vou generalizar tanto. 50% das pessoas não fazem. Eu conheço um bocado de pessoas que, ah, não sei pergunta do chatGPT, me bota a resposta lá, né, Atividade, principalmente no momento de pandemia, é essa coisa muito, muito mais forms lá da vida que só queria a resposta, não importava como você fez.Eu vi muita gente usando desses artifício para passar, tirar notas boas e depois no final, não saber nem o que fez. E inclusive, questão de redações que é, é um negócio que eu tive uma experiência bem de perto mesmo. Algumas pessoas pegam, mandam chatGPT, fazem a redação de qualquer tema. Ele vai fazer, põe outro, 3 palavrinha, inverte o parágrafo outro e manda, tira notas boas. Acho que o conselho acadêmico, deveria haver um jeito também de fazer o chatGPT não dá a resposta pronta, mas mostrar como faz. Eu acho que é tipo um chatGPT acadêmico, né? Seria inovador, diria. Então o debatedor 3 concorda que deveria ser restringido? Não, restringido não, criada uma nova ferramenta específica para a educação. Mas isso é restringir o uso das IAs, não? Você poderá restringir dentro da escola, mas você vai ter a outra justamente de provas. Eu acho que seria importante. Mas o garante que você mesmo entenda essa nova ferramenta assim, tipo, um filtros limitadores, o que garante que a pessoa não vai usar a outra. É muito leve e aberto. Mas quando você, você parte para a ética, o uso de uma IA normal sem ter filtro nem limitação, você usando com ética é responsabilidade já seria uso correto, não concorda? Por exemplo, tem o chatGPT como exemplo. Ele é uma base de dados, então ele não está 100% correto o tempo todo. Então eu já vi gente reclamando: \"Ah, eu usei uma IA generativa e a resposta deu estava errada.\" Só que você é, além de você, tem que ter o seu senso e saber o que você está falando. Exatamente o que ela falou, porque se tu pega, se tu pega e se tu pergunta uma coisa e tu tem um resultado e tu pega ali e usa, tu vai estar pondo em risco tua integridade, a tua ética. você não está confirmando se aquilo ali é realmente completamente verídico, porque como já a como eu já havia falado, ela está aprendendo, ela está aprendendo coisa errada também. Eu não estou sempre dando resultado e tu não verifica a responsabilidade é tua. Alguém mais gostaria de falar algo sobre? Pois bem, então passaremos a terceira pergunta para o debatedor 3, de que maneira a propriedade intelectual deve ser tratada quando o conteúdo é gerado por uma IA, por exemplo, se o usuário gerou uma música usando IA, o crédito pela criação deve ser o deste usuário? da plataforma utilizada? do criador dos dados originais com o com os quais aí já foi treinada? Eis uma grande dúvida. há muita discussão sobre isso. Modéstia à parte, eu acho que como a IA aprende com quem está interagindo com ela eu acho que Mesmo que houvesse uma divisão, não, eu que fiz a IA eu quero 20%, sei lá, 10% dos créditos da música. Acho que a maior parte deve deve ser para uma pessoa que ela Foi treinada mesmo, mesmo que uma parte pequena, assim 10, 5% for para a plataforma e outros 10% por criador da IA acho que a maior parte tem que ir para quem a treinou. O usuário que interagiu com ela para criar essa música. Eu acho que a criação de música pelo IA, usando outras músicas de ser pensado da mesma forma que, por exemplo, na indústria da música, atualmente eles usam a interpolação. Eu acho que uma parte, vai para o criador original e a outra o útil parte dos números da música vai para quem fez uma pegada diferente com essa música, por exemplo. Só que eu acho que tem que partir para essa parte legal é da mesma forma que as interpolações são feitas e eu não acho que ainda deve, , dinheiro para a plataforma de IA, porque ela é só um meio que o usuário está usando para criar aquilo. Acho uma pergunta um pouco aberta, porque quando você usa uma plataforma, por exemplo, de IA, mais difundido chatGPT, ela tem, ela tem regras, tem condições que você aceita. Então, dependendo do que tem nessas condições, nessas regras que ela passa e você vai está lá e aceita, do que você aceitou, você, você, se você não lembra, você está se propondo a correr o risco de, dependendo do que ela gerou, você vai partir para ela, para o criador. outra coisa, por exemplo, se um usuário gerar uma música, usando IA, aí é o questionamento, até onde, aliás, gerou a música e que partes ela fez. Ela adicionou palavras? ela ajudou você no raciocínio? como é que a gente, como é que isso vai ser fiscalizado? Então eu acho eu tem que ser vários pontos analisados até chegar ao veredito de quem vai ser quem vai ser creditado por isso. Agora eu vou fazer uma pergunta direcionada a todo grupo, qualquer um dos debatedores podem responder. O uso e o desenvolvimento de IA generativas devem ser fortemente fiscalizados por órgãos governamentais, ou elas são apenas mais um tipo de software comum como milhares de outros existentes? Eu acho que uma resposta deve ser fortemente fiscalizada como a música , porque até como todo o nosso impacto foi o debate foi em relação a isso que deve haver a fiscalização da deve-se usar os IAs, mas com a forte fiscalização. Mas a fiscalização tem que ser governamental? porque, porque a no país, no Brasil, onde estamos, a fiscalização governamental é falha. Então assim, eu acho que ele é um software comum e dependendo do seu uso, dependendo do que você fez, você tem uma consequência. Eu acho que o onde é que o governo tem que entrar, dependendo da situação, da conjuntura atual ou do futuro, criar regras, alguma regra ou ou algo do tipo, mas não fiscalizar fortemente, porque essa fiscalização fortemente em algum momento, ela vai vir, ela vai ser limitante pra IA. Então, até que ponto fiscalizar fortemente? , eu vou concordar com ele que falou, no Brasil que nós vivemos o pessoal joga o lixo fora do lixo do lado do lixo, então não vai funcionar aí eu acho que, como os países vou caçar aqui a culturas diferentes de cada um puder definir de uma forma diferente, até que ponto nós temos um IA porque cada cultura tem seus princípios seus, seus culturas, a cultura em geral. Cada povo tem sua cultura e para algumas culturas, pode ser bom algo e para outros não. Aí, tipo, num país a IA é fiscalizada pelo governo e o governo disse não, você não pode ensinar o pessoal como criar um avião. E a outra disse que tem que ensinar o pessoal. Acho que vai dar errado, vai dar errado. Vão ter duas IAs diferentes no caso, viu? Eu acho que para dar fé tem que ser uma IA universal e as mesmas regras em todos os países. Aí que se tem alguns que podem ser moldadas, né? De acordo com a situação, mas, partindo desse eu acho que tem que ser pouco... pouco fiscalizada, mas tem algumas regras, sejam universais para todas. Tem que existir lá a regra universal para todas, OK? Mas eu não [INAUDÍVEL]. Nenhuma pessoa de assunto informando o governo porque porque pode ser falha, pode ser instintiva e pode é de Liberdade. Mais alguém gostaria de comentar algo? Não? Pois bem, então agora, certo, nós partimos para a última fase do debate em que cada participante terá um momento para falar suas considerações finais sobre o tema, sua opinião ou visão sobre o tema. No geral, então sua opinião ou visão sobre o tema mudou depois do debate ou se fortaleceu ou ou algum tipo? Fortaleceu. Opinião é a mesmo: uso aberto, uso livre, uso consciente, consciente de consequência, uma regra ou outra. Fiscalização governador não. Continua a mesma também, mas eu acredito na fiscalização governamental, porque se não houver uma fiscalização, que órgão, que vai, é... ser geral para toda a sociedade?. Por que que você acha de que para o governo? porque as próprias empresas, criadores de IA, não criam um meio, um órgão que que fiscalize e que e que reja? porque tem que vir no governo, sabes? Essa, esse órgão vindo de empresas não seria facilmente burlado, não? Mas o que que? Mas o que garante que fiscalização governamental seria menos falha do que uma privada? Porque eu penso em uma fiscalização privada, como talvez tinha que ter, talvez um pouquinho do dedo do governo para ser um mediador de todas as empresas que criam IAs por exemplo, aí pode ser OK, mas só o governo fiscalizado não é pouco, é inviável. Pensando nisso, tá partindo da daquele exemplo, lá é do que eu falei logo no início, da fome aí a pessoa manda um processo generativo lá para a empresa e ela passa pelo governo e o governo olha. Tá bacana? Vai, vai solucionar a fome. A empresa vai aí a empresa começar a distribuir essa IA e implementar nos computadores. Dentro do governo dá certo? A pergunta é um pouco vaga porque o nosso plano de governo atual é bonito. Só que na prática que a gente vê coisa, então é. É a fiscalização em si. Por isso que eu falei, eu acho que o governo teria minimamente só consciência, no máximo. Entrar como mediador? talvez. Porque não faz sentido, porque nada garante seja uma situação só o governamental, seja fiscalização de empresa privada ou um consenso mundial. De qualquer forma, ela vai ser falha. Ninguém garante que ela vai ser completamente uma fiscalização completamente OK. Porque outra coisa, tu acha que a fiscalização, ela seria melhor pelo governo? Não, eu acho que seria ruim, mas impô-las em alguns cantos. Acho que vai depender muito do governo que está regendo a região, porque se for um governo que vai implementa as leis eprocura resolver os problemas, pode ser uma fiscalização plausível, né? Mas aí, se um governo agir com descaso, não, vai ser muito invariável. Até eu pensei agora uma junção dos 2, fase um fazer dois, passou pela fase do governo, aí passa pelos testes, entre aspas, da empresa que criou. Eu pensei na fiscalização do governo porque traz a universalidade em todas essas empresas, de IA entendeu? Como os debatedores Estavam falando, é, cada empresa pode ter diferentes morais e éticas que podem passando por diferentes coisas, não? E eu coloquei, em tese na minha fala, um governo que funciona perfeitamente, então pensei normal, Que é falho. Talvez, talvez iniciativa público-privada seria uma boa assim, a depender da circunstância e da forma que ela vai ser criada. Porque falar de fiscalização de IA, principalmente na época atual, que a gente está vivendo, que ela estão tendo o boom que está começando a ser estudado amplamente. Entao não seja uma boa hora, Agora. Mas em algum momento deve-se existir e deve ser adversado. Como isso vai funcionar? Como isso vai agir? Não dá para você chegar e falar: \"Ah, eu acho que a fiscalização tem que ser assim, assim\" porque ele nunca vai, nunca vai abrir todo o mundo vai ter pontos negativos sempre, sempre. Bem, nesse caso, retomamos a pergunta final, né? Porque a gente acabou voltando ao assunto anterior, é? Houve uma mudança de visão? quais são as suas considerações finais sobre o tema? Essa mudança ocorreu depois do debate? poder livre, aberto, talvez um dedo do governo aí e possivelmente uma fiscalização público-privada. continua a mesmo, mas eu pensei na ideia dos debatedores, e é, eu ainda acredito na fiscalização governamental por conta da universalidade. Mas tem que ter o dedo de mais pessoas. Mudou-se um pouco a minha ideia. Levando em conta que ainda IA estar aprendendo muito ainda. , eu concordei que não agora, né? Mas depois de um certo conhecimento de como essa IA vai se comportar e entender melhor. Ela. Talvez existe uma certa fiscalização público privada. Entendi. Pois bem, gente, estamos chegando ao final, né? Do nosso debate. Então vocês podem é escanear esse quer para um formulário de autoavaliação, bemrapidinho. E as respostas são confidenciais e serão utilizadas só para os fins de avaliação e aprimoramento, no geral, não.\n"]}]},{"cell_type":"markdown","source":["# Contador de Disfluências Removidas"],"metadata":{"id":"OKYj9oxTe4iw"}},{"cell_type":"code","source":["def contar_ocorrencias_texto(texto, dicionario):\n","    # Inicializando o dicionário de contagem de ocorrências\n","    ocorrencias_llm = {key: 0 for key in dicionario}\n","\n","    # Adiciona espaços ao redor do texto para capturar padrões no início e fim\n","    texto = f\" {texto} \"\n","\n","    # Pontuações consideradas após o padrão\n","    pontuacoes = r'[,.!?;:]?'\n","\n","    # Iterando sobre as chaves do dicionário\n","    for chave in dicionario:\n","        # Adiciona espaços ao redor da chave e permite pontuações depois da chave\n","        padrao = rf' {re.escape(chave)}{pontuacoes} '\n","        # Usando expressão regular para encontrar todas as ocorrências da chave no texto\n","        ocorrencias = re.findall(padrao, texto)\n","        # Atualizando a contagem no dicionário 'ocorrencias_llm'\n","        ocorrencias_llm[chave] = len(ocorrencias)\n","\n","    return ocorrencias_llm\n","\n","def subtrair_dicionarios(dict1, dict2):\n","    # Inicializando o dicionário de resultado para a diferença\n","    resultado = {}\n","\n","    # Conjunto de todas as chaves presentes em ambos os dicionários\n","    todas_chaves = set(dict1.keys()).union(set(dict2.keys()))\n","\n","    # Calculando a diferença para cada chave\n","    for chave in todas_chaves:\n","        # Contagem em dict1 (dicionário original)\n","        contagem1 = dict1.get(chave, 0)\n","        # Contagem em dict2 (dicionário resultante)\n","        contagem2 = dict2.get(chave, 0)\n","        # Calculando a diferença\n","        diferenca = contagem1 - contagem2\n","        # Adicionando ao dicionário de resultado apenas se a diferença for não zero\n","        if diferenca != 0:\n","            resultado[chave] = diferenca\n","\n","    return resultado\n","\n","def preenche_dic_disfluentes(disfluencias):\n","  # Inicializando os dicionários de hesitações, repetições, erros e correções\n","    hes = {}\n","    rep = {}\n","    erro = {}\n","    corr = {}\n","\n","    # Preenchendo os dicionários 'hes', 'rep', 'erro' e 'corr'\n","    for tag, content in disfluencias:\n","        if tag == 'hes':\n","            hes[content] = hes.get(content, 0) + 1\n","        elif tag == 'rep':\n","            rep[content] = rep.get(content, 0) + 1\n","        elif tag == 'erro':\n","            erro[content] = erro.get(content, 0) + 1\n","        elif tag == 'corr':\n","            corr[content] = corr.get(content, 0) + 1\n","\n","    return hes, rep, erro, corr\n","hes, rep, erro, corr = preenche_dic_disfluentes(disfluencias)\n","\n","def count_disfluencias_in_clean(clean_text, hes, rep, erro, corr):\n","        # Contando ocorrências no texto\n","    hes_llm = contar_ocorrencias_texto(clean_text, hes)\n","    rep_llm = contar_ocorrencias_texto(clean_text, rep)\n","    erro_llm = contar_ocorrencias_texto(clean_text, erro)\n","    corr_llm = contar_ocorrencias_texto(clean_text, corr)\n","\n","\n","    return hes_llm, rep_llm, erro_llm, corr_llm\n","\n"],"metadata":{"id":"fHMdHUT4gnWK","executionInfo":{"status":"ok","timestamp":1725285907455,"user_tz":180,"elapsed":8,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Código para fazer o balanço da limpeza da LLM"],"metadata":{"id":"LOaeIJ3IyyGn"}},{"cell_type":"code","source":["def count_matches(manual_dict, llm_dict):\n","    \"\"\"\n","    Counts how many times the LLM correction matches the manual correction.\n","\n","    Args:\n","    - manual_dict (dict): The dictionary with the manual correction.\n","    - llm_dict (dict): The dictionary with the LLM correction.\n","\n","    Returns:\n","    - int: The count of keys with matching values.\n","    \"\"\"\n","    # Initialize the counter for matches\n","    matches = 0\n","    length_of_incorrect_matches = 0\n","\n","    # Iterate through all keys in the manual correction dictionary\n","    for key in manual_dict:\n","        # Check if the key exists in the LLM correction dictionary and has the same value\n","        if key in llm_dict and manual_dict[key] == llm_dict[key]:\n","            matches += 1  # Increment the counter if the values match\n","        else:\n","          errors = abs(manual_dict[key] - llm_dict[key])\n","          length_of_incorrect_matches += abs(len(key)) * errors\n","    return matches, length_of_incorrect_matches\n","\n","def calcular_metricas(acertos, total_chaves):\n","    \"\"\"\n","    Calcula as métricas de comparação entre acertos da LLM e o total de chaves.\n","\n","    Args:\n","    - acertos (int): Número de acertos da LLM.\n","    - total_chaves (int): Número total de chaves no dicionário manual.\n","\n","    Returns:\n","    - porcentagem_acertos (float): Percentual de acertos da LLM.\n","    - erros (int): Número de chaves que a LLM não identificou corretamente.\n","    \"\"\"\n","    porcentagem_acertos = (acertos / total_chaves) * 100 if total_chaves > 0 else 0\n","    erros = total_chaves - acertos\n","    return porcentagem_acertos, erros\n","\n","def exibir_metricas(resultados):\n","    \"\"\"\n","    Exibe as métricas de comparação entre a LLM e o manual para cada categoria.\n","\n","    Args:\n","    - resultados (dict): Dicionário com as categorias e tuplas de (acertos, total_chaves).\n","    \"\"\"\n","    total_acertos = 0\n","    total_chaves = 0\n","    categorias_erro = ['Repetições', 'Hesitações', 'Erros']\n","\n","    # Calcula e exibe as métricas para cada categoria\n","    for categoria, (acertos, total) in resultados.items():\n","        porcentagem_acertos, erros = calcular_metricas(acertos, total)\n","        print(f'{categoria}:')\n","        print(f'  Acertos da LLM: {acertos}')\n","        print(f'  Total de chaves no manual: {total}')\n","        print(f'  Porcentagem de acertos: {porcentagem_acertos:.2f}%')\n","        print(f'  Número de chaves não corretamente identificadas: {erros}')\n","        print()\n","\n","        # Somando para o cálculo da média de acertos\n","        if categoria in categorias_erro:\n","            total_acertos += acertos\n","            total_chaves += total\n","\n","    # Calcula a porcentagem média de acertos para as categorias de erro\n","    media_acertos = (total_acertos / total_chaves) * 100 if total_chaves > 0 else 0\n","    print(f'Média de porcentagem de acertos entre Hesitações, Erros e Repetições: {media_acertos:.2f}%')\n"],"metadata":{"id":"K6VPlVWiy116","executionInfo":{"status":"ok","timestamp":1725285907455,"user_tz":180,"elapsed":7,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Código para mensurar as alterações e integridade"],"metadata":{"id":"o2W-_Q-x7gKr"}},{"cell_type":"code","source":["def calculate_metrics(original, processed):\n","    # Calcula a distância de Levenshtein\n","    levenshtein_distance = Levenshtein.distance(original, processed)\n","\n","    # Calcula a similaridade de Levenshtein\n","    levenshtein_similarity = Levenshtein.ratio(original, processed)\n","\n","    # Calcula a distância de edição\n","    edit_distance = Levenshtein.distance(original, processed)\n","\n","    original_length = len(original)\n","    processed_length = len(processed)\n","\n","    original_word_count = len(original.split())\n","    processed_word_count = len(processed.split())\n","\n","    return {\n","        'Levenshtein Distance': f'{levenshtein_distance:,}',\n","        'Levenshtein Similarity': f'{levenshtein_similarity * 100:.2f}%',\n","        'Edit Distance': f'{edit_distance:,}',\n","        'Original Length': f'{original_length:,}',\n","        'Processed Length': f'{processed_length:,}',\n","        'Original Word Count': f'{original_word_count:,}',\n","        'Processed Word Count': f'{processed_word_count:,}'\n","    }\n","\n","\n","def adjust_levenshtein_distance(data, not_to_be_considered):\n","    \"\"\"\n","    Adjusts the Levenshtein Distance by excluding a specified number of edits\n","    and recalculates the Levenshtein Similarity.\n","\n","    Parameters:\n","    data (dict): A dictionary containing Levenshtein metrics:\n","                 {'Levenshtein Distance': str, 'Processed Length': str}\n","    not_to_be_considered (int): The number of edits that should not be considered.\n","\n","    Returns:\n","    dict: A dictionary with the adjusted Levenshtein Distance and Similarity.\n","    \"\"\"\n","    # Extract values from the dictionary and convert them to integers\n","    levenshtein_distance = int(data['Levenshtein Distance'].replace(',', ''))\n","    processed_length = int(data['Processed Length'].replace(',', ''))\n","\n","    # Adjust the Levenshtein Distance\n","    adjusted_distance = levenshtein_distance - not_to_be_considered\n","\n","    # Recalculate the Levenshtein Similarity\n","    adjusted_similarity = (1 - (adjusted_distance / processed_length)) * 100\n","\n","    # Return the adjusted values as a dictionary\n","    return {\n","        'Adjusted Levenshtein Distance': adjusted_distance,\n","        'Adjusted Levenshtein Similarity': f'{adjusted_similarity:.2f}%'\n","    }\n"],"metadata":{"id":"j7QpUbqu7j2d","executionInfo":{"status":"ok","timestamp":1725286441911,"user_tz":180,"elapsed":368,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["# Prompt 1.1 (Zero-shot no context)"],"metadata":{"id":"PJS9yuGDHpk8"}},{"cell_type":"code","source":["prompt = f\"\"\"\n","Please remove disfluencies from the following Portuguese text transcription without changing the original text.\n","Ensure that aside from the removal of this disfluencies, no other changes are made to the text. You should NOT change text that does not refer to disfluencies. ANY text that is not in one of those three categories of disfluencies should not be changed. Return only the cleaned text with no additional information. Remember the text must be in its original full size, but without the disfluencies in it.\n","\n","\n","Text: {texto_disfluente}\n","\"\"\"\n","response1, duration1 = get_response_and_time(prompt)\n","\n","print(response1.text)\n","print('A limpeza foi feita em ', duration1)"],"metadata":{"id":"vyxII3TtHtgd","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1725286012606,"user_tz":180,"elapsed":105157,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"outputId":"67194e8c-43ee-4e0f-f636-cc0ce81e7fc6"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Minha identificação é a número 1. Estou contribuindo com a pesquisa no Brasil. Minha identificação é a número 2. Estou contribuindo com a pesquisa no Brasil. Minha identificação é a número 3. Estou contribuindo com a pesquisa no Brasil. Então agora eu vou explicar basicamente a principal regra do debate, que é: antes de mergulharmos em nossa discussão, é essencial que todos compreendam o ensino, as regras de debate. Essas regras foram criadas para garantir um debate justo e ordenado para todos os envolvidos. A principal e essencial regra é: sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando. Se você deseja contribuir para a discussão ou oferecer um contraponto, por favor, levante a mão e aguarde o moderador lhe conceder a palavra. Uma vez que tenha sido autorizado a falar, você terá a palavra para prestar seus pensamentos ou responder aos outros.\n","Então, explicando o funcionamento do debate, nós vamos seguir o formato estruturado, dividido em 3 momentos distintos, cada um com seu propósito e regras específicas. No momento 1, abordaremos a questão principal do debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central, que é aquele que eu lhes mandei. No momento 2, haverá uma rodada de perguntas e respostas direcionadas para cada um dos debatedores, abriremos espaço para os outros participantes contra-argumentar e prestarem as suas opiniões sobre a resposta dada.\n","Após as perguntas direcionadas, teremos uma última pergunta que será direcionada a todos e, nesse momento, vocês têm a liberdade de escolher se desejam responder ou não e, caso sintam, têm algo relevante a acrescentar também ou não.\n","E no fim, o último momento será de uma pergunta sobre a sua colocação final sobre o exemplo, se tem algo que é, enfim, colocação final.\n","Então a gravação já está sendo executada, certo? Primeiramente, para, terá um momento inicial para expressar as suas principais opiniões e pensamentos sobre o tema. No caso, IA generativa e cada participante terá um momento para fazer isso, começando pelo debatedor 1. Eu acho que com um certo controle, ela contribui muito, principalmente para a gente que é estudante, por ter um tutor particular, basicamente. E para as outras pessoas também, inclusive. Não só a IA generativa, ela contribui no campo acadêmico, só que você, com a IA, tem que também ter esse controle, porque como ela aprende com a gente, também pode aprender coisa errada. Isso é um problema, porque quando você tem um negócio, por exemplo, o ChatGPT, como um público, que várias pessoas contribuem, vai chegar um momento que vira bagunça, porque você pode contribuir com verdade, mas pode vir alguém e cair por terra sua fala, então aí vira uma bagunça. E não é nem controle, acho que é importante, a fiscalização é muito importante para o avanço de muita coisa. Acho que é isso, por hora.\n","OK, agora o debatedor número 2. Então, eu acho que tem gente que é muito conservador em relação à IA, que é: \"Ah, eu sou contra totalmente, isso está acabando com a gente\". Mas como o debatedor 1 falou, tem que ser usado na medida certa e não só o ChatGPT, mas também a IA para a formação de áudio, de vídeo, de imagem. Tudo isso eu acho que tem muito a contribuir. Tipo, a gente ajuda muita gente, só que no campo ético, eu acho que tem gente, tem que ser muito bem pensado, porque pode ser usada para construir grandes coisas, tipo em relação a, sei lá, a uma cidade, pode criar uma história, uma mentira que pode acabar com a vida, assim, na sociedade, na cidade. Aí no campo acadêmico, eu também acho que tem gente que se aproveita exacerbadamente do uso da IA e não ajuda a IA a raciocinar mais, raciocina por ela, entendeu? \n","Agora o debatedor 3. Pois bem, eu compactuo diretamente com a opinião do número 1 e do número 2, mas penso que deva haver algum meio de fiscalizar o que essas IAs estão fazendo, porque elas vão seguir ao pé da letra o que você mandar, o que você programar para ela fazer. E acho que é aí que mora o provável problema, né? Porque a partir do momento que uma pessoa programa uma IA para fazer algo que em teoria traria o bem, mas se for seguido ao pé da letra pode fazer muito mal. Aí temos problemas. Um exemplo retirado direto da IA, que eu perguntei para o ChatGPT é: por exemplo, se uma empresa mandou uma pessoa criar um código para implementar numa IA, de maneira de acabar com a fome no mundo. Aí vai, implementa. Show de bola, começa a colocar essa IA. Poucos meses depois, alguns navios vão mudar de rota, porque eles são guiados pela IA, aviões que deveriam chegar com alimentos em lugares não vão chegar e algumas regiões vão ser dizimadas. Mas a IA está cumprindo o papel dela: se não há pessoas, não há fome. Ah, eu acho que partindo dessa lógica, tem que se haver o policiamento do que essas IAs estão fazendo. A partir do momento que começar a fazer mal à humanidade, tem que ter uma maneira de parar, dar um break, né?\n","Vamos iniciar uma rodada de perguntas. Irei realizar uma pergunta para cada participante, que terá seu tempo de resposta e, ao final de sua resposta, os demais podem pedir espaço para comentar algo sobre a pergunta feita ou então a resposta dada, certo? Vamos começar. A primeira pergunta para o debatedor 1: se um sistema de IA generativa criar algo prejudicial ou ofensivo, por exemplo, uma imagem com conteúdo racista, quem deve ser responsabilizado? O desenvolvedor da IA, o usuário, a plataforma que hospeda ou alguma outra instituição ou pessoa? É isso aí, você me pega, porque é muita gente. É inteligência artificial, ela aprende com a gente. Então, se alguém ensinou ela a fazer uma coisa específica, ela vai aprender. Então, assim, foi, por exemplo, você criou a IA para determinada coisa, eu vou lá e ensino outra coisa, isso fica armazenado. Então se a IA gera uma coisa que é um problema, por exemplo, aí tem que ver, né? Porque, tipo, até onde eu vou apontar o dedo? Para quem eu vou apontar o dedo? Até onde eu tolero quem fez isso? Quem fez isso? Então, eu não acho que dá para apontar o dedo para uma pessoa específica, porque pode ter sido culpa do criador, pode ter sido culpa do usuário ou da empresa. Pode ser dos 3 ou de todos. \n","Debatedor 3. Não, só complementar que pode ter sido culpa de tudinho e tudinho para responder pelo crime. Aí eu acho que entra no âmbito de fiscalização, criar regras. Porque quando ela cria, quando a IA cria um problema ou alguma coisa que fere o direito de alguém, quem vai ser culpado? Não tem isso, não tem uma regra falando: ninguém deve ser culpado. E eu acho que não tem lei também, né? Então, assim, fica complicado culpar alguém. Eu acho que é, também acho que é complicado culpar alguém. Mas, por exemplo, se um usuário pedir para a gente gerar uma coisa de caráter racista, o usuário tem parte de culpa nisso, mas ele, a IA está gerando esse conteúdo porque tem uma base de dados que tem esse caráter racista. Então, como o debatedor 1 falou, eu acho que pode ser culpa de qualquer pessoa, qualquer um: o desenvolvedor, a plataforma ou o usuário. E também acho que é aquilo que eu falei da ética na IA, da fiscalização, porque todos os crimes podem ser gerados por IA, porque, como o debatedor 3 falou, por exemplo, a história de acabar com a fome no mundo, pode gerar um crime pela IA. Indo para outra perspectiva, a gente pode ver parte de culpa do criador, porque como ele criou, ele pode limitar também. Ele pode limitar a IA. Então, por que ele não limitou isso? Para quando ele recebesse, ela retornar: \"Não, isso aqui não é legal, então não vou te responder, não vou aprender isso\". Então eu acho que é assim, parte tem como eu não criar, não pode ter sido, tipo, não intencionalmente, mas por que não me limitar se vai ver ferir o direito de alguém, se não é construtivo para ninguém? Nem para a IA, nem para ele.\n","Debatedor 3. Mas e por que limitar? Porque limitando você está limitando o processo de desenvolvimento. Logo, talvez ela desenvolvesse para fazer algo, ficaria patinando no mesmo ciclo, não desenvolvesse como se a IA tivesse toda a liberdade, poderia desenvolver. Eu acho que se tiver alguma coisa assim que fere algum direito de alguém, poderia ser, não limitado, mas dado uma resposta, por exemplo: \"Ah, não vou criar conteúdos desse caráter por conta disso, disso e disso\". Mas ele vai ter a base de dados.\n","O debatedor 3 falou sobre liberdade do aprendizado da IA, mas até que ponto uma liberdade para aprender uma coisa que não é construtiva para ninguém, que fere o direito do outro, até onde isso é liberdade de aprender? Porque não faz sentido. Tu pega, por exemplo, saindo de IA, aplicativo como Instagram, como Twitter, eles já reconhecem conteúdos que são racistas, conteúdos com teor pornográfico. Eles reconhecem. Então, IA pode muito bem reconhecer isso e assim: \"Não, bloqueia isso. Eu não vou reter esse conhecimento e não vou retornar nada\", mesmo que o usuário volte lhe pedindo, ele não retorne nada, até porque não faz sentido. Que tipo de conhecimento amplo é esse que você pode aprender uma coisa que fere o outro? \n","Alguém mais quer falar sobre esse ponto? Pois bem, vamos para a segunda pergunta, para o debatedor 2. IAs generativas podem ser usadas nos processos educacionais? Por exemplo, em aulas, em atividades ou provas? O aluno deve reportar ao professor sobre o uso de IAs generativas em suas atividades? Eu imagino que sim, que pode ser usado, que a IA, por exemplo, eu estava com dúvida em uma questão e eu estava pensando de uma forma e ela me ajudou a ter um raciocínio de outra forma, mas não copiando tudo. Pode ser, pode ser usado para ajuda de raciocínios, mas eu acho que nos processos educacionais, os professores, os docentes, qualquer coisa, eles estão se restringindo muito do leque de possibilidades que a IA poderia dar ao, a aulas, por exemplo, uma aula mais interativa ou ajuda ou pesquisas com os alunos por meio da IA, como uma ferramenta tipo Google, só que usando GPT, por exemplo. Eu acho que ele se restringe muito. No sentido de restrição, não deve ser restringido, mas aí a gente volta para a ética e para o seu senso de uso, tanto de professor como do aluno, porque você está usando para quê? Até que ponto aquilo ali é seu? Até que ponto lhe ajudou? Então, dependendo do que você pediu, quanto que você fez, você pegou o resultado que a IA deu para quê? Então tem que ser, eu não acho que tem que ser restringido, tem que ser aberto a todo, a todos, tanto para professor quanto ao aluno, mas com uso responsável.\n","OK. Eu não vou generalizar tanto, 50% das pessoas não fazem. Eu conheço um bocado de pessoas que: \"Ah, não sei, pergunta do ChatGPT, me bota a resposta lá, né?\". Atividade, principalmente no momento de pandemia, essa coisa muito, muito mais forms lá da vida, que só queria a resposta, não importava como você fez. Eu vi muita gente usando desses artifícios para passar, tirar notas boas e depois, no final, não saber nem o que fez. E inclusive, questão de redações, que é um negócio que eu tive uma experiência bem de perto mesmo. Algumas pessoas pegam, mandam para o ChatGPT, fazem a redação de qualquer tema. Ele vai fazer, põe outro, 3 palavrinhas, inverte o parágrafo outro e manda, tira notas boas. Acho que o conselho acadêmico deveria haver um jeito também de fazer o ChatGPT não dar a resposta pronta, mas mostrar como faz. Eu acho que é, tipo, um ChatGPT acadêmico, né? Seria inovador, diria.\n","Então o debatedor 3 concorda que deveria ser restringido? Não, restringido não, criada uma nova ferramenta específica para a educação. Mas isso é restringir o uso das IAs, não? Você poderá restringir dentro da escola, mas você vai ter a outra justamente de provas. Eu acho que seria importante. Mas o que garante que você mesmo entenda essa nova ferramenta, assim, tipo, um filtros limitadores? O que garante que a pessoa não vai usar a outra? É muito leve e aberto. Mas quando você, você parte para a ética, o uso de uma IA normal, sem ter filtro nem limitação, você usando com ética e responsabilidade já seria o uso correto, não concorda? Por exemplo, tem o ChatGPT como exemplo. Ele é uma base de dados, então ele não está 100% correto o tempo todo. Então eu já vi gente reclamando: \"Ah, eu usei uma IA generativa e a resposta que deu estava errada\". Só que você é, além de você, tem que ter o seu senso e saber o que você está falando. Exatamente o que ela falou, porque se tu pega, se tu pega e se tu pergunta uma coisa e tu tem um resultado e tu pega ali e usa, tu vai estar pondo em risco tua integridade, a tua ética. E você não está confirmando se aquilo ali é realmente completamente verídico, porque, como já, como eu já havia falado, ela está aprendendo, ela está aprendendo coisa errada também. Eu não estou sempre dando resultado e tu não verifica, a responsabilidade é tua. \n","Alguém mais gostaria de falar algo sobre? Pois bem, então passaremos à terceira pergunta para o debatedor 3. De que maneira a propriedade intelectual deve ser tratada quando o conteúdo é gerado por uma IA? Por exemplo, se o usuário gerou uma música usando IA, o crédito pela criação deve ser o deste usuário, da plataforma utilizada, do criador dos dados originais com os quais a IA foi treinada? Eis uma grande dúvida. Há muita discussão sobre isso. Modéstia à parte, eu acho que como a IA aprende com quem está interagindo com ela, eu acho que, mesmo que houvesse uma divisão: \"Não, eu que fiz a IA, eu quero 20%, sei lá, 10% dos créditos da música\". Acho que a maior parte deve, deve ser para a pessoa que ela foi treinada mesmo, mesmo que uma parte pequena, assim, 10, 5% for para a plataforma e outros 10% para o criador da IA, acho que a maior parte tem que ir para quem a treinou, o usuário que interagiu com ela para criar essa música.\n","Eu acho que a criação de música pela IA usando outras músicas deve ser pensado da mesma forma que, por exemplo, na indústria da música atualmente, eles usam a interpolação. Eu acho que é uma parte, vai para o criador original e a outra parte dos números da música vai para quem fez uma pegada diferente com essa música, por exemplo. Só que eu acho que tem que partir para essa parte legal da mesma forma que as interpolações são feitas e eu não acho que ainda deva dinheiro para a plataforma de IA, porque ela é só um meio que o usuário está usando para criar aquilo.\n","Acho uma pergunta um pouco aberta, porque quando você usa uma plataforma, por exemplo, de IA, mais difundido, ChatGPT, ela tem, ela tem regras, tem condições que você aceita. Então, dependendo do que tem nessas condições, nessas regras que ela passa e você vai, está lá e aceita, do que você aceitou, você, você, se você não lembra, você está se propondo a correr o risco de, dependendo do que ela gerou, você vai partir para ela, para o criador. E outra coisa, por exemplo, se um usuário gerar uma música usando IA, aí é o questionamento, até onde, aliás, gerou a música e que partes ela fez. Ela adicionou palavras? Ela ajudou você no raciocínio? Como é que a gente, como é que isso vai ser fiscalizado? Então eu acho, eu, tem que ser vários pontos analisados até chegar ao veredito de quem vai ser, quem vai ser creditado por isso.\n","Agora eu vou fazer uma pergunta direcionada a todo o grupo, qualquer um dos debatedores podem responder. O uso e o desenvolvimento de IAs generativas devem ser fortemente fiscalizados por órgãos governamentais ou elas são apenas mais um tipo de software comum como milhares de outros existentes? Eu acho que uma resposta deve ser fortemente fiscalizada como a música, porque, até como todo o nosso impacto foi, o debate foi em relação a isso, que deve haver a fiscalização, deve-se usar as IAs, mas com a forte fiscalização.\n","Mas a fiscalização tem que ser governamental? Porque, porque, no país, no Brasil, onde estamos, a fiscalização governamental é falha. Então, assim, eu acho que ele é um software comum e, dependendo do seu uso, dependendo do que você fez, você tem uma consequência. Eu acho que o, onde é que o governo tem que entrar, dependendo da situação, da conjuntura atual ou do futuro, criar regras, alguma regra ou algo do tipo, mas não fiscalizar fortemente, porque essa fiscalização fortemente, em algum momento, ela vai vir, ela vai ser limitante para a IA. Então, até que ponto fiscalizar fortemente?\n","É, eu vou concordar com ele que falou, no Brasil que nós vivemos, o pessoal joga o lixo fora do lixo, do lado do lixo, então não vai funcionar. Aí eu acho que, como os países têm, vou caçar aqui a palavra, culturas diferentes, cada um pode definir de uma forma diferente até que ponto nós temos uma IA, porque cada cultura tem seus princípios, seus, seus culturas, suas, a cultura em geral. Cada povo tem sua cultura e para algumas culturas pode ser bom algo e para outros não. Aí, tipo, num país, a IA é fiscalizada pelo governo e o governo disse: \"Não, você não pode ensinar o pessoal como criar um avião\". E a outra disse que tem que ensinar o pessoal. Acho que vai dar errado, vai dar errado. Vão ter duas IAs diferentes, no caso, viu? Eu acho que para dar certo, tem que ser uma IA universal e as mesmas regras em todos os países. Aí que se tem algumas que podem ser moldadas de acordo com a situação, mas nesse, partindo desse, eu acho que tem que ser pouco, pouco fiscalizada, mas tem algumas regras, sejam universais para todas. Tem que existir lá a regra universal para todas, OK? Mas eu não, nenhuma pessoa de assunto informando o governo, porque, porque pode ser falha, pode ser instintiva e pode, de liberdade.\n","Mais alguém gostaria de comentar algo? Não? Pois bem, então agora, certo, nós partimos para a última fase do debate, em que cada participante terá um momento para falar suas considerações finais sobre o tema, sua opinião ou visão sobre o tema no geral. Então, sua opinião ou visão sobre o tema mudou depois do debate ou se fortaleceu ou algum tipo? Fortaleceu. Opinião é a mesma: uso aberto, uso livre, uso consciente, consciente de consequência, uma regra ou outra. Fiscalização governamental não. Continua a mesma também, mas eu acredito na fiscalização governamental, porque é, se não houver uma fiscalização, que órgão que vai ser geral para toda a sociedade? Por que que você acha de que para o governo? Porque as próprias empresas, criadores de IA, não criam um meio, um órgão que que fiscalize e que e que reja? Porque tem que vir no governo, sabe? Esse, esse órgão vindo de empresas não seria facilmente burlado, não? Mas o que que? Mas o que garante que a fiscalização governamental seria menos falha do que uma privada? Porque eu penso em uma fiscalização privada, como, talvez tinha que ter, talvez um pouquinho do dedo do governo para ser um mediador de todas as empresas que criam IAs, por exemplo. Aí pode ser OK, mas só o governo fiscalizado não, é pouco, é inviável. Pensando nisso, está partindo daquele exemplo lá do que eu falei logo no início, da fome, aí a pessoa manda um processo generativo lá para a empresa e ela passa pelo governo e o governo olha: \"Tá bacana? Vai, vai solucionar a fome\". A empresa vai, aí a empresa começa a distribuir essa IA e implementar nos computadores dentro do governo. Dá certo? A pergunta é um pouco vaga, porque o nosso plano de governo atual é bonito, só que na prática que a gente vê coisa, então é, é a fiscalização em si. Por isso que eu falei, eu acho que o governo teria minimamente só consciência, no máximo. Entrar como mediador? Talvez. Porque não faz sentido, porque nada garante, seja uma situação só governamental, seja fiscalização de empresa privada ou um consenso mundial. De qualquer forma, ela vai ser falha. Ninguém garante que ela vai ser completamente uma fiscalização completamente OK. Porque outra coisa, tu acha que a fiscalização, ela seria melhor pelo governo? Não, eu acho que seria ruim, mas impô-las em alguns cantos. Acho que vai depender muito do governo que está regendo a região, porque se for um governo que vai implementar as leis e procura resolver os problemas, pode ser uma fiscalização plausível, né? Mas aí, se um governo agir com descaso, não, vai ser muito invariável. Até eu pensei agora uma junção dos 2, fase um, fazer dois, passou pela fase do governo, aí passa pelos testes, entre aspas, da empresa que criou. Eu pensei na fiscalização do governo porque traz a universalidade em todas essas empresas de IA, entendeu? Como os debatedores estavam falando, cada empresa pode ter diferentes morais e éticas que podem passando por diferentes coisas, não? E eu coloquei, em tese, na minha fala, um governo que funciona perfeitamente, então pensei normal, que é falho. Talvez, talvez iniciativa público-privada seria uma boa assim, a depender da circunstância e da forma que ela vai ser criada. Porque falar de fiscalização de IA, principalmente na época atual que a gente está vivendo, que ela estão tendo o boom, que está começando a ser estudado amplamente, então não seja uma boa hora agora. Mas em algum momento deve-se existir e deve ser adversado. Como isso vai funcionar? Como isso vai agir? Não dá para você chegar e falar: \"Ah, eu acho que a fiscalização tem que ser assim, assim\", porque ele nunca vai, nunca vai abrir, todo o mundo vai ter pontos negativos sempre, sempre.\n","Bem, nesse caso, retomamos a pergunta final, né? Porque a gente acabou voltando ao assunto anterior, é? Houve uma mudança de visão? Quais são as suas considerações finais sobre o tema? Essa mudança ocorreu depois do debate? Poder livre, aberto, talvez um dedo do governo aí e possivelmente uma fiscalização público-privada. Continua a mesma, mas eu pensei na ideia dos debatedores e eu ainda acredito na fiscalização governamental por conta da universalidade. Mas tem que ter o dedo de mais pessoas. Mudou-se um pouco a minha ideia. Levando em conta que ainda a IA está aprendendo muito ainda. É, eu concordei que não agora, né? Mas depois de um certo conhecimento de como essa IA vai se comportar e entender melhor ela, talvez exista uma certa fiscalização público-privada. Entendi.\n","Pois bem, gente, estamos chegando ao final do nosso debate. Então vocês podem escanear esse QR Code para um formulário de autoavaliação, bem rapidinho. E as respostas são confidenciais e serão utilizadas só para os fins de avaliação e aprimoramento, no geral, não.\n","\n","A limpeza foi feita em  105.1439561843872\n"]}]},{"cell_type":"markdown","source":["## prompt"],"metadata":{"id":"tlgCwgUS8iY_"}},{"cell_type":"code","source":["prompt_1 = \"\"\"Gravação iniciada. Minha identificação é o número aluno um, estou contribuindo para a pesquisa no Brasil. Minha identificação é aluno 2, estou contribuindo para a pesquisa no Brasil. Minha identificação é a número 3. Estou contribuindo com a pesquisa no Brasil. Minha eficação é o número 4. Estou contribuindo com a pesquisa do Brasil. Minha identificação número 5, estou contribuindo com a pesquisa no Brasil. Excelente. Pois bem, agora eu explicarei as regras deste debate, e então, antes de mergulharmos em nossa discussão, é essencial. Todos compreendam e sigam as reuniões de debate. Essas regras foram ampliadas para garantir um debate justo e ordenado para todos os envolvidos. A única principal regra é: sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando. Se você deseja contribuir para alguma discussão ou oferecer um contra argumento, por favor, levante a mão e aguarde um moderador, no caso eu lhe conceder a palavra, uma vez que tenha sido autorizada a palavra, você terá a palavra e poderá expressar seus pensamentos ou responder aos outros. vamos seguir um formato estruturado dividido em 3 momentos distintos, cada um com seu propósito e regras específicas. No primeiro momento abordaremos a questão principal no debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central. Que foi aquele tema que lhes foi enviado. No segundo momento teremos uma rodada de perguntas direcionadas para cada um dos debatedores. Abriremos espaço para outros participantes contra argumentar, ou espressarem as suas opiniões sobre a resposta dada após as perguntas direcionadas, teremos uma última pergunta que será direcionada a todos os participantes, nesse momento, vocês têm a Liberdade de escolher se desejam responder ou não e só caso tenham algo no caso sintam que tem algo relevante a acrescentar. Por fim, no terceiro momento, será perguntado se os participantes têm alguma outra colocação final sobre o tema. Então cada um de vocês terá esse movimento inicial para expressar suas principais opiniões e pensamentos sobre o tema. E o tema é, esse que aí está e que foi também lhes enviado, então começando do debatedor número 1. Quais são as suas opiniões iniciais sobre o tema? Uma opinião inicial é que, conforme vai crescendo na inteligência artificial e se não for assim, não foi controlado o público que a utiliza, as pessoas vão acabar se dependendo, dependendo de mais dela, por causa de vai acabar usando ela para fazer qualquer coisa na vamos ver, o estudante vai usar a inteligência artificial para fazer as questões por de algum professor e vai acabar não se dedicando para aprender o assunto. Assim vai acabar sendo muito dependente dela e não vai acabar crescendo quase nada, na sociedade. Debatedor número 2. Eu acredito que o uso da da inteligência artificial de forma benigna, pode como o próprio já diz, causar um bem no sentido, por exemplo, aplicativos que utilizam da inteligência artificial, da IA, para produzir, por exemplo, na questão da construção civil, que pode utilizar para a questão de produção de planta baixa ou de outros projetos arquitetônicos nesse sentido olhando essa visão, eu acredito que é um uso com um bem explícito, mas que também depende, por exemplo, do seu uso como o debatedor 1 falou poderia no caso do estudante que ele começa a depender demais da da inteligência artificial, no nosso caso mais atual, por exemplo, o ChatGPT que para responder as perguntas de seja de exercício ou atividades, enfim, começa a depender o uso demasiado da inteligência artificial e pelo contrário não provocam bem a si mesmo. Ele está degenerando a si mesmo. Está seu tá agravando seu processo de de desconstrução de conhecimento, é isso que é isso que eu defendo, é a questão do uso mais moderado. Debatedor número 3. Eu acredito que a IA como qualquer outra tecnologia, ela vai ela vai ser útil para facilitar a nossa vida, mas como nas outras tecnologias, também tem que ser usado de uma da forma certa. Durante a guerra a gente viu que usou a tecnologia para fazer mal para a sociedade, a IA pode ser a mesma, pode ser usado para a mesma coisa e pode fazer um mal para você próprio. Então acho que ela deve ser usada, mas também tem que ser empregado no ponto de como usar ela da maneira certa, tem que ensinar as pessoas a usar da maneira correta. Debatedor número 4 Sinto que é necessário criar uma verificação no que está sendo passada para ela, uma vez que sem um limite eu posso infringir a própria ética no caso de criar, por exemplo, deep face, né? Fake news que é desenvolver né imagens né alteradas, então foi pelo. Acho que é bom é que exista uma evolução na na IA, mas deve ter assim, uma verificação, pra que que está sendo passado para ela não seja nada que infrinja a ética, a moral, como um todo. Debatedor número 5 Bem, eu acredito que esse, na verdade, é um assunto bastante delicado, né? É pessoas de diversas áreas, vão ter opiniões que divergem uma das outras É, mas como qualquer outra coisa, é o seu uso de forma imprópria é pode causar desses problemas, né? Então, é o uso de inteligência artificial, tem que ser definitivamente, tem que ser pensado antes de ser usado, né? Você não pode usar de uma forma indevida, ainda mais que ainda não está dentro de um de uma lei. Se, como você pode usar, como você não pode, então imagino que seja um assunto bem delicado. Pois bem, nós estaremos agora, então a rodada de perguntas, certo? A primeira rodada de perguntas. E nela eu irei realizar uma pergunta para cada um dos participantes, que terá seu tempo de resposta ao final da sua, ao final da sua resposta, onde os demais terão, é espaço para comentar algo sobre a pergunta ou a resposta dada. Então, vamos começar. A primeira pergunta para o levantador número 1. Se o sistema de IA generativo criar algo prejudicial ou ofensivo, por exemplo, uma imagem com conteúdo racista, quem deve ser responsabilizada? Desenvolvedor da IA, o usuário, a plataforma que hospeda com alguma outra instituição pessoa? Debatedor número 1. Acredito que seja um único, acredito que seja o usuário, que seja responsabilizado por causa que como já foi dito, pelo debatedor 3, número 3 a sobre a opinião dele, que a inteligência artificial se for utilizada de forma errada, acaba sendo mais a culpa da pessoa que está usando ela não de alguém que desenvolver, porque a pessoa que desenvolveu a internet artificial fez para com intuito de beneficiar a sociedade. Mas a pessoa que usou o usuário usou de forma errada e acaba fazendo alguma coisa prejudicial. Alguém tem algo a comentar sobre a resposta do debatedor um ou a pergunta em si. Tá, então passemos para a segunda pergunta para o debatedor número 2. IAs generativas podem ser usadas nos processos educacionais, por exemplo, em aulas, atividades ou provas, o ou a aluno ou a aluna deve reportar ao professor ou professora sobre o uso de IAs generativas em suas atividades? Eu acredito que pode ser utilizado sim, como qualquer outra tecnologia, a gente utiliza, por exemplo, em nossas atividades escolares acadêmicas. A questão do do uso da internet, por exemplo em sites de pesquisa,e a gente pode encontrar informações. Como a IA se baseia em um banco de dados gigante eu acredito que nós podemos utilizar no sentido de que podemos utilizá-la como fonte dessas informações, certo? Por exemplo, eu quero pesquisar, supondo, de uma forma bem grotesca sobre a questão da história da do Brasil. Eu Acredito que a IA vai nos fornecer é informações que serão necessárias ou muito importantes para o nosso crescimento, para o nosso crescimento intelectual de conhecimento e outra pergunta, o aluno deve reportar ao professor sobre o uso das IAs generativas em suas atividades? Eu lembro que se Eu Acredito que sim, como qualquer outro banco de dados que nós já vemos referir da onde a gente pegou essas informações. Eu acredito que é necessário também reportar ao professor, ao docente, o da onde a gente tirou essas informações. Alguém gostaria de comentar algo sobre a resposta dada ou a pergunta em si? Então passemos pra pergunta 3, ao debatedor número 3. De que maneira a propriedade intelectual deve ser tratada quando um conteúdo é gerado por uma IA? Por exemplo, se um usuário gerou uma música usando IA, o crédito pela criação deve ser o deste usuário? Da plataforma de IA utilizada? Do criador dos dados originais, com os quais a IA foi treinada? Ou de que?\n"," Não acredito que deva ser da IA porque a IA gerativa, ela é feita como uma base de dados muito gigantesca e ela vai fazer as coisas coisas novas, não vai replicar o que tem, ela vai aprender e vai replicar e vai criar coisas novas. Então, uma criação dela e uma criação de outras pessoas, ela, o crédito deve ser dela. Debatedor número 5 Eu imagino que seja, tenha créditos à inteligência artificial, mas que não totalmente, já que ela utiliza de um banco de dados, possivelmente ela vai estar pegando algo de outra pessoa e reutilizando, é de certa forma, então possivelmente, se você identifica é seus direitos autorais no que ela gerou, eu imagino que é o os direitos autorais você também tenha participação disso. Debatedor número 2. Como o debatedor falou, número 5, ele falou, é como se fosse uma árvore, né? Se a gente puxar, é de onde está havendo as informações sempre vai ter um crédito como ele falou, na questão do do do grande banco de dados, O o artistao músico que está procurando, é, criar uma nova música utilizando a inteligência artificial também deve ter seu crédito de certa forma, mas acredito também tanto os conteúdos é que estão dentro É da IA, do do banco de dados da IA também devem ser procurados de de onde foi que ela utilizou essas informações E, de certa forma, acredito que também até o os criadores do da IA também. Alguém mais, tem algo a comentar sobre a pergunta, sobre as respostas dadas? Não? Então sigamos para a pergunta 4 debatedor número 4. Como garantir que conteúdo gerados por IA não sejam usados para espelhar informações tendenciosas, errôneas ou maliciosas, por exemplo, quando esse tipo de informação é propagada massivamente por bots em uma rede social, a responsabilidade deve ser da empresa que administra a rede social, dos programadores da IA, de quem produziu aquele conteúdo usando a IA?   Eu prevejo que seja de quem produziu aquele conteúdo. Porque não minto minto que seja do da empresa o cara tem domínio né, daquela rede social de propagar aquilo que ela está passando. Então se passa uma informação que ela não consegue verificar, não consegue analisar que é justamente tendenciosa é errônea, né? Como uma imagem, né? Uma fake news, uma, um som, uma até uma, música que passe por assim sem ela perceber essa essa falha, né? Que pode dar na ética. Eu vejo que seja dela a essa essa falha, né não de que ade que a produziu, assim, quem produziu também, mas seria mais ela, que tá propagando. Debatedor 2 Eu Acredito também, assim como o debatedor 4, falou É, tem uma parcela em culpa da empresa em talvez propagar essa esse conteúdo de forma errônea ou de forma é replicada, mas também do próprio usuário que que produziu o conteúdo usando da IA. Acredito que a IA ela Não, não, não tem essa, tanto, essa parcela de culpa que que eu comparo com se fosse o carro, por exemplo, de forma grotesca, claro. Um carro, o criador de um automóvel, no caso ele não pensou naquelas pessoas, talvez muito provavelmente nas pessoas que poderiam utilizálo como 11 veículo de de de rachas na rua, por exemplo. Mas como uma forma de locomoção das pessoas e para um lugar, outros lugares et cetera, et cetera, mas que devido aos seus usuários, por exemplo, nós, quando nós utilizamos OOO nosso automóvel, assumimos essa essa responsabilidade de que, caso venha, venhamos a desrespeitar desrespeitar ou infringir leis de trânsitos, leis de trânsito perdão e assumirmos essas responsabilidades, assumimos essa culpa de talvez provocar um acidente e comparando de forma com o usuário que utiliza essa IA eu acredito que ele também deve ser responsabilizado. Por quê? Porque ele está assumindo de que quando ele produz esse conteúdo, é claro, é evidência evidencialmente vai ser 11 conteúdo é pejorativo, um conteúdo que é traz mal para a sociedade. Debatedor 5 Eu já para mim, eu não imagino que a empresa, a rede social que administra ela seria responsável, já que possivelmente vai haver algum algoritmo ele vai identificar aquilo, claro que existem métodos de filtragem para identificar se se é um, se é uma informação falsa ou não, mas é o algoritmo, só vai repassar para outras pessoas se as pessoas concordarem e curtirem compartilharem, repassarem para outras pessoas, então, eu imagino que é mais das pessoas que veem aquele conteúdo e de quem produziu esse conteúdo É a culpa de informações tendenciosas serem repassadas do que mesmo da responsabilidade da rede social, né? Já que, teoricamente, a rede social não foi feita para isso. Alguém tem algo a comentar sobre o que tinha dito ou sobre a pergunta? Então passemos a quinta pergunta ao debatedor número 5. Quais os impactos da IA no ambiente de trabalho, você acha que o uso de IAs generativas irá gerar ou destruir empregos, por exemplo, uma IA generativa que consegue fazer um trabalho de um arquiteto ou publicitário de forma mais rápida fará um trabalho totalmente confiável. É, eu imagino que E vai existir impactos dessa inteligência artificial, né no mercado de trabalho, mas isso acontece hoje em dia sempre aconteceu com diversas outras coisas existem diversos empregos que não existem mais porque foi criado algo novo, que é melhor, que é superado hoje em dia, por exemplo, não tem mais antigamente tinha um emprego nas naqueles lugares de jogar boliche, tinha um pessoal que organizava os pinos para você jogar de novo. Hoje em dia não é assim, mais não. Esse emprego não existe mais. Então, é enquanto a inteligência artificial estiver sendo é desenvolvida, é claro que você não pode confiar totalmente, né? É preciso que você tenha a é a inspeção de um arquiteto, de um cara que estudou para isso. Possivelmente a inteligência artificial vai ter arquitetos que vão ter, vão estar trabalhando em conjunto com programadores para desenvolver essa inteligência. Então, eu imagino que enquanto a inteligência artificial estiver evoluindo, a tendência é que ela esteja mais e mais confiável E diante disse empregos, se não forem atualizados, se não tiverem mais AA eficácia deixaram de existir. Alguém tem algo a comentar sobre esse ponto ou sobre a resposta dada? Bem, então passamos agora para a pergunta livre. A, lembrando que vocês podem responder ou não. Uso e o desenvolvimento de áreas narrativas devem ser fortemente fiscalizados por órgãos governamentais ou elas são apenas mais um tipo de software comum, como milhares de outros existentes? Debatedor número 5. É bastante adverso. Sim, elas devem ser fiscalizadas, mas não fortemente. Até porque tem que ter algum, alguma parte criativa naquilo, né? Se for totalmente fiscalizado, talvez você trave você pare o desenvolvimento daquilo, que você torne lento. O desenvolvimento disso, se você não corr Claro que a fiscalização é importante/> justamente por outros motivos, direitos autorais, tudo mais, mas é, se for fortemente, é fiscalizado, é A gente vai deixar de evoluir? Basicamente a gente vai deixar de ter um desenvolvimento mais rápido simplesmente por conta que o governo está fiscalizando e ele não deixa por conta N motivos, né? Então, imagino que deve ser fiscalizado, mas até certo ponto. Alguém mais gostaria de responder a pergunta ou comentar sobre o que foi dito? Bem, então agora cada participante terá um momento para falar suas considerações finais sobre o tema, sua opinião ou visão sobre o tema mudou depois do debate? Começando do debatedor número 1, você tem alguma coisa sobre para falar mais sobre o tema? Tem alguma concentração final, senão, você sua ou visão ou opinião mudou sobre o tema de IAs generativas depois do debate? Não. Debatedor 2 Eu acredito, só, para, a título de conclusão final, acredito que a inteligência artificial, assim como qualquer outra tecnologia, assim como na comparação que eu fiz como automóveis, de forma, grotesca, é claro, mas, ela pode auxiliar, ela vai auxiliar a sociedade na criação de, de, na produção de, de n coisas. No entanto, que deve ter assim um cuidado sim, uma fiscalização para que não torne essa, essa produção de forma demasiada ou que acabe por gerar, é, algo algo que não produza benefícios, pelo contrário, produza malefícios para a sociedade na questão, por exemplo, de criação de imagens utilizando fotos de pessoas e aí parece com que uma pessoa está em um canto que não está ou que está fazendo algo que não, nunca fez. Eu acho que isso acredito que isso deve ser considerado na fiscalização da, da IA para que não ocorra, por exemplo, se, se a IA, um usuário utiliza a minha imagem, usando também a IA e coloque a minha imagem como se eu tivesse fazendo algo ilícito. Não, claro que isso traz no benefício para mim, como pessoa, porque eu nunca fiz aquilo, porque eu nunca estive naquele lugar, et cetera, et cetera. Então deve ser fiscalizado sim, para que não ocorra esse tipo de produção. Debatedor 3 Não Debatedor 4 Prevejo que ela é uma ferramenta, uma conquista, na verdade, em toda espaço da, da, da, da computação, por exemplo, e que, sim, é, deve existir, né, uma fiscalização ali, não fortemente, é claro, mas para barrar justamente problemas, pois uma ferramenta como ela, é, ela é aberta ao público, é vai do usuário, né? O seu intuito, né? O que ele quer trazer, o que quer que a IA faça e retorne. Então, para não ter problemas como direitos autorais ou de problemas que infrinjam a ética, então é algo racista, né, algo homofóbico, por exemplo, uma imagem. Eu vejo que tem que ter um, um, limite, né? Um órgão que verifique, né, passe de parâmetro para a IA e o cara retorna. Debatedor 5. Só para finalizar, é, eu imagino que é um conteúdo, é um, é um, é um tema que, é, traz bastante medo na sociedade, né? Principalmente porque, a sociedade em geral, não conhece como a inteligência artificial funciona, o que que ela pode fazer, o que que ela não pode fazer. Então é preciso entender corretamente o que, que ela pode fazer, até onde ela vai chegar, o que é que ela pode te causar. E a partir disso, é a inteligência artificial vai ser mais aceita, né? Principalmente por gerações que já vem, né? E é isso. Então utilizem este QR Code para acessar e responder a um questionário, que é uma avaliação e avaliação geral do debate. Suas respostas são confidenciais e serão usadas para fins de avaliação e aprimoramento. Dito isto, obrigado pela participação de vocês no experimento, iremos fazermos um sorteio de um brinde no final de todos os experimentos. Fiquem atentos, portanto, ao e-mail que vocês cadastraram no formulário de inscrição.\n","\"\"\""],"metadata":{"id":"P1IEUrGB7v6M","executionInfo":{"status":"ok","timestamp":1725286012607,"user_tz":180,"elapsed":7,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Prompt 1.2 (Zero-shot some context)\n","\n","\n","\n"],"metadata":{"id":"UWQ8xRwaE6f6"}},{"cell_type":"code","source":["prompt = f\"\"\"\n","The following Portuguese text was generated using an STT (Speech To Text) model from a debate recording. Such transcriptions often contain unwanted elements known as disfluencies, which include:\n","\n","- **Repetitions**: These occur when a word or phrase is repeated consecutively without adding any new meaning or value to the sentence. Repetitions are often present in speech but they do not contribute any additional information to the context. For example, in the phrase \"o ambiente da da tecnologia,\" the word \"da\" is repeated twitce without adding anything meaningful to the sentence, only one occurence of \"da\" would be sufficient to get what the phrase is trying to transmit.\n","\n","- **Hesitations**: These are non-verbal expressions or fillers used in speech to indicate a pause or hesitation. Common hesitations include sounds like \"ahh,\" \"ehh,\" \"um,\", \"hmm\" or \"uh.\" They serve as verbal placeholders while the speaker thinks or searches for the right words. Although they can indicate thought processes, they do not add substantive meaning to the text and should be removed for clarity. For example, in the phrase \"Eu estava, ahh, pensando sobre isso,\" the term \"ahh\" is a hesitation that can be removed.\n","\n","- **Corrections**: These occur when a speaker makes an initial error in their speech and then corrects it. The correction typically involves an initial incorrect phrase followed by a revised version of the same phrase. For instance, in the phrase \"que isso é, quer dizer, isso foi,\" the speaker initially says \"que isso é,\" makes a correction by saying \"quer dizer,\" and finally provides the corrected phrase \"isso foi.\" The goal is to remove the error, leaving only the final corrected version.\n","\n","Please remove these disfluencies from the text without altering the original meaning. You should NOT change text that does not refer to disfluencies. ANY text that is not in one of those three categories of disfluencies should not be changed. Return only the cleaned text with no additional information. Remember the text must be in its original full size, but without the disfluencies in it.\n","\n","\n","Text: {texto_disfluente}\n","\"\"\"\n","\n","response2, duration2 = get_response_and_time(prompt)\n","\n","print(response2.text)\n","print('A limpeza foi feita em ', duration2)"],"metadata":{"id":"uR556RKZE-Ut","executionInfo":{"status":"ok","timestamp":1725286115565,"user_tz":180,"elapsed":102965,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"d849756c-faa2-4a43-94ab-70effc317a55"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Minha identificação é a número 1. Estou contribuindo com a pesquisa no Brasil. Minha identificação é a número 2. Estou contribuindo com a pesquisa no Brasil. Minha identificação é a número 3. Estou contribuindo com a pesquisa no Brasil. Então agora eu vou explicar basicamente a principal regra do debate, que é antes de mergulharmos em nossa discussão, é essencial que todos compreendam o ensino, as regras de debate. Essas regras foram criadas para garantir o debate justo e ordenado para todos os envolvidos. A principal e essencial regra é sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando.\n","Se você deseja contribuir para a discussão ou oferecer um contraponto, por favor, levante a mão e aguarde o moderador lhe conceder a palavra. Uma vez que tenha sido autorizado a falar, você terá a palavra para prestar seus pensamentos ou responder aos outros.\n","Então, explicando o funcionamento do debate, nós vamos seguir o formato estruturado em 3 momentos distintos, cada um com seu propósito e regras específicas. No momento 1, abordaremos a questão principal do debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central, que é aquele que eu lhes enviei. No momento 2, haverá uma rodada de perguntas e respostas direcionadas para cada um dos debatedores, abriremos espaço para os outros participantes contra-argumentar e prestarem as suas opiniões sobre a resposta dada.\n","Após as perguntas direcionadas, teremos uma última pergunta que será direcionada a todos e, nesse momento, vocês têm a liberdade de escolher se desejam responder ou não e caso sintam que tem algo relevante a acrescentar.\n","E no fim, o último momento será de uma pergunta sobre a sua colocação final, se tem algo que é, enfim, colocação final. \n","Então a gravação já está sendo executada, certo? \n","Primeiramente, para, terá um momento inicial para expressar as suas principais opiniões e pensamento sobre o tema, no caso, IA generativa e cada participante terá um momento para fazer isso, começando pelo debatedor 1. Eu acho que com um certo controle, ela contribui muito, principalmente para a gente que é estudante, por ter um tutor particular, basicamente. E para as outras pessoas também, inclusive. Não só a IA generativa contribui no campo acadêmico, só que você, com a IA, tem que também ter esse controle porque como ela aprende com a gente, também pode aprender coisa errada. Isso é um problema porque quando você tem um negócio, por exemplo, o ChatGPT, como um público, que várias pessoas contribuem, vai chegar um momento que vira bagunça porque você pode contribuir com verdade, mas pode vir alguém e cair por terra sua fala, então aí vira uma bagunça. E não é nem controle, acho que é importante a fiscalização, é muito importante para o avanço de muita coisa. Acho que é isso, por hora. OK, agora o debatedor número 2. Então, eu acho que tem gente que é muito conservador em relação à IA, que é: \"Ah, eu sou contra totalmente, isso está acabando com a gente\". Mas como o debatedor 1 falou, tem que ser usado na medida certa e não só o ChatGPT, mas também a IA para formação de áudio, de vídeo, de imagem. Tudo isso eu acho que tem muito a contribuir, tipo, ajuda muita gente, só que no campo ético, eu acho que tem que ser muito bem pensado porque pode ser usada para construir grandes coisas, tipo em relação a, sei lá, a uma cidade, pode criar uma história, uma mentira que pode acabar com a vida, assim, na sociedade, na cidade. Aí no campo acadêmico, eu também acho que tem gente que se aproveita exacerbadamente do uso da IA e não ajuda a IA a raciocinar mais, raciocina por ela, entendeu? Agora o Debatedor 3. Pois bem, eu compactuo diretamente com a opinião do número 1 e do número 2, mas penso que deva haver algum meio de fiscalizar o que essas IAs estão fazendo porque elas vão seguir ao pé da letra o que você mandar, o que você programar para ela fazer. E acho que é aí que mora o provável problema, né? Porque a partir do momento que uma pessoa programa uma IA para fazer algo que em teoria traria o bem, mas se for seguido ao pé da letra pode fazer muito mal. Aí temos problemas. Um exemplo retirado direto da IA, que eu perguntei para o ChatGPT é: Por exemplo, se uma empresa mandou uma pessoa criar um código para implementar numa IA de maneira de acabar com a fome no mundo. Aí vai, implementa. Show de bola, começa a colocar essa IA. Poucos meses depois alguns navios vão mudar de rota porque eles são guiados pela IA, aviões que deveriam chegar com alimentos em lugares não vão chegar e algumas regiões vão ser dizimadas. Mas a IA está cumprindo o papel dela: se não há pessoas, não há fome. Ah, eu acho que partindo dessa lógica, tem que se haver o policiamento do que essas IAs estão fazendo. A partir do momento que começar a fazer mal à humanidade, tem que ter uma maneira de parar, dar um break. Vamos iniciar uma rodada de perguntas, irei realizar uma pergunta para cada participante, que terá seu tempo de resposta e ao final de sua resposta, os demais podem pedir espaço para comentar algo sobre a pergunta feita ou então a resposta dada, certo? Vamos começar. A primeira pergunta para o debatedor 1. Se um sistema de IA generativa criar algo prejudicial ou ofensivo, por exemplo, uma imagem com conteúdo racista, quem deve ser responsabilizado? O desenvolvedor da IA, o usuário, a plataforma que hospeda ou alguma outra instituição ou pessoa? É isso aí você me pega porque é muita gente. É inteligência artificial, ela aprende com a gente. Então, se alguém ensinou ela a fazer uma coisa específica, ela vai aprender. Então, assim, foi, por exemplo, você criou a IA para determinada coisa, eu vou lá e ensino outra coisa, isso fica armazenado. Então se a IA gera uma coisa que é um problema, por exemplo, aí tem que ver, né? Porque, tipo, até onde eu vou apontar o dedo, para quem eu vou apontar o dedo? Até onde eu tolero quem fez isso? Então eu não acho que dá para apontar o dedo para uma pessoa específica porque pode ter sido culpa do criador, pode ter sido culpa do usuário ou da empresa. Pode ser dos 3 ou de todos. Debatedor 3, não só complementar que pode ter sido culpa de tudinho e tudinho para responder pelo crime. Aí eu acho que entra no âmbito de fiscalização, criar regras. Porque quando ela cria, quando a IA cria um problema ou alguma coisa que fere direito de alguém, quem vai ser culpado? Não tem isso, não tem uma regra falando, ninguém deve ser culpado e eu acho que não tem lei também, né? Então assim fica complicado culpar alguém. Eu acho que é, também acho que é complicado culpar alguém. Mas, por exemplo, se um usuário pedir para a gente gerar uma coisa de caráter racista, o usuário tem parte de culpa nisso, mas ele, a IA está gerando esse conteúdo porque tem uma base de dados que tem esse caráter racista. Então, como o debatedor 1 falou, eu acho que pode ser culpa de qualquer pessoa, qualquer um: o desenvolvedor, a plataforma ou o usuário. E também acho que é aquilo que eu falei da ética na IA, da fiscalização porque todos os crimes podem ser gerados por IA, porque como o debatedor 3 falou, por exemplo, a história de acabar com a fome no mundo pode gerar um crime pela IA. Indo para outra perspectiva, a gente pode ver parte de culpa do criador porque como ele criou, ele pode limitar também. Ele pode limitar a IA, então por que ele não limitou isso? Para quando ele recebesse, ela retorna: \"Não, isso aqui não é legal, então não vou te responder, não vou aprender isso\". Então eu acho que é assim, parte tem como eu não criar, não pode ter sido, tipo, não intencionalmente, mas por que não me limitar se vai ver ferir o direito de alguém, se não é construtivo para ninguém? Nem para a IA, nem para ele. Debatedor 3. Mas e por que limitar? Porque limitando você está limitando o processo de desenvolvimento. Logo, talvez ela desenvolvesse para fazer algo, ficaria patinando no mesmo ciclo, não desenvolvesse como se a IA tivesse toda a liberdade, poderia desenvolver. Eu acho que se tiver alguma coisa assim, que fere algum direito de alguém, poderia ser, não limitado, mas dado uma resposta, por exemplo: \"Ah, não vou criar conteúdos desse caráter por conta disso, disso e disso\", mas ele vai ter a base de dados. O debatedor 3 falou sobre liberdade do aprendizado da IA. Mas até que ponto uma liberdade para aprender uma coisa que não é construtiva para ninguém, que fere o direito do outro, até onde isso é liberdade de aprender? Porque não faz sentido. Tu pega, por exemplo, saindo de IA, aplicativo como Instagram, como Twitter, eles já reconhecem conteúdos que são racistas, conteúdos com teor pornográfico. Eles reconhecem. Então a IA pode muito bem reconhecer isso e assim: \"Não, bloqueia isso. Eu não vou reter esse conhecimento e não vou retornar nada\", mesmo que o usuário volte lhe pedindo, ele não retorne nada, até porque não faz sentido. Que tipo de conhecimento amplo é esse que você pode aprender uma coisa que fere o outro? Alguém mais quer falar sobre esse ponto? Pois bem, vamos para a segunda pergunta para o debatedor 2. IAs generativas podem ser usadas nos processos educacionais? Por exemplo, em aulas, atividades ou provas, o aluno deve reportar ao professor sobre o uso de IA generativas em suas atividades? Eu imagino que sim, que pode ser usado, que a IA, por exemplo, eu estava com dúvida em uma questão e eu estava pensando de uma forma e ela me ajudou a ter um raciocínio de outra forma, mas não copiando tudo. Pode ser usado para ajuda de raciocínios, mas eu acho que nos processos educacionais, os professores, os docentes, qualquer coisa, eles estão se restringindo muito do leque de possibilidades que a IA poderia dar a aulas, por exemplo, uma aula mais interativa ou ajuda, ou pesquisas com os alunos por meio da IA, como uma ferramenta tipo Google, só que usando GPT, por exemplo. Eu acho que eles se restringem muito. No sentido de restrição, não deve ser restringido, mas aí a gente volta para a ética e para o seu senso de uso, tanto de professor como do aluno, porque você está usando para quê? Até que ponto aquilo ali é seu? Até que ponto lhe ajudou? Então, dependendo do que você pediu, quanto que você fez? Você pegou o resultado que a IA deu para quê? Então tem que ser, eu não acho que tem que ser restringido, tem que ser aberto a todos, tanto para professor quanto ao aluno, mas com uso responsável. OK, eu não vou generalizar tanto, 50% das pessoas não fazem. Eu conheço um bocado de pessoas que, ah, não sei, pergunta do ChatGPT, me coloca a resposta lá na atividade, principalmente no momento de pandemia, essa coisa muito mais forms da vida que só queria a resposta, não importava como você fez. Eu vi muita gente usando desses artifícios para passar, tirar notas boas e depois no final não saber nem o que fez. E inclusive, questão de redações que é um negócio que eu tive uma experiência bem de perto mesmo. Algumas pessoas pegam, mandam para o ChatGPT, fazem a redação de qualquer tema. Ele vai fazer, coloca outra, 3 palavrinhas, inverte o parágrafo e manda, tira notas boas. Acho que o conselho acadêmico deveria haver um jeito também de fazer o ChatGPT não dar a resposta pronta, mas mostrar como faz. Eu acho que é tipo um ChatGPT acadêmico, seria inovador, diria. Então o debatedor 3 concorda que deveria ser restringido? Não, restringido não, criada uma nova ferramenta específica para a educação. Mas isso é restringir o uso das IAs, não? Você poderá restringir dentro da escola, mas você vai ter a outra justamente de provas. Eu acho que seria importante. Mas o que garante que você mesmo entenda essa nova ferramenta, assim, tipo, um filtros limitadores, o que garante que a pessoa não vai usar a outra? É muito leve e aberto. Mas quando você parte para a ética, o uso de uma IA normal sem ter filtro nem limitação, você usando com ética e responsabilidade já seria o uso correto, não concorda? Por exemplo, tem o ChatGPT como exemplo. Ele é uma base de dados, então ele não está 100% correto o tempo todo. Então eu já vi gente reclamando: \"Ah, eu usei uma IA generativa e a resposta que deu estava errada\". Só que você, além de você, tem que ter o seu senso e saber o que você está falando. Exatamente o que ela falou, porque se tu pega, se tu pergunta uma coisa e tu tem um resultado e tu pega ali e usa, tu vai estar pondo em risco tua integridade, a tua ética. E você não está confirmando se aquilo ali é realmente completamente verídico porque como eu já havia falado, ela está aprendendo, ela está aprendendo coisa errada também. Eu não estou sempre dando resultado e tu não verifica, a responsabilidade é tua. Alguém mais gostaria de falar algo sobre? Pois bem, então passaremos à terceira pergunta para o debatedor 3. De que maneira a propriedade intelectual deve ser tratada quando o conteúdo é gerado por uma IA? Por exemplo, se o usuário gerou uma música usando IA, o crédito pela criação deve ser deste usuário, da plataforma utilizada, do criador dos dados originais com os quais a IA foi treinada? Eis uma grande dúvida. Há muita discussão sobre isso. Modéstia à parte, eu acho que como a IA aprende com quem está interagindo com ela, eu acho que mesmo que houvesse uma divisão, não, eu que fiz a IA, eu quero 20%, sei lá, 10% dos créditos da música. Acho que a maior parte deve ser para a pessoa que a treinou mesmo, mesmo que uma parte pequena, assim 10, 5% for para a plataforma e outros 10% para o criador da IA, acho que a maior parte tem que ir para quem a treinou, o usuário que interagiu com ela para criar essa música. Eu acho que a criação de música pela IA usando outras músicas deve ser pensado da mesma forma que, por exemplo, na indústria da música atualmente, eles usam a interpolação. Eu acho que uma parte vai para o criador original e a outra parte dos números da música vai para quem fez uma pegada diferente com essa música, por exemplo. Só que eu acho que tem que partir para essa parte legal da mesma forma que as interpolações são feitas e eu não acho que ainda deve dinheiro para a plataforma de IA porque ela é só um meio que o usuário está usando para criar aquilo. Acho uma pergunta um pouco aberta porque quando você usa uma plataforma, por exemplo, de IA, mais difundido ChatGPT, ela tem regras, tem condições que você aceita. Então, dependendo do que tem nessas condições, nessas regras que ela passa e você está lá e aceita, do que você aceitou, você, se você não lembra, você está se propondo a correr o risco de, dependendo do que ela gerou, você vai partir para ela, para o criador. E outra coisa, por exemplo, se um usuário gerar uma música usando IA, aí é o questionamento, até onde, aliás, gerou a música e que partes ela fez. Ela adicionou palavras? Ela ajudou você no raciocínio? Como é que a gente, como é que isso vai ser fiscalizado? Então eu acho que tem que ser vários pontos analisados até chegar ao veredito de quem vai ser creditado por isso. Agora eu vou fazer uma pergunta direcionada a todo o grupo, qualquer um dos debatedores podem responder. O uso e o desenvolvimento de IAs generativas devem ser fortemente fiscalizados por órgãos governamentais ou elas são apenas mais um tipo de software comum como milhares de outros existentes? Eu acho que deve ser fortemente fiscalizada como a música porque até como todo o nosso impacto foi, o debate foi em relação a isso, que deve haver a fiscalização da, deve-se usar as IAs, mas com a forte fiscalização. Mas a fiscalização tem que ser governamental? Porque no país, no Brasil, onde estamos, a fiscalização governamental é falha. Então assim, eu acho que ele é um software comum e dependendo do seu uso, dependendo do que você fez, você tem uma consequência. Eu acho que o governo tem que entrar, dependendo da situação, da conjuntura atual ou do futuro, criar regras, alguma regra ou algo do tipo, mas não fiscalizar fortemente porque essa fiscalização fortemente em algum momento, ela vai vir, ela vai ser limitante para a IA. Então até que ponto fiscalizar fortemente? Eu vou concordar com ele que falou, no Brasil que nós vivemos, o pessoal joga o lixo fora do lixo, do lado do lixo, então não vai funcionar. Aí eu acho que como os países têm, vou caçar aqui a palavra, culturas diferentes, cada um puder definir de uma forma diferente até que ponto nós temos uma IA porque cada cultura tem seus princípios, seus, suas culturas, sua cultura em geral. Cada povo tem sua cultura e para algumas culturas pode ser bom algo e para outros não. Aí, tipo, num país a IA é fiscalizada pelo governo e o governo disse: \"Não, você não pode ensinar o pessoal como criar um avião\". E a outra disse que tem que ensinar o pessoal. Acho que vai dar errado, vão ter duas IAs diferentes, no caso, viu? Eu acho que para dar certo tem que ser uma IA universal e as mesmas regras em todos os países. Aí que se tem algumas que podem ser moldadas de acordo com a situação, mas nesse, partindo desse, eu acho que tem que ser pouco fiscalizada, mas tem algumas regras, sejam universais para todas. Tem que existir lá a regra universal para todas, OK? Mas eu não, nenhuma pessoa de assunto informando o governo porque pode ser falha, pode ser instintiva e pode de liberdade. Mais alguém gostaria de comentar algo? Não? Pois bem, então agora, certo, nós partimos para a última fase do debate em que cada participante terá um momento para falar suas considerações finais sobre o tema, sua opinião ou visão sobre o tema no geral, então sua opinião ou visão sobre o tema mudou depois do debate ou se fortaleceu ou algum tipo? Fortaleceu. Opinião é a mesma: uso aberto, uso livre, uso consciente, consciente de consequência, uma regra ou outra. Fiscalização governamental não. Continua a mesma também, mas eu acredito na fiscalização governamental porque se não houver uma fiscalização, que órgão que vai ser geral para toda a sociedade? Por que que você acha que para o governo? Porque as próprias empresas, criadores de IA, não criam um meio, um órgão que fiscalize e que reja? Porque tem que vir no governo, sabe? Esse órgão vindo de empresas não seria facilmente burlado, não? Mas o quê? Mas o que garante que a fiscalização governamental seria menos falha do que uma privada? Porque eu penso em uma fiscalização privada, como talvez tinha que ter, talvez um pouquinho do dedo do governo para ser um mediador de todas as empresas que criam IAs, por exemplo, aí pode ser OK, mas só o governo fiscalizando não, é pouco, é inviável. Pensando nisso, está partindo daquele exemplo lá do que eu falei logo no início, da fome, aí a pessoa manda um processo generativo lá para a empresa e ela passa pelo governo e o governo olha: \"Tá bacana? Vai, vai solucionar a fome\". A empresa vai, aí a empresa começa a distribuir essa IA e implementar nos computadores. Dentro do governo dá certo? A pergunta é um pouco vaga porque o nosso plano de governo atual é bonito, só que na prática que a gente vê coisa, então é a fiscalização em si. Por isso que eu falei, eu acho que o governo teria minimamente só consciência, no máximo. Entrar como mediador? Talvez. Porque não faz sentido, porque nada garante, seja uma situação só o governamental, seja fiscalização de empresa privada ou um consenso mundial. De qualquer forma, ela vai ser falha. Ninguém garante que ela vai ser completamente uma fiscalização completamente OK. Porque outra coisa, tu acha que a fiscalização, ela seria melhor pelo governo? Não, eu acho que seria ruim, mas impô-las em alguns cantos. Acho que vai depender muito do governo que está regendo a região porque se for um governo que vai implementar as leis e procura resolver os problemas, pode ser uma fiscalização plausível, mas aí se um governo agir com descaso, não, vai ser muito inviável. Até eu pensei agora uma junção dos 2, fase um, fazer dois, passou pela fase do governo, aí passa pelos testes, entre aspas, da empresa que criou. Eu pensei na fiscalização do governo porque traz a universalidade em todas essas empresas de IA, entendeu? Como os debatedores estavam falando, cada empresa pode ter diferentes morais e éticas que podem passando por diferentes coisas, não? E eu coloquei em tese na minha fala um governo que funciona perfeitamente, então pensei normal, que é falho. Talvez, talvez iniciativa público-privada seria uma boa, assim, a depender da circunstância e da forma que ela vai ser criada. Porque falar de fiscalização de IA, principalmente na época atual que a gente está vivendo, que elas estão tendo o boom, que está começando a ser estudado amplamente, então não seja uma boa hora agora. Mas em algum momento deve-se existir e deve ser adversado. Como isso vai funcionar? Como isso vai agir? Não dá para você chegar e falar: \"Ah, eu acho que a fiscalização tem que ser assim, assim\" porque nunca vai, nunca vai abrir todo o mundo, vai ter pontos negativos sempre, sempre. Bem, nesse caso, retomamos a pergunta final, né? Porque a gente acabou voltando ao assunto anterior. Houve uma mudança de visão? Quais são as suas considerações finais sobre o tema? Essa mudança ocorreu depois do debate? Poder livre, aberto, talvez um dedo do governo aí e possivelmente uma fiscalização público-privada. Continua a mesma, mas eu pensei na ideia dos debatedores e eu ainda acredito na fiscalização governamental por conta da universalidade. Mas tem que ter o dedo de mais pessoas. Mudou-se um pouco a minha ideia. Levando em conta que ainda a IA está aprendendo muito ainda, eu concordei que não agora, mas depois de um certo conhecimento de como essa IA vai se comportar e entender melhor ela, talvez exista uma certa fiscalização público-privada. Entendi. Pois bem, gente, estamos chegando ao final do nosso debate. Então vocês podem escanear esse QR Code para um formulário de autoavaliação, bem rapidinho. E as respostas são confidenciais e serão utilizadas só para os fins de avaliação e aprimoramento, no geral, não.\n","\n","A limpeza foi feita em  102.60643744468689\n"]}]},{"cell_type":"markdown","source":["## prompt"],"metadata":{"id":"1f4c3_qd8lIr"}},{"cell_type":"code","source":["prompt2 = \"\"\"Gravação iniciada. Minha identificação é o número aluno um, estou contribuindo para a pesquisa no Brasil. Minha identificação é aluno 2, estou contribuindo para a pesquisa no Brasil. Minha identificação é a número 3. Estou contribuindo com a pesquisa no Brasil. Minha eficação é o número 4. Estou contribuindo com a pesquisa do Brasil. Minha identificação número 5, estou contribuindo com a pesquisa no Brasil. Excelente. Pois bem, agora eu explicarei as regras deste debate, e então, antes de mergulharmos em nossa discussão, é essencial. Todos compreendam e sigam as reuniões de debate. Essas regras foram ampliadas para garantir um debate justo e ordenado para todos os envolvidos. A única principal regra é: sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando. Se você deseja contribuir para alguma discussão ou oferecer um contra argumento, por favor, levante a mão e aguarde um moderador, no caso eu lhe conceder a palavra, uma vez que tenha sido autorizada a palavra, você terá a palavra e poderá expressar seus pensamentos ou responder aos outros. Vamos seguir um formato estruturado dividido em 3 momentos distintos, cada um com seu propósito e regras específicas. No primeiro momento abordaremos a questão principal no debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central. Que foi aquele tema que lhes foi enviado. No segundo momento teremos uma rodada de perguntas direcionadas para cada um dos debatedores. Abriremos espaço para outros participantes contra argumentar, ou espressarem as suas opiniões sobre a resposta dada após as perguntas direcionadas, teremos uma última pergunta que será direcionada a todos os participantes, nesse momento, vocês têm a Liberdade de escolher se desejam responder ou não, e só caso tenham algo no caso sintam que tem algo relevante a acrescentar. Por fim, no terceiro momento, será perguntado se os participantes têm alguma outra colocação final sobre o tema. Então cada um de vocês terá esse movimento inicial para expressar suas principais opiniões e pensamentos sobre o tema. E o tema é, esse que aí está e que foi também lhes enviado, então começando do debatedor número 1. Quais são as suas opiniões iniciais sobre o tema? Uma opinião inicial é que, conforme vai crescendo na inteligência artificial e se não for, não foi controlado o público que a utiliza, as pessoas vão acabar se dependendo, de mais dela, por causa de vai acabar usando ela para fazer qualquer coisa na, vamos ver, o estudante vai usar a inteligência artificial para fazer as questões por, de algum professor e vai acabar não se dedicando para aprender o assunto. Assim vai acabar sendo muito dependente dela e não vai acabar crescendo quase nada, na sociedade. Debatedor número 2. Eu acredito que o uso da inteligência artificial de forma benigna, pode como o próprio já diz, causar um bem no sentido, por exemplo, aplicativos que utilizam da inteligência artificial, da IA, para produzir, por exemplo, na questão da construção civil, que pode utilizar para a questão de produção de planta baixa ou de outros projetos arquitetônicos nesse sentido olhando essa visão, eu acredito que é um uso, com um bem explícito, mas que também depende, por exemplo, do seu uso como o debatedor 1 falou poderia no caso do estudante que ele começa a depender demais da inteligência artificial, no nosso caso mais atual, por exemplo, o ChatGPT que para responder as perguntas de seja de exercício ou atividades, enfim, começa a depender o uso demasiado da inteligência artificial e pelo contrário não provocam bem a si mesmo. Ele está degenerando a si mesmo. Está seu tá agravando seu processo de de desconstrução de conhecimento, é isso que é isso que eu defendo, é a questão do uso mais moderado. Debatedor número 3. Eu acredito que a IA como qualquer outra tecnologia, ela vai ela vai ser útil para facilitar a nossa vida, mas como nas outras tecnologias, também tem que ser usado de uma, da forma certa. Durante a guerra a gente viu que usou a tecnologia para fazer mal para a sociedade, a IA pode ser a mesma, pode ser usado para a mesma coisa e pode fazer um mal para você próprio. Então acho que ela deve ser usada, mas também tem que ser empregado no ponto de como usar ela da maneira certa, tem que ensinar as pessoas a usar da maneira correta. Debatedor número 4 Sinto que é necessário criar uma verificação no que está sendo passada para ela, uma vez que sem um limite eu posso infringir a própria ética no caso de criar, por exemplo, deep face, né? Fake news que é desenvolver né imagens né alteradas, então foi pelo. Acho que é bom é que exista uma evolução na na IA, mas deve ter assim, uma verificação, para que que está sendo passado para ela não seja nada que infrinja a ética, a moral, como um todo. Debatedor número 5 Bem, eu acredito que esse, na verdade, é um assunto bastante delicado, né? É pessoas de diversas áreas, vão ter opiniões que divergem uma das outras É, mas como qualquer outra coisa, é o seu uso de forma imprópria é pode causar desses problemas, né? Então, é o uso de inteligência artificial, tem que ser definitivamente, tem que ser pensado antes de ser usado, né? Você não pode usar de uma forma indevida, ainda mais que ainda não está dentro de um de uma lei. Se, como você pode usar, como você não pode, então imagino que seja um assunto bem delicado. Pois bem, nós estaremos agora, então a rodada de perguntas, certo? A primeira rodada de perguntas. E nela eu irei realizar uma pergunta para cada um dos participantes, que terá seu tempo de resposta ao final da sua, ao final da sua resposta, onde os demais terão, é espaço para comentar algo sobre a pergunta ou a resposta dada. Então, vamos começar. A primeira pergunta para o levantador número 1. Se o sistema de IA generativo criar algo prejudicial ou ofensivo, por exemplo, uma imagem com conteúdo racista, quem deve ser responsabilizada? Desenvolvedor da IA, o usuário, a plataforma que hospeda com alguma outra instituição pessoa? Debatedor número 1. Acredito que seja um único, acredito que seja o usuário, que seja responsabilizado por causa que como já foi dito, pelo debatedor 3,  número 3 a sobre a opinião dele, que a inteligência artificial se for utilizada de forma errada, acaba sendo mais a culpa da pessoa que está usando ela não de alguém que desenvolver, porque a pessoa que desenvolveu a internet artificial fez para com intuito de beneficiar a sociedade. Mas a pessoa que usou o usuário usou de forma errada e acaba fazendo alguma coisa prejudicial. Alguém tem algo a comentar sobre a resposta do debatedor um ou a pergunta em si. Tá, então passemos para a segunda pergunta para o debatedor número 2. IAs generativas podem ser usadas nos processos educacionais, por exemplo, em aulas, atividades ou provas, o ou a aluno ou a aluna deve reportar ao professor ou professora sobre o uso de IAs generativas em suas atividades? Eu acredito que pode ser utilizado sim, como qualquer outra tecnologia, a gente utiliza, por exemplo, em nossas atividades escolares acadêmicas. A questão do do uso da internet, por exemplo em sites de pesquisa,e a gente pode encontrar informações. Como a IA se baseia em um banco de dados gigante eu acredito que nós podemos utilizar no sentido de que podemos utilizá-la como fonte dessas informações, certo? Por exemplo, eu quero pesquisar, supondo, de uma forma bem grotesca sobre a questão da história da do Brasil. Eu Acredito que a IA vai nos fornecer é informações que serão necessárias ou muito importantes para o nosso crescimento, para o nosso crescimento intelectual de conhecimento e outra pergunta, o aluno deve reportar ao professor sobre o uso das IAs generativas em suas atividades? Eu lembro que se Eu Acredito que sim, como qualquer outro banco de dados que nós já vemos referir, da onde a gente pegou essas informações. Eu acredito que é necessário também reportar ao professor, ao docente, o da onde a gente tirou essas informações. Alguém gostaria de comentar algo sobre a resposta dada ou a pergunta em si? Então passemos pra pergunta 3, ao debatedor número 3. De que maneira a propriedade intelectual deve ser tratada quando um conteúdo é gerado por uma IA? Por exemplo, se um usuário gerou uma música usando IA, o crédito pela criação deve ser o deste usuário? Da plataforma de IA utilizada? Do criador dos dados originais, com os quais a IA foi treinada? Ou de que?\n"," Não acredito que deva ser da IA porque a IA gerativa, ela é feita como uma base de dados muito gigantesca e ela vai fazer as coisas coisas novas, não vai replicar o que tem, ela vai aprender e vai replicar e vai criar coisas novas. Então, uma criação dela e uma criação de outras pessoas, ela, o crédito deve ser dela. Debatedor número 5 Eu imagino que seja, tenha créditos à inteligência artificial, mas que não totalmente, já que ela utiliza de um banco de dados, possivelmente ela vai estar pegando algo de outra pessoa e reutilizando, é de certa forma, então possivelmente, se você identifica, é seus direitos autorais no que ela gerou, eu imagino que é o os direitos autorais você também tenha participação disso. Debatedor número 2. Como o debatedor falou, número 5, ele falou, é como se fosse uma árvore, né? Se a gente puxar, é de onde está havendo as informações sempre vai ter um crédito como ele falou, na questão do do do grande banco de dados, O o artistao músico que está procurando, é, criar uma nova música utilizando a inteligência artificial também deve ter seu crédito de certa forma, mas acredito também tanto os conteúdos é que estão dentro É da IA, do do banco de dados da IA também devem ser procurados de de onde foi que ela utilizou essas informações E, de certa forma, acredito que também até o os criadores do da IA também. Alguém mais, tem algo a comentar sobre a pergunta, sobre as respostas dadas? Não? Então sigamos para a pergunta 4 debatedor número 4. Como garantir que conteúdo gerados por IA não sejam usados para espelhar informações tendenciosas, errôneas ou maliciosas, por exemplo, quando esse tipo de informação é propagada massivamente por bots em uma rede social, a responsabilidade deve ser da empresa que administra a rede social, dos programadores da IA, de quem produziu aquele conteúdo usando a IA?   Eu prevejo que seja de quem produziu aquele conteúdo.  Porque não minto que seja do da empresa o cara tem domínio né, daquela rede social de propagar aquilo que ela está passando. Então se passa uma informação que ela não consegue verificar, não consegue analisar que é justamente tendenciosa é errônea, né? Como uma imagem, né? Uma fake news, uma, um som, uma até uma, música que passe por assim sem ela perceber essa essa falha, né? Que pode dar na ética. Eu vejo que seja dela a essa essa falha, né não de que ade que a produziu, assim, quem produziu também, mas seria mais ela, que tá propagando. Debatedor 2 Eu Acredito também, assim como o debatedor 4, falou É, tem uma parcela em culpa da empresa em talvez propagar essa esse conteúdo de forma errônea ou de forma é replicada, mas também do próprio usuário que que produziu o conteúdo usando da IA. Acredito que a IA ela  Não, não, não tem essa, tanto, essa parcela de culpa que que eu comparo com se fosse o carro, por exemplo, de forma grotesca, claro. Um carro, o criador de um automóvel, no caso ele não pensou naquelas pessoas, talvez muito provavelmente nas pessoas que poderiam utilizálo como veículo de de de rachas na rua, por exemplo. Mas como uma forma de locomoção das pessoas e  para um lugar, outros lugares et cetera, et cetera, mas que devido aos seus usuários, por exemplo, nós, quando nós utilizamos o nosso automóvel, assumimos essa essa responsabilidade de que, caso venha, venhamos a desrespeitar, leis de trânsito perdão e assumirmos essas responsabilidades, assumimos essa culpa de talvez provocar um acidente e comparando de forma com o usuário que utiliza essa IA eu acredito que ele também deve ser responsabilizado. Por quê? Porque ele está assumindo de que quando ele produz esse conteúdo, é claro, é evidência evidencialmente vai ser um conteúdo é pejorativo, um conteúdo que é traz mal para a sociedade. Debatedor 5 Eu já para mim, eu não imagino que a empresa, a rede social que administra ela seria responsável, já que possivelmente vai haver algum algoritmo ele vai identificar aquilo, claro que existem métodos de filtragem para identificar se se é um, se é uma informação falsa ou não, mas é o algoritmo, só vai repassar para outras pessoas se as pessoas concordarem e curtirem compartilharem, repassarem para outras pessoas, então, eu imagino que é mais das pessoas que veem aquele conteúdo e de quem produziu esse conteúdo É a culpa de informações tendenciosas serem repassadas do que mesmo da responsabilidade da rede social, né? Já que, teoricamente, a rede social não foi feita para isso. Alguém tem algo a comentar sobre o que tinha dito ou sobre a pergunta? Então passemos a quinta pergunta ao debatedor número 5. Quais os impactos da IA no ambiente de trabalho, você acha que o uso de IAs generativas irá gerar ou destruir empregos, por exemplo, uma IA generativa que consegue fazer um trabalho de um arquiteto ou publicitário de forma mais rápida fará um trabalho totalmente confiável. É, eu imagino que E vai existir impactos dessa inteligência artificial, né no mercado de trabalho, mas isso acontece hoje em dia sempre aconteceu com diversas outras coisas existem diversos empregos que não existem mais porque foi criado algo novo, que é melhor, que é superado hoje em dia, por exemplo, não tem mais antigamente tinha um emprego nas naqueles lugares de jogar boliche, tinha um pessoal que organizava os pinos para você jogar de novo. Hoje em dia não é assim, mais não. Esse emprego não existe mais. Então, é enquanto a inteligência artificial estiver sendo é desenvolvida, é claro que você não pode confiar totalmente, né? É preciso que você tenha a é a inspeção de um arquiteto, de um cara que estudou para isso. Possivelmente a inteligência artificial vai ter arquitetos que vão ter, vão estar trabalhando em conjunto com programadores para desenvolver essa inteligência. Então, eu imagino que enquanto a inteligência artificial estiver evoluindo, a tendência é que ela esteja mais e mais confiável E diante disse empregos, se não forem atualizados, se não tiverem mais a eficácia deixaram de existir. Alguém tem algo a comentar sobre esse ponto ou sobre a resposta dada? Bem, então passamos agora para a pergunta livre. A, lembrando que vocês podem responder ou não. Uso e o desenvolvimento de áreas narrativas devem ser fortemente fiscalizados por órgãos governamentais ou elas são apenas mais um tipo de software comum, como milhares de outros existentes? Debatedor número 5. É bastante adverso. Sim, elas devem ser fiscalizadas, mas não fortemente. Até porque tem que ter algum, alguma parte criativa naquilo, né? Se for totalmente fiscalizado, talvez você trave você pare o desenvolvimento daquilo, que você torne lento. O desenvolvimento disso, se você não, claro que a fiscalização é importante justamente por outros motivos, direitos autorais, tudo mais, mas é, se for fortemente, é fiscalizado, é A gente vai deixar de evoluir? Basicamente a gente vai deixar de ter um desenvolvimento mais rápido simplesmente por conta que o governo está fiscalizando e ele não deixa por conta N motivos, né? Então, imagino que deve ser fiscalizado, mas até certo ponto. Alguém mais gostaria de responder a pergunta ou comentar sobre o que foi dito? Bem, então agora cada participante terá um momento para falar suas considerações finais sobre o tema, sua opinião ou visão sobre o tema mudou depois do debate? Começando do debatedor número 1, você tem alguma coisa sobre para falar mais sobre o tema? Tem alguma concentração final, senão, você sua ou visão ou opinião mudou sobre o tema de IAs generativas depois do debate? Não. Debatedor 2 Eu acredito, só, para, a título de conclusão final, acredito que a inteligência artificial, assim como qualquer outra tecnologia, assim como na comparação que eu fiz como automóveis, de forma, grotesca, é claro, mas, ela pode auxiliar, ela vai auxiliar a sociedade na criação de, de, na produção de, de n coisas. No entanto, que deve ter assim um cuidado sim, uma fiscalização para que não torne essa, essa produção de forma demasiada ou que acabe por gerar, é, algo algo que não produza benefícios, pelo contrário, produza malefícios para a sociedade na questão, por exemplo, de criação de imagens utilizando fotos de pessoas e aí parece com que uma pessoa está em um canto que não está ou que está fazendo algo que não, nunca fez. Eu acho que isso acredito que isso deve ser considerado na fiscalização da, da IA para que não ocorra, por exemplo, se, se a IA, um usuário utiliza a minha imagem, usando também a IA e coloque a minha imagem como se eu tivesse fazendo algo ilícito. Não, claro que isso traz no benefício para mim, como pessoa, porque eu nunca fiz aquilo, porque eu nunca estive naquele lugar, et cetera, et cetera. Então deve ser fiscalizado sim, para que não ocorra esse tipo de produção. Debatedor 3 Não Debatedor 4 Prevejo que ela é uma ferramenta, uma conquista, na verdade, em toda espaço da, da, da, da computação, por exemplo, e que, sim, é, deve existir, né, uma fiscalização ali, não fortemente, é claro, mas para barrar justamente problemas, pois uma ferramenta como ela, é, ela é aberta ao público, é vai do usuário, né? O seu intuito, né? O que ele quer trazer, o que quer que a IA faça e retorne. Então, para não ter problemas como direitos autorais ou de problemas que infrinjam a ética, então é algo racista, né, algo homofóbico, por exemplo, uma imagem. Eu vejo que tem que ter um, um, um, limite, né? Um órgão que verifique, né, passe de parâmetro para a IA e o cara retorna. Debatedor 5. Só para finalizar, é, eu imagino que é um conteúdo, é um, é um, é um tema que, é, traz bastante medo na sociedade, né? Principalmente porque, a sociedade em geral, não conhece como a inteligência artificial funciona, o que que ela pode fazer, o que que ela não pode fazer. Então é preciso entender corretamente o que, que ela pode fazer, até onde ela vai chegar, o que é que ela pode te causar. E a partir disso, é a inteligência artificial vai ser mais aceita, né? Principalmente por gerações que já vem, né? E é isso. Então utilizem este QR Code para acessar e responder a um questionário, que é uma avaliação e avaliação geral do debate. Suas respostas são confidenciais e serão usadas para fins de avaliação e aprimoramento. Dito isto, obrigado pela participação de vocês no experimento, iremos fazermos um sorteio de um brinde no final de todos os experimentos. Fiquem atentos, portanto, ao e-mail que vocês cadastraram no formulário de inscrição.\n","\"\"\""],"metadata":{"id":"U4BRFRqb707M","executionInfo":{"status":"ok","timestamp":1725286115566,"user_tz":180,"elapsed":20,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# Prompt 2.1 (Few shot some context)"],"metadata":{"id":"vxLYKlXCFu3b"}},{"cell_type":"code","source":["prompt = f\"\"\"\n","Context: The text below is a transcription in Portuguese from a Speech-to-Text (STT) model of a debate. In these transcriptions, disfluencies such as hesitations, repetitions, and corrections are common.\n","\n","- **Repetitions**: These occur when a word or phrase is repeated consecutively without adding any new meaning or value to the sentence. Repetitions are often present in speech but they do not contribute any additional information to the context. For example, in the phrase \"o ambiente da da tecnologia,\" the word \"da\" is repeated twitce without adding anything meaningful to the sentence, only one occurence of \"da\" would be sufficient to get what the phrase is trying to transmit.\n","\n","- **Hesitations**: These are non-verbal expressions or fillers used in speech to indicate a pause or hesitation. Common hesitations include sounds like \"ahh,\" \"ehh,\" \"um,\", \"hmm\" or \"uh.\" They serve as verbal placeholders while the speaker thinks or searches for the right words. Although they can indicate thought processes, they do not add substantive meaning to the text and should be removed for clarity. For example, in the phrase \"Eu estava, ahh, pensando sobre isso,\" the term \"ahh\" is a hesitation that can be removed.\n","\n","- **Corrections**: These occur when a speaker makes an initial error in their speech and then corrects it. The correction typically involves an initial incorrect phrase followed by a revised version of the same phrase. For instance, in the phrase \"que isso é, quer dizer, isso foi,\" the speaker initially says \"que isso é,\" makes a correction by saying \"quer dizer,\" and finally provides the corrected phrase \"isso foi.\" The goal is to remove the error, leaving only the final corrected version.\n","\n"," The example below shows the same transcription in three stages. The first stage, \"Original,\" is the raw transcription as it comes from the STT model. The second stage, \"Marked,\" is the same transcription with tags identifying the disfluencies in the text, such as \"<hes\" for hesitations, \"<erro\" for errors, \"<corr\" for corrections that come after an error, and \"<rep\" for repeated words. The third and final stage shows the text without the marked transcriptions, cleaned of these so-called disfluencies.\n","\n","Example:\n","\n","\"Original\": \"Excelente. Oi, bem, agora eu eu IA explicar as regras deste debate, e então, antes de de mergulharmos em nossa discussão, é essencial. Todos compreendam e sigam as reuniões de debate. Essas regras foram ampliadas para garantir um debate justo e ordenado para todos os envolvidos. A única principal regra é essa, sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando. Se você deseja contribuir para contra discussão ou oferecer um contra argumento, por favor, levando-se a mão e aguarde em moderador caso eu lhe conceder a palavra, uma vez que tenha sido autorizada a palavra, você terá a palavra e poderá ingressar seus pensamentos. Ou responder aos outros? Ah, vamos seguir um formato estruturado? Deveria em 3 momentos distintos, cada um com seu propósito e regras específicas. O primeiro momento abordaremos a questão principal no debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central foi a medida que isso foi *****. O segundo momento teremos uma rodada de bernanke direcionadas para cada um dos debatedores. Abriremos espaço para outros participantes contra argumentar, eu experçarem as suas opiniões sobre a resposta dada após as Pendências direcionadas, teremos uma última pergunta que será direcionada a todos os participantes, nesse momento, vocês têm a Liberdade de escolher se desejam responder ou não? Ah, e só caso tenham muito algo no caso simples, que tem algo relevante a acrescentar. Por fim, no no terceiro momento, será perguntado se os participantes têm alguma outra colocação ao sobre o tema então. Cada um de vocês terá esse movimento inicial para lhes pensar suas principais opiniões e pensamentos sobre o terminal e o tema é, disse que aí está e que foi também seguido então, começando do debatedor número 1. Quais são as suas opiniões iniciais sobre o tema?\"\n","\n","\"Marked\": \"Excelente. Pois bem, agora <rep eu eu/> explicarei as regras deste debate, e então, antes <rep de de/> mergulharmos em nossa discussão, é essencial. Todos compreendam e sigam as reuniões de debate. Essas regras foram ampliadas para garantir um debate justo e ordenado para todos os envolvidos. A única principal regra é: sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando. Se você deseja contribuir para alguma discussão ou oferecer um contra argumento, por favor, levante a mão e aguarde um moderador, no caso eu lhe conceder a palavra, uma vez que tenha sido autorizada a palavra, você terá a palavra e poderá expressar seus pensamentos ou responder aos outros. <hes ahh/>, vamos seguir um formato estruturado dividido em 3 momentos distintos, cada um com seu propósito e regras específicas. No primeiro momento abordaremos a questão principal no debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central. Que foi aquele tema que lhes foi enviado. No segundo momento teremos uma rodada de perguntas direcionadas para cada um dos debatedores. Abriremos espaço para outros participantes contra argumentar, ou expressarem as suas opiniões sobre a resposta dada após as perguntas direcionadas, teremos uma última pergunta que será direcionada a todos os participantes, nesse momento, vocês têm a Liberdade de escolher se desejam responder ou não <hes ahh/>, <erro e só caso tenham algo /> <corr no caso sintam que tem algo/> relevante a acrescentar. Por fim, <rep no no/> terceiro momento, será perguntado se os participantes têm alguma outra colocação final sobre o tema. Então cada um de vocês terá esse movimento inicial para expressar suas principais opiniões e pensamentos sobre o tema. E o tema é, esse que aí está e que foi também lhes enviado, então começando do debatedor número 1. Quais são as suas opiniões iniciais sobre o tema?\"\n","\n","\"Cleaned\": \"Excelente. Pois bem, agora eu explicarei as regras deste debate, e então, antes de mergulharmos em nossa discussão, é essencial. Todos compreendam e sigam as reuniões de debate. Essas regras foram ampliadas para garantir um debate justo e ordenado para todos os envolvidos. A única principal regra é: sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando. Se você deseja contribuir para alguma discussão ou oferecer um contra-argumento, por favor, levante a mão e aguarde um moderador, no caso de lhe concederem a palavra. Uma vez que tenha sido autorizado a falar, você terá a palavra e poderá expressar seus pensamentos ou responder aos outros. Vamos seguir um formato estruturado dividido em 3 momentos distintos, cada um com seu propósito e regras específicas. No primeiro momento, abordaremos a questão principal no debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central. No segundo momento, teremos uma rodada de perguntas direcionadas a cada um dos debatedores. Abriremos espaço para outros participantes contra-argumentarem ou expressarem suas opiniões sobre as respostas dadas. Após as perguntas direcionadas, teremos uma última pergunta que será direcionada a todos os participantes. Nesse momento, vocês têm a liberdade de escolher se desejam responder ou não. Caso sintam que têm algo relevante a acrescentar. Por fim, no terceiro momento, será perguntado se os participantes têm alguma outra colocação final sobre o tema. Então, cada um de vocês terá esse momento inicial para expressar suas principais opiniões e pensamentos sobre o tema. Começando pelo debatedor número 1, quais são suas opiniões iniciais sobre o tema?\"\n","\n","Following the example presented to you, remove all disfluencies from the following text without altering the original meaning or structure. You should NOT change text that does not refer to disfluencies. ANY text that is not in one of those three categories of disfluencies should not be changed. Return only the cleaned text with no additional information. Remember the text must be in its original full size, but without the disfluencies in it.\n","\n","Text: {texto_disfluente}\n","\"\"\"\n","\n","response3, duration3 = get_response_and_time(prompt)\n","\n","print(response3.text)\n","print('A limpeza foi feita em ', duration3)"],"metadata":{"id":"IJidpx6aFySS","executionInfo":{"status":"ok","timestamp":1725286217792,"user_tz":180,"elapsed":102245,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"750de102-1ff0-430e-fda8-31a01e8ae21e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Minha identificação é a número 1. Estou contribuindo com a pesquisa no Brasil. Minha identificação é a número 2. Estou contribuindo com a pesquisa no Brasil. Minha identificação é a número 3. Estou contribuindo com a pesquisa no Brasil. Então agora eu vou explicar basicamente a principal regra do debate, que é, antes de mergulharmos em nossa discussão, é essencial que todos compreendam o ensino, as regras de debate. Essas regras foram criadas para garantir o debate justo e ordenado para todos os envolvidos. A principal e essencial regra é: sem interrupções. Os debatedores não devem interromper uns aos outros enquanto alguém estiver falando.\n","Se você deseja contribuir para a discussão ou oferecer um contra-argumento, por favor, levante a mão e aguarde o moderador lhe conceder a palavra. Uma vez que tenha sido autorizado a falar, você terá a palavra e poderá expressar seus pensamentos ou responder aos outros.\n","Então, explicando o funcionamento do debate, nós vamos seguir o formato estruturado dividido em 3 momentos distintos, cada um com seu propósito e regras específicas. No momento 1, abordaremos a questão principal do debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central, que é aquele que eu lhes enviei. No momento 2, haverá uma rodada de perguntas e respostas direcionadas para cada um dos debatedores. Abriremos espaço para os outros participantes contra-argumentarem ou expressarem as suas opiniões sobre a resposta dada.\n","Após as perguntas direcionadas, teremos uma última pergunta que será direcionada a todos e, nesse momento, vocês têm a liberdade de escolher se desejam responder ou não, e caso sintam que têm algo relevante a acrescentar.\n","E, por fim, o último momento será de uma pergunta sobre a sua colocação final sobre o exemplo, se tem algo que é, enfim, colocação final.\n","Então a gravação já está sendo executada, certo? Primeiramente, cada um terá um momento inicial para expressar as suas principais opiniões e pensamentos sobre o tema, no caso, IA generativa, e cada participante terá um momento para fazer isso, começando pelo debatedor 1. Eu acho que, com um certo controle, ela contribui muito, principalmente para a gente que é estudante, por ter um tutor particular, basicamente. E para as outras pessoas também, inclusive. Não só a IA generativa contribui no campo acadêmico, só que você, com a IA, tem que também ter esse controle porque, como ela aprende com a gente, também pode aprender coisa errada. Isso é um problema porque quando você tem um negócio, por exemplo, o ChatGPT, como um público, que várias pessoas contribuem, vai chegar um momento que vira bagunça porque você pode contribuir com verdade, mas pode vir alguém e cair por terra sua fala, então aí vira uma bagunça. E não é nem controle, acho que é importante a fiscalização, é muito importante para o avanço de muita coisa. Acho que é isso, por hora. OK, agora o debatedor número 2. Então, eu acho que tem gente que é muito conservador em relação à IA, que é: \"Ah, eu sou contra totalmente, isso está acabando com a gente\". Mas, como o debatedor 1 falou, tem que ser usado na medida certa e não só o ChatGPT, mas também a IA para a formação de áudio, de vídeo, de imagem. Tudo isso, eu acho que tem muito a contribuir, tipo, ajuda muita gente, só que no campo ético, eu acho que tem que ser muito bem pensado porque pode ser usada para construir grandes coisas, tipo, em relação a, sei lá, uma cidade, pode criar uma história, uma mentira que pode acabar com a vida, assim, na sociedade, na cidade. Aí no campo acadêmico, eu também acho que tem gente que se aproveita exacerbadamente do uso da IA e não ajuda a IA a raciocinar mais, raciocina por ela, entendeu? Agora o debatedor 3. Pois bem, eu compactuo diretamente com a opinião do número 1 e do número 2, mas penso que deva haver algum meio de fiscalizar o que essas IAs estão fazendo porque elas vão seguir ao pé da letra o que você mandar, o que você programar para ela fazer. E acho que é aí que mora o provável problema, né? Porque a partir do momento que uma pessoa programa uma IA para fazer algo que, em teoria, traria o bem, mas se for seguido ao pé da letra, pode fazer muito mal, aí temos problemas. Um exemplo retirado direto da IA, que eu perguntei para o ChatGPT, é: por exemplo, se uma empresa mandou uma pessoa criar um código para implementar em uma IA, de maneira a acabar com a fome no mundo, aí vai, implementa, show de bola, começa a colocar essa IA. Poucos meses depois, alguns navios vão mudar de rota porque eles são guiados pela IA, aviões que deveriam chegar com alimentos em lugares não vão chegar e algumas regiões vão ser dizimadas, mas a IA está cumprindo o papel dela: se não há pessoas, não há fome. Eu acho que, partindo dessa lógica, tem que se haver o policiamento do que essas IAs estão fazendo. A partir do momento que começar a fazer mal à humanidade, tem que ter uma maneira de parar, dar um break. Vamos iniciar uma rodada de perguntas. Irei realizar uma pergunta para cada participante, que terá seu tempo de resposta e, ao final de sua resposta, os demais podem pedir espaço para comentar algo sobre a pergunta feita ou então a resposta dada, certo? Vamos começar. A primeira pergunta para o debatedor 1: se um sistema de IA generativa criar algo prejudicial ou ofensivo, por exemplo, uma imagem com conteúdo racista, quem deve ser responsabilizado? O desenvolvedor da IA, o usuário, a plataforma que hospeda ou alguma outra instituição ou pessoa? É isso aí você me pega porque é muita gente. A inteligência artificial, ela aprende com a gente. Então se alguém ensinou ela a fazer uma coisa específica, ela vai aprender. Então, assim, foi, por exemplo, você criou a IA para determinada coisa, eu vou lá e ensino outra coisa, isso fica armazenado. Então se a IA gera uma coisa que é um problema, por exemplo, aí tem que ver, né? Porque, tipo, até onde eu vou apontar o dedo? Para quem eu vou apontar o dedo? Até onde eu tolero quem fez isso? Então eu não acho que dá para apontar o dedo para uma pessoa específica porque pode ter sido culpa do criador, pode ter sido culpa do usuário ou da empresa, pode ser dos três ou de todos. Debatedor 3, não só complementar que pode ter sido culpa de tudinho e tudinho para responder pelo crime. Aí eu acho que entra no âmbito de fiscalização, criar regras, porque quando a IA cria um problema ou alguma coisa que fere o direito de alguém, quem vai ser culpado? Não tem isso, não tem uma regra falando, ninguém deve ser culpado e eu acho que não tem lei também, né? Então, assim, fica complicado culpar alguém. Eu acho que é complicado culpar alguém, mas, por exemplo, se um usuário pedir para a IA gerar uma coisa de caráter racista, o usuário tem parte de culpa nisso, mas a IA está gerando esse conteúdo porque tem uma base de dados que tem esse caráter racista. Então, como o debatedor 1 falou, eu acho que pode ser culpa de qualquer pessoa, qualquer um: o desenvolvedor, a plataforma ou o usuário. E também acho que é aquilo que eu falei da ética na IA, da fiscalização, porque todos os crimes podem ser gerados por IA porque, como o debatedor 3 falou, por exemplo, a história de acabar com a fome no mundo pode gerar um crime pela IA. Indo para outra perspectiva, a gente pode ver parte de culpa do criador porque, como ele criou, ele pode limitar também, ele pode limitar a IA para quando ela recebesse, ela retornasse: \"Não, isso aqui não é legal, então não vou te responder, não vou aprender isso\". Então eu acho que, assim, parte tem como não criar, não pode ter sido, tipo, não intencionalmente, mas por que não me limitar se vai ver ferir o direito de alguém, se não é construtivo para ninguém? Nem para a IA, nem para ele. Debatedor 3, mas e por que limitar? Porque, limitando, você está limitando o processo de desenvolvimento. Logo, talvez ela desenvolvesse para fazer algo, ficaria patinando no mesmo ciclo, não desenvolvesse como se a IA tivesse toda a liberdade, poderia desenvolver. Eu acho que, se tiver alguma coisa que fere algum direito de alguém, poderia ser, não limitado, mas dada uma resposta, por exemplo: \"Ah, não vou criar conteúdos desse caráter por conta disso, disso e disso\", mas ele vai ter a base de dados. O debatedor 3 falou sobre a liberdade do aprendizado da IA, mas até que ponto uma liberdade para aprender uma coisa que não é construtiva para ninguém, que fere o direito do outro, até onde isso é liberdade de aprender? Porque não faz sentido. Você pega, por exemplo, saindo de IA, aplicativos como Instagram, como Twitter, eles já reconhecem conteúdos que são racistas, conteúdos com teor pornográfico, eles reconhecem. Então a IA pode muito bem reconhecer isso e, assim: \"Não, bloqueia isso, eu não vou reter esse conhecimento e não vou retornar nada\", mesmo que o usuário volte lhe pedindo, ele não retorne nada, até porque não faz sentido. Que tipo de conhecimento amplo é esse que você pode aprender uma coisa que fere o outro? Alguém mais quer falar sobre esse ponto? Pois bem, vamos para a segunda pergunta, para o debatedor 2. IAs generativas podem ser usadas nos processos educacionais? Por exemplo, em aulas, em atividades ou provas, o aluno deve reportar ao professor sobre o uso de IAs generativas em suas atividades? Eu imagino que sim, que pode ser usado, que a IA, por exemplo, eu estava com dúvida em uma questão e eu estava pensando de uma forma e ela me ajudou a ter um raciocínio de outra forma, mas não copiando tudo. Pode ser usado para ajuda de raciocínios, mas eu acho que, nos processos educacionais, os professores, os docentes, estão se restringindo muito do leque de possibilidades que a IA poderia dar às aulas, por exemplo, uma aula mais interativa ou ajuda ou pesquisas com os alunos por meio da IA, como uma ferramenta tipo Google, só que usando o ChatGPT, por exemplo. Eu acho que eles se restringem muito. No sentido de restrição, não deve ser restringido, mas aí a gente volta para a ética e para o seu senso de uso, tanto de professor como do aluno, porque você está usando para quê? Até que ponto aquilo ali é seu? Até que ponto lhe ajudou? Então, dependendo do que você pediu, quanto que você fez? Você pegou o resultado que a IA deu para quê? Então tem que ser, eu não acho que tem que ser restringido, tem que ser aberto a todos, tanto para professor quanto ao aluno, mas com uso responsável. OK, eu não vou generalizar tanto, 50% das pessoas não fazem. Eu conheço um bocado de pessoas que: \"Ah, não sei a pergunta do ChatGPT, me bota a resposta lá, né?\". Atividade, principalmente no momento de pandemia, essa coisa muito, muito mais forms da vida que só queria a resposta, não importava como você fez. Eu vi muita gente usando desses artifícios para passar, tirar notas boas e, depois no final, não saber nem o que fez. E, inclusive, questão de redações, que é um negócio que eu tive uma experiência bem de perto mesmo, algumas pessoas pegam, mandam para o ChatGPT fazer a redação de qualquer tema, ele vai fazer, põem outra, três palavrinhas, invertem o parágrafo e mandam, tiram notas boas. Acho que o conselho acadêmico deveria haver um jeito também de fazer o ChatGPT não dar a resposta pronta, mas mostrar como faz. Eu acho que é, tipo, um ChatGPT acadêmico, né? Seria inovador, diria. Então o debatedor 3 concorda que deveria ser restringido? Não, restringido não, criada uma nova ferramenta específica para a educação. Mas isso é restringir o uso das IAs, não? Você poderá restringir dentro da escola, mas você vai ter a outra justamente de provas, eu acho que seria importante. Mas o que garante que você mesmo entenda essa nova ferramenta, assim, tipo, um filtros limitadores, o que garante que a pessoa não vai usar a outra? É muito leve e aberto, mas quando você parte para a ética, o uso de uma IA normal, sem ter filtro nem limitação, você usando com ética e responsabilidade já seria o uso correto, não concorda? Por exemplo, tem o ChatGPT como exemplo, ele é uma base de dados, então ele não está 100% correto o tempo todo. Então eu já vi gente reclamando: \"Ah, eu usei uma IA generativa e a resposta que deu estava errada\". Só que você, além de você, tem que ter o seu senso e saber o que você está falando. Exatamente o que ela falou porque se você pega e pergunta uma coisa e você tem um resultado e você pega ali e usa, você vai estar pondo em risco a tua integridade, a tua ética, e você não está confirmando se aquilo ali é realmente completamente verídico porque, como eu já havia falado, ela está aprendendo, ela está aprendendo coisa errada também. Ela não está sempre dando o resultado e você não verifica, a responsabilidade é tua. Alguém mais gostaria de falar algo sobre? Pois bem, então passaremos à terceira pergunta, para o debatedor 3. De que maneira a propriedade intelectual deve ser tratada quando o conteúdo é gerado por uma IA? Por exemplo, se o usuário gerou uma música usando IA, o crédito pela criação deve ser deste usuário, da plataforma utilizada, do criador dos dados originais com os quais a IA foi treinada? Eis uma grande dúvida, há muita discussão sobre isso. Modéstia à parte, eu acho que, como a IA aprende com quem está interagindo com ela, eu acho que, mesmo que houvesse uma divisão, \"Não, eu que fiz a IA, eu quero 20%, sei lá, 10% dos créditos da música\", acho que a maior parte deve ser para a pessoa que a treinou, mesmo que uma parte pequena, assim, 10%, 5%, for para a plataforma e outros 10% para o criador da IA, acho que a maior parte tem que ir para quem a treinou, o usuário que interagiu com ela para criar essa música. Eu acho que a criação de música pela IA, usando outras músicas, deve ser pensado da mesma forma que, por exemplo, na indústria da música atualmente, eles usam a interpolação. Eu acho que uma parte vai para o criador original e a outra parte dos números da música vai para quem fez uma pegada diferente com essa música, por exemplo. Só que eu acho que tem que partir para essa parte legal da mesma forma que as interpolações são feitas e eu não acho que deva ir dinheiro para a plataforma de IA porque ela é só um meio que o usuário está usando para criar aquilo. Acho uma pergunta um pouco aberta porque, quando você usa uma plataforma de IA, mais difundido o ChatGPT, ela tem regras, tem condições que você aceita. Então, dependendo do que tem nessas condições, nessas regras que ela passa e você aceita, do que você aceitou, você está se propondo a correr o risco de, dependendo do que ela gerou, você vai partir para ela, para o criador. E outra coisa, por exemplo, se um usuário gerar uma música usando IA, aí é o questionamento: até onde, aliás, gerou a música e que partes ela fez? Ela adicionou palavras? Ela ajudou você no raciocínio? Como é que isso vai ser fiscalizado? Então eu acho que tem que ser vários pontos analisados até chegar ao veredito de quem vai ser creditado por isso. Agora eu vou fazer uma pergunta direcionada a todo o grupo, qualquer um dos debatedores pode responder. O uso e o desenvolvimento de IAs generativas devem ser fortemente fiscalizados por órgãos governamentais ou elas são apenas mais um tipo de software comum, como milhares de outros existentes? Eu acho que a resposta deve ser fortemente fiscalizada, como a música, porque, até como todo o nosso impacto foi, o debate foi em relação a isso, que deve haver a fiscalização, deve-se usar as IAs, mas com a forte fiscalização. Mas a fiscalização tem que ser governamental? Porque no país, no Brasil, onde estamos, a fiscalização governamental é falha. Então, assim, eu acho que ele é um software comum e, dependendo do seu uso, dependendo do que você fez, você tem uma consequência. Eu acho que onde o governo tem que entrar, dependendo da situação, da conjuntura atual ou do futuro, é criar regras, alguma regra ou algo do tipo, mas não fiscalizar fortemente porque essa fiscalização fortemente, em algum momento, ela vai vir, ela vai ser limitante para a IA. Então, até que ponto fiscalizar fortemente? Eu vou concordar com ele que falou, no Brasil que nós vivemos, o pessoal joga o lixo fora do lixo, do lado do lixo, então não vai funcionar. Aí eu acho que, como os países têm, vou caçar aqui a palavra, culturas diferentes, cada um pode definir de uma forma diferente até que ponto nós temos uma IA porque cada cultura tem seus princípios, seus, suas culturas, sua cultura em geral, cada povo tem sua cultura e, para algumas culturas, pode ser bom algo e para outros não. Aí, tipo, em um país, a IA é fiscalizada pelo governo e o governo disse: \"Não, você não pode ensinar o pessoal como criar um avião\", e a outra disse que tem que ensinar o pessoal. Acho que vai dar errado, vão ter duas IAs diferentes, no caso, viu? Eu acho que para dar certo, tem que ser uma IA universal e as mesmas regras em todos os países. Aí tem algumas que podem ser moldadas de acordo com a situação, mas, partindo desse, eu acho que tem que ser pouco fiscalizada, mas tem que ter algumas regras que sejam universais para todas. Tem que existir a regra universal para todas, OK? Mas eu não... Nenhuma pessoa de assunto informando o governo porque pode ser falha, pode ser instintiva e pode tirar a liberdade. Mais alguém gostaria de comentar algo? Não? Pois bem, então agora, certo, nós partimos para a última fase do debate, em que cada participante terá um momento para falar suas considerações finais sobre o tema, sua opinião ou visão sobre o tema no geral. Então, sua opinião ou visão sobre o tema mudou depois do debate ou se fortaleceu ou algum tipo? Fortaleceu. Opinião é a mesma: uso aberto, uso livre, uso consciente, consciente de consequência, uma regra ou outra. Fiscalização governamental, não. Continua a mesma também, mas eu acredito na fiscalização governamental porque, se não houver uma fiscalização, que órgão vai ser geral para toda a sociedade? Por que que você acha que tem que ser o governo? Por que que as próprias empresas, criadores de IA, não criam um meio, um órgão que fiscalize e que reja? Por que tem que vir do governo? Essa esse órgão vindo de empresas não seria facilmente burlado, não? Mas o quê que garante que a fiscalização governamental seria menos falha do que uma privada? Porque eu penso em uma fiscalização privada, como talvez tenha que ter, talvez um pouquinho do dedo do governo para ser um mediador de todas as empresas que criam IAs, por exemplo, aí pode ser OK, mas só o governo fiscalizando não, é pouco, é inviável. Pensando nisso, está partindo daquele exemplo do que eu falei logo no início, da fome, aí a pessoa manda um processo generativo lá para a empresa e ela passa pelo governo e o governo olha: \"Tá bacana? Vai, vai solucionar a fome\". A empresa vai, aí a empresa começa a distribuir essa IA e implementar nos computadores. Dentro do governo dá certo? A pergunta é um pouco vaga porque o nosso plano de governo atual é bonito, só que na prática que a gente vê coisa, então é a fiscalização em si. Por isso que eu falei, eu acho que o governo teria minimamente só a consciência, no máximo, entrar como mediador, talvez. Porque não faz sentido, porque nada garante, seja uma situação só governamental, seja fiscalização de empresa privada ou um consenso mundial, de qualquer forma, ela vai ser falha. Ninguém garante que ela vai ser completamente uma fiscalização completamente OK. Porque, outra coisa, você acha que a fiscalização, ela seria melhor pelo governo? Não, eu acho que seria ruim, mas impô-las em alguns cantos. Acho que vai depender muito do governo que está regendo a região porque, se for um governo que vai implementar as leis e procura resolver os problemas, pode ser uma fiscalização plausível, mas aí, se um governo agir com descaso, não, vai ser muito inviável. Até eu pensei agora, uma junção dos dois, fase um, fazer dois, passou pela fase do governo, aí passa pelos testes, entre aspas, da empresa que criou. Eu pensei na fiscalização do governo porque traz a universalidade em todas essas empresas de IA, entendeu? Como os debatedores estavam falando, cada empresa pode ter diferentes morais e éticas que podem estar passando por diferentes coisas, não? E eu coloquei, em tese na minha fala, um governo que funciona perfeitamente, então pensei normal, que é falho. Talvez, talvez a iniciativa público-privada seria uma boa, assim, a depender da circunstância e da forma que ela vai ser criada, porque falar de fiscalização de IA, principalmente na época atual que a gente está vivendo, que elas estão tendo o boom, que está começando a ser estudado amplamente, então não seja uma boa hora agora, mas em algum momento deve-se existir e deve ser conversado. Como isso vai funcionar? Como isso vai agir? Não dá para você chegar e falar: \"Ah, eu acho que a fiscalização tem que ser assim, assim\", porque nunca vai, nunca vai agradar todo mundo, vai ter pontos negativos sempre. Bem, nesse caso, retomamos a pergunta final, né? Porque a gente acabou voltando ao assunto anterior, houve uma mudança de visão? Quais são as suas considerações finais sobre o tema? Essa mudança ocorreu depois do debate? Poder livre, aberto, talvez um dedo do governo aí e, possivelmente, uma fiscalização público-privada. Continua a mesma, mas eu pensei na ideia dos debatedores e, eu ainda acredito na fiscalização governamental por conta da universalidade, mas tem que ter o dedo de mais pessoas. Mudou-se um pouco a minha ideia, levando em conta que ainda a IA está aprendendo muito ainda. Eu concordei que não agora, mas depois de um certo conhecimento de como essa IA vai se comportar e entender melhor ela, talvez exista uma certa fiscalização público-privada. Entendi. Pois bem, gente, estamos chegando ao final do nosso debate. Então vocês podem escanear esse QR Code para um formulário de autoavaliação, bem rapidinho, e as respostas são confidenciais e serão utilizadas só para os fins de avaliação e aprimoramento, no geral, não.\n","\n","A limpeza foi feita em  102.57666277885437\n"]}]},{"cell_type":"markdown","source":["# Chain-of-Thought Prompt"],"metadata":{"id":"ekjL9_-gBrXC"}},{"cell_type":"code","source":["prompt = f\"\"\"\n","Context: The text below is a transcription in Portuguese from a Speech-to-Text (STT) model of a debate. In these transcriptions, disfluencies such as hesitations, repetitions, and corrections are common.\n","\n","- **Repetitions**: These occur when a word or phrase is repeated consecutively without adding any new meaning or value to the sentence. Repetitions are often present in speech but they do not contribute any additional information to the context. For example, in the phrase \"o ambiente da da tecnologia,\" the word \"da\" is repeated twitce without adding anything meaningful to the sentence, only one occurence of \"da\" would be sufficient to get what the phrase is trying to transmit.\n","\n","- **Hesitations**: These are non-verbal expressions or fillers used in speech to indicate a pause or hesitation. Common hesitations include sounds like \"ahh,\" \"ehh,\" \"um,\", \"hmm\" or \"uh.\" They serve as verbal placeholders while the speaker thinks or searches for the right words. Although they can indicate thought processes, they do not add substantive meaning to the text and should be removed for clarity. For example, in the phrase \"Eu estava, ahh, pensando sobre isso,\" the term \"ahh\" is a hesitation that can be removed.\n","\n","- **Corrections**: These occur when a speaker makes an initial error in their speech and then corrects it. The correction typically involves an initial incorrect phrase followed by a revised version of the same phrase. For instance, in the phrase \"que isso é, quer dizer, isso foi,\" the speaker initially says \"que isso é,\" makes a correction by saying \"quer dizer,\" and finally provides the corrected phrase \"isso foi.\" The goal is to remove the error, leaving only the final corrected version.\n","\n","Your task is to identify and remove these disfluencies while maintaining the original meaning and structure of the text. We will do this step by step, identifying and removing each type of disfluency.\n","\n","Example 1:\n","\n","Step 1: Identify Repetitions\n","\n","Original: \"Oi, eu eu acho que que é importante começar.\"\n","Marked: \"Oi, <rep eu eu/> acho que <rep que que/> é importante começar.\"\n","Action: Remove repeated words.\n","Cleaned: \"Oi, eu acho que é importante começar.\"\n","\n","Step 2: Identify Hesitations\n","\n","Original: \"Ah, bem, então...\"\n","Marked: \"<hes Ah,/> bem, então...\"\n","Action: Remove hesitation fillers like \"Ah,\" \"é,\" etc.\n","\n","Step 3: Identify Corrections\n","\n","Original: \"Esse é, quero dizer, isso é essencial.\"\n","Marked: \"<erro Esse é, quero dizer,/> <corr isso é essencial./>\"\n","Action: Remove filler words during corrections.\n","Cleaned: \"isso é essencial.\"\n","\n","Example 2:\n","\n","Step 1: Identify Repetitions\n","\n","Original: \"Bem, a gente tem que, ah, analisar mais profundamente.\"\n","Marked: \"Bem, a gente tem que, <rep analisar analisar/> mais profundamente.\"\n","Action: No repetition to remove.\n","Cleaned: \"Bem, a gente tem que, analisar mais profundamente.\"\n","\n","\n","Step 2: Identify Hesitations\n","\n","Original: \"Ah, analisar mais profundamente.\"\n","Marked: \"<hes Ah,/> analisar mais profundamente.\"\n","Action: Remove hesitation \"Ah.\"\n","Cleaned: \"analisar mais profundamente.\"\n","\n","\n","Step 3: Identify Corrections\n","\n","Original: \"e só caso tenham algo, no caso sintam que tem algo\"\n","Marked: \" <erro e só caso tenham algo /> <corr no caso sintam que tem algo/>\"\n","Action: Remove errors and keep the corrections\".\n","Marked: \"no caso sintam que tem algo\"\n","\n","Instructions: Using the step-by-step method demonstrated in the examples, identify and remove all disfluencies from the following text. Ensure to maintain the original transcription and structure. You should NOT change text that does not refer to disfluencies. ANY text that is not in one of those three categories of disfluencies should not be changed. Return only the cleaned text with no additional information. Remember the text must be in its original full size, but without the disfluencies in it.\n","\n","Text: {texto_disfluente}\n","\"\"\"\n","\n","response4, duration4 = get_response_and_time(prompt)\n","\n","print(response4.text)\n","print('A limpeza foi feita em ', duration4)"],"metadata":{"id":"iwPZYNRJBrF5","executionInfo":{"status":"ok","timestamp":1725286322024,"user_tz":180,"elapsed":104242,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"f285c161-71d8-4027-af1f-3b2dbce5e05f"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Minha identificação é a número 1. Estou contribuindo com a pesquisa no Brasil. Minha identificação é a número 2. Estou contribuindo com a pesquisa no Brasil. Minha identificação é a número 3. Estou contribuindo com a pesquisa no Brasil. Então agora eu vou explicar basicamente a principal regra do debate, que é antes de mergulharmos em nossa discussão, é essencial todos compreendam o ensino, as regras de debate. Essas regras foram criadas para garantir o debate justo e ordenado para todos os envolvidos. A principal e a essencial regra é sem interrupções. Os debatedores não devem interromper uns aos outros entre nós, alguém estiver falando.\n","Se você deseja contribuir para a discussão ou oferecer um contrato médio, por favor, levante a mão e aguarde o moderador lhe conceder a palavra. Caso, uma vez que tenha sido autorizado a falar, você terá a palavra do Bandeirantes para prestar seus pensamentos ou responder aos outros.\n","Então, explicando o funcionamento do debate, nós vamos seguir, levar para o formato estruturado, deveria ter em 3 momentos distintos, cada um com seu propósito em regras específicas. No momento 1, abordaremos a questão principal do debate e o objetivo é que cada participante expresse sua opinião inicial sobre o tema central, que é aquele que eu lhes mandei. No momento 2, haverá uma rodada de perguntas e respostas direcionadas para cada um dos debatedores, abriremos espaço para os outros participantes contra-argumentar e prestarem as suas opiniões sobre a resposta dada.\n","Após as perguntas direcionadas, teremos uma última pergunta que será direcionada a todos e, nesse momento, vocês têm a liberdade de escolher se desejam responder ou não e caso sintam que tem algo relevante a acrescentar também ou não.\n","E no fim, o último momento será de uma pergunta sobre a sua colocação final sobre o exemplo, se tem algo que é, enfim, colocação final.\n","Então a gravação já está sendo executada, certo? Quando alguém... E primeiramente, para não, terá um momento inicial para expressar as suas principais opiniões e pensamento sobre o tema, no caso, IA generativa e cada participante terá um momento para fazer isso, começando pelo debatedor 1. Eu acho que com um certo controle, ela contribuiu muito, principalmente para a gente que é estudante, por ter um tutor particular, basicamente. E para as outras pessoas também, inclusive. Não só a IA generativa, ela contribui no campo acadêmico, só que você, com a IA, tem que também ter esse controle, porque como ela aprende com a gente, também pode aprender coisa errada. Isso é um problema porque quando você tem um negócio, por exemplo, o ChatGPT, como um público, que várias pessoas contribuem, vai chegar um momento que vira bagunça e, porque você pode contribuir com verdade, mas pode vir alguém e cair por terra sua fala, então aí vira uma bagunça. E não é nem controle, acho que é importante a fiscalização, é muito importante para o avanço de muita coisa. Acho que é isso, por hora. OK, agora o debatedor número 2. Então, eu acho que tem gente que é muito conservador em relação à IA, que é: \"Ah, eu sou contra totalmente, isso está acabando com a gente\". Mas como o debatedor 1 falou, tem que ser usado na medida certa e não só o ChatGPT, mas também a IA para a formação de áudio, de vídeo, de imagem. Tudo isso eu acho que tem muito a contribuir. Tipo, a gente ajuda muita gente, só que no campo ético, eu acho que tem gente, tem que ser muito bem pensado, porque pode ser usada para construir grandes coisas, tipo em relação a, sei lá, a uma cidade, pode criar uma história de uma mentira que pode acabar com a vida assim, na sociedade, na cidade, aí no campo acadêmico, eu também acho que tem gente que se aproveita exacerbadamente do uso da IA e não ajuda a IA a raciocinar mais, raciocina por ela, entendeu? Agora o debatedor 3. Pois bem, eu compactuo diretamente com a opinião do número 1 e do número 2, mas penso que deva haver alguma meio de fiscalizar o que essas IAs estão fazendo, porque elas vão seguir ao pé da letra o que você mandar, o que você programar para ela fazer. E acho que é aí que mora o provável problema, né? Porque a partir do momento que uma pessoa programa uma IA para fazer algo que em teoria traria o bem, mas se for seguido ao pé da letra, pode fazer muito mal. Aí temos problemas. Um exemplo retirado direto da IA, que eu perguntei para o ChatGPT é: por exemplo, se uma empresa mandou uma pessoa criar um código fontezinho só para implementar numa IA, de maneira de acabar com a fome no mundo. Aí vai, implementa. Show de bola, começa a colocar essa IA. Poucos meses depois, alguns navios vão mudar de rota, porque eles são guiados pela IA, aviões que deveriam chegar com alimentos em lugares não vão chegar e algumas regiões vão ser dizimadas. Mas a IA está cumprindo o papel dela. Se não há pessoas, não há fome. Ah, eu acho que partindo dessa lógica, né? Tem que se haver o policiamento do que essas IAs estão fazendo. A partir do momento que começar a fazer mal à humanidade, tem que ter uma maneira de parar, dar um break, né? Vamos iniciar uma rodada de perguntas, irei realizar uma pergunta para cada participante, que terá seu tempo de resposta e ao final de sua resposta, os demais podem pedir espaço para comentar algo sobre a pergunta feita ou então a resposta dada, certo? Vamos começar. A primeira pergunta para o debatedor 1. Se um sistema de IA generativa criar algo prejudicial ou ofensivo, por exemplo, uma imagem com conteúdo racista, quem deve ser responsabilizado? O desenvolvedor da IA, o usuário, a plataforma que hospeda ou alguma outra instituição ou pessoa? É isso. Aí você me pega porque é muita gente. É inteligência artificial, ela aprende com a gente. Então se alguém ensinou ela fazer uma coisa específica, ela vai aprender. Então assim foi, por exemplo, você criou a IA para determinada coisa, eu vou lá e ensino outra coisa, isso fica armazenado. Então se a IA gera uma coisa que é um problema, por exemplo, aí tem que ver, né? Porque, tipo, até onde eu vou apontar o dedo, para quem eu vou apontar o dedo? Até onde eu tolero quem fez isso? Quem fez isso? Então, eu não acho que dá para apontar o dedo para uma pessoa específica, porque pode ter sido culpa do criador, pode ter sido culpa do usuário ou da empresa. Pode ser dos 3. Ou de todos. Debatedor 3. Não, só complementar que pode ter sido culpa de tudinho e tudinho para responder pelo crime. Aí eu acho que entra no âmbito de fiscalização, criar regras. Porque quando ela cria, quando a IA cria um problema ou alguma coisa que fere direito de alguém, quem vai ser culpado? Não tem isso, não tem uma regra falando, ninguém deve ser culpado e eu acho que não tem lei também, né? Então assim fica complicado culpar alguém. Eu acho que é, também acho que é complicado culpar alguém. Mas, por exemplo, se um usuário pedir para a gente gerar uma coisa de caráter racista, o usuário tem parte de culpa nisso, mas ele, a IA está gerando esse conteúdo porque tem uma base de dados que tem esse caráter racista. Então, como o debatedor 1 falou, eu acho que pode ser culpa de qualquer pessoa, qualquer um, o desenvolvedor, a plataforma ou o usuário. E também acho que é aquilo que eu falei da ética na IA, do, da fiscalização, porque todos os crimes podem ser gerados por IA, porque como o debatedor 3 falou, por exemplo, a história de acabar com a fome no mundo, pode gerar um crime pela IA. Indo para outra perspectiva, a gente pode ver parte de culpa do criador, porque como ele criou, ele pode limitar também. Ele pode limitar a IA, então porque ele não limitou isso? Para quando ele recebesse, ela retorna: \"Não, isso aqui não é legal, então não vou te responder, não vou aprender isso\". Então eu acho que é assim, parte tem como eu não criar. Não pode ter sido tipo, não intencionalmente, mas porque não me limitar se vai ver ferir o direito de alguém, se não é construtivo para ninguém? Nem para a IA, nem para ele. Debatedor 3. Mas e por que limitar? Porque limitando você está limitando o processo de desenvolvimento. Logo, talvez ela desenvolvesse para fazer algo, ficaria patinando no mesmo ciclo, não desenvolvesse como a IA tivesse toda a liberdade, poderia desenvolver. Eu acho que se tiver alguma coisa assim que fere algum direito de alguém, poderia ser, não limitado, mas, dado uma resposta, por exemplo: \"Ah, não vou criar conteúdos desse caráter por conta disso, disso e disso\", mas ele vai ter a base de dados. O debatedor 3 falou sobre liberdade do aprendizado da IA. Mas até que ponto uma liberdade para aprender uma coisa que não é construtiva para ninguém, que fere o direito do outro, até onde isso é liberdade de aprender? Porque não faz sentido. Tu pega, por exemplo, saindo de IA, aplicativo como Instagram, como Twitter, eles já reconhecem conteúdos que são racistas, conteúdos com teor pornográfico. Eles reconhecem. Então IA pode muito bem reconhecer isso e assim: \"Não, bloqueia isso. Eu não vou reter esse conhecimento e não vou retornar nada\", mesmo que o usuário volte lhe pedindo, ele não retorne nada, até porque não faz sentido. Que tipo de conhecimento amplo é esse que você pode aprender uma coisa que fere o outro? Alguém mais quer falar sobre esse ponto? Pois bem, vamos para a segunda pergunta para o debatedor 2. IAs generativas podem ser usadas nos processos educacionais? Por exemplo, em aulas, em aula, atividades ou provas, o ou a aluna deve reportar ao professor sobre o uso de IA generativas em suas atividades? Eu imagino que sim, que pode ser usado, que a IA, por exemplo, eu estava com dúvida em uma questão e eu estava pensando de uma forma e ela me ajudou a ter um raciocínio de outra forma, mas não copiando tudo. Pode ser, pode ser usado para ajuda de raciocínios, mas eu acho que nos processos educacionais, os professores, os docentes, qualquer coisa, eles estão se restringindo muito do leque de possibilidades que a IA poderia dar ao, a aulas, por exemplo, uma aula mais interativa ou ajuda ou pesquisas com os alunos por meio da IA, como uma ferramenta tipo Google. Só que usando GPT, por exemplo, eu acho que eles se restringem muito. No sentido de restrição, não deve ser restringido, mas aí a gente volta para a ética e para o seu senso de uso, tanto de professor como do aluno, porque você está usando para quê? Até que ponto aquilo ali é seu? Até que ponto lhe ajudou? Então, dependendo do que você pediu, quanto que você fez? Você pegou o resultado que a IA deu para quê? Então tem que ser, eu não acho que tem que ser restringido, tem que ser aberto a todo, a todos, tanto para professor quanto ao aluno, mas com uso responsável. OK, eu não vou generalizar tanto. 50% das pessoas não fazem. Eu conheço um bocado de pessoas que: \"Ah, não sei, pergunta do ChatGPT, me bota a resposta lá, né? Atividade, principalmente no momento de pandemia, essa coisa muito, muito mais forms lá da vida que só queria a resposta, não importava como você fez. Eu vi muita gente usando desses artifícios para passar, tirar notas boas e depois no final, não saber nem o que fez. E inclusive, questão de redações que é um negócio que eu tive uma experiência bem de perto mesmo. Algumas pessoas pegam, mandam para o ChatGPT, fazem a redação de qualquer tema. Ele vai fazer, põe outro, 3 palavrinhas, inverte o parágrafo outro e manda, tira notas boas. Acho que o conselho acadêmico deveria haver um jeito também de fazer o ChatGPT não dar a resposta pronta, mas mostrar como faz. Eu acho que é tipo um ChatGPT acadêmico, né? Seria inovador, diria. Então o debatedor 3 concorda que deveria ser restringido? Não, restringido não, criada uma nova ferramenta específica para a educação. Mas isso é restringir o uso das IAs, não? Você poderá restringir dentro da escola, mas você vai ter a outra justamente de provas. Eu acho que seria importante. Mas o que garante que você mesmo entenda essa nova ferramenta assim, tipo, um filtros limitadores, o que garante que a pessoa não vai usar a outra? É muito leve e aberto. Mas quando você parte para a ética, o uso de uma IA normal sem ter filtro nem limitação, você usando com ética e responsabilidade já seria uso correto, não concorda? Por exemplo, tem o ChatGPT como exemplo. Ele é uma base de dados, então ele não está 100% correto o tempo todo. Então eu já vi gente reclamando: \"Ah, eu usei uma IA generativa e a resposta que deu estava errada.\" Só que você, além de você, tem que ter o seu senso e saber o que você está falando. Exatamente o que ela falou, porque se tu pega, se tu pega e se tu pergunta uma coisa e tu tem um resultado e tu pega ali e usa, tu vai estar pondo em risco tua integridade, a tua ética. E você não está confirmando se aquilo ali é realmente completamente verídico, porque como já, como eu já havia falado, ela está aprendendo, ela está aprendendo coisa errada também. Eu não estou sempre dando resultado e tu não verifica, a responsabilidade é tua. Alguém mais gostaria de falar algo sobre? Pois bem, então passaremos a terceira pergunta para o debatedor 3. De que maneira a propriedade intelectual deve ser tratada quando o conteúdo é gerado por uma IA? Por exemplo, se o usuário gerou uma música usando IA, o crédito pela criação deve ser o deste usuário? Da plataforma utilizada? Do criador dos dados originais com os quais a IA foi treinada? Eis uma grande dúvida. Há muita discussão sobre isso. Modéstia à parte, eu acho que como a IA aprende com quem está interagindo com ela, eu acho que mesmo que houvesse uma divisão, não, eu que fiz a IA, eu quero 20%, sei lá, 10% dos créditos da música. Acho que a maior parte deve, deve ser para uma pessoa que ela foi treinada mesmo, mesmo que uma parte pequena, assim 10, 5% for para a plataforma e outros 10% por criador da IA, acho que a maior parte tem que ir para quem a treinou, o usuário que interagiu com ela para criar essa música. Eu acho que a criação de música pela IA usando outras músicas deve ser pensado da mesma forma que, por exemplo, na indústria da música atualmente eles usam a interpolação. Eu acho que é uma parte vai para o criador original e a outra, o útil, parte dos números da música vai para quem fez uma pegada diferente com essa música, por exemplo. Só que eu acho que tem que partir para essa parte legal da mesma forma que as interpolações são feitas e eu não acho que ainda deve aí dinheiro para a plataforma de IA, porque ela é só um meio que o usuário está usando para criar aquilo. Acho uma pergunta um pouco aberta, porque quando você usa uma plataforma, por exemplo, de IA, mais difundido ChatGPT, ela tem, ela tem regras, tem condições que você aceita. Então, dependendo do que tem nessas condições, nessas regras que ela passa e você vai está lá e aceita, do que você aceitou, você, se você não lembra, você está se propondo a correr o risco de, dependendo do que ela gerou, você vai partir para ela, para o criador. E outra coisa, por exemplo, se um usuário gerar uma música usando IA, aí é o questionamento, até onde, aliás, gerou a música e que partes ela fez? Ela adicionou palavras? Ela ajudou você no raciocínio? Como é que a gente, como é que isso vai ser fiscalizado? Então eu acho, eu tem que ser vários pontos analisados até chegar ao veredito de quem vai ser, quem vai ser creditado por isso. Agora eu vou fazer uma pergunta direcionada a todo grupo, qualquer um dos debatedores podem responder. O uso e o desenvolvimento de IAs generativas devem ser fortemente fiscalizados por órgãos governamentais ou elas são apenas mais um tipo de software comum como milhares de outros existentes? Eu acho que uma resposta deve ser fortemente fiscalizada como a música, porque até como todo o nosso impacto foi, o debate foi em relação a isso, que deve haver a fiscalização da, deve-se usar as IAs, mas com a forte fiscalização. Mas a fiscalização tem que ser governamental? Porque, porque no país, no Brasil, onde estamos, a fiscalização governamental é falha. Então assim, eu acho que ele é um software comum e dependendo do seu uso, dependendo do que você fez, você tem uma consequência. Eu acho que o, onde é que o governo tem que entrar, dependendo da situação, da conjuntura atual ou do futuro, criar regras, alguma regra ou algo do tipo, mas não fiscalizar fortemente, porque essa fiscalização fortemente em algum momento, ela vai vir, ela vai ser limitante para a IA. Então, até que ponto fiscalizar fortemente? É, eu vou concordar com ele que falou, no Brasil que nós vivemos, o pessoal joga o lixo fora do lixo, do lado do lixo, então não vai funcionar. Aí eu acho que, como os países têm, vou caçar aqui a palavra, culturas diferentes de cada um poder definir de uma forma diferente até que ponto nós temos uma IA porque cada cultura tem seus princípios, seus, seus culturas, suas, a cultura em geral. Cada povo tem sua cultura e para algumas culturas pode ser bom algo e para outros não. Aí, tipo, num país a IA é fiscalizada pelo governo e o governo disse: \"Não, você não pode ensinar o pessoal como criar um avião\". E a outra disse que tem que ensinar o pessoal. Acho que vai dar errado, vai dar errado. Vão ter duas IAs diferentes, no caso, viu? Eu acho que para dar fé tem que ser uma IA universal e as mesmas regras em todos os países. Aí que se tem alguns que podem ser moldadas, né? De acordo com a situação, mas nesse, partindo desse, eu acho que tem que ser pouco fiscalizada, mas tem algumas regras, sejam universais para todas. Tem que existir lá a regra universal para todas, OK? Mas eu não... Nenhuma pessoa de assunto informando o governo porque, porque pode ser falha, pode ser instintiva e pode de liberdade. Mais alguém gostaria de comentar algo? Não? Pois bem, então agora, certo, nós partimos para a última fase do debate em que cada participante terá um momento para falar suas considerações finais sobre o tema, sua opinião ou visão sobre o tema no geral, então sua opinião ou visão sobre o tema mudou depois do debate ou se fortaleceu ou, ou algum tipo? Fortaleceu. Opinião é a mesma: uso aberto, uso livre, uso consciente, consciente de consequência, uma regra ou outra. Fiscalização governamental não. Continua a mesma também, mas eu acredito na fiscalização governamental porque se não houver uma fiscalização, que órgão que vai ser geral para toda a sociedade? Por que que você acha que para o governo? Porque as próprias empresas, criadores de IA, não criam um meio, um órgão que fiscalize e que e que reja? Porque tem que vir no governo, sabe? Essa, esse órgão vindo de empresas não seria facilmente burlado, não? Mas o que que? Mas o que garante que a fiscalização governamental seria menos falha do que uma privada? Porque eu penso em uma fiscalização privada, como talvez tinha que ter, talvez um pouquinho do dedo do governo para ser um mediador de todas as empresas que criam IAs, por exemplo, aí pode ser OK, mas só o governo fiscalizado não é pouco, é inviável. Pensando nisso, está partindo daquele exemplo lá do que eu falei logo no início, da fome, aí a pessoa manda um processo generativo lá para a empresa e ela passa pelo governo e o governo olha. Está bacana? Vai, vai solucionar a fome. A empresa vai, aí a empresa começa a distribuir essa IA e implementar nos computadores. Dentro do governo dá certo? A pergunta é um pouco vaga porque o nosso plano de governo atual é bonito. Só que na prática que a gente vê coisa, então é. É a fiscalização em si. Por isso que eu falei, eu acho que o governo teria minimamente só consciência, no máximo. Entrar como mediador? Talvez. Porque não faz sentido, porque nada garante, seja uma situação só o governamental, seja fiscalização de empresa privada ou um consenso mundial. De qualquer forma, ela vai ser falha. Ninguém garante que ela vai ser completamente uma fiscalização completamente OK. Porque outra coisa, tu acha que a fiscalização, ela seria melhor pelo governo? Não, eu acho que seria ruim, mas impô-las em alguns cantos. Acho que vai depender muito do governo que está regendo a região, porque se for um governo que vai implementar as leis e procura resolver os problemas, pode ser uma fiscalização plausível, né? Mas aí se um governo agir com descaso, não, vai ser muito invariável. Até eu pensei agora uma junção dos 2, fase um fazer dois, passou pela fase do governo, aí passa pelos testes, entre aspas, da empresa que criou. Eu pensei na fiscalização do governo porque traz a universalidade em todas essas empresas de IA, entendeu? Como os debatedores estavam falando, cada empresa pode ter diferentes morais e éticas que podem passando por diferentes coisas, não? E eu coloquei, em tese, na minha fala, um governo que funciona perfeitamente, então pensei normal, que é falho. Talvez, talvez iniciativa público-privada seria uma boa assim, a depender da circunstância e da forma que ela vai ser criada. Porque falar de fiscalização de IA, principalmente na época atual que a gente está vivendo, que elas estão tendo o boom, que está começando a ser estudado amplamente. Então não seja uma boa hora agora. Mas em algum momento deve-se existir e deve ser adversado. Como isso vai funcionar? Como isso vai agir? Não dá para você chegar e falar: \"Ah, eu acho que a fiscalização tem que ser assim, assim\", porque ele nunca vai, nunca vai abrir todo o mundo, vai ter pontos negativos sempre, sempre. Bem, nesse caso, retomamos a pergunta final, né? Porque a gente acabou voltando ao assunto anterior, é? Houve uma mudança de visão? Quais são as suas considerações finais sobre o tema? Essa mudança ocorreu depois do debate? Poder livre, aberto, talvez um dedo do governo aí e possivelmente uma fiscalização público-privada. Continua a mesma, mas eu pensei na ideia dos debatedores e eu ainda acredito na fiscalização governamental por conta da universalidade. Mas tem que ter o dedo de mais pessoas. Mudou-se um pouco a minha ideia. Levando em conta que ainda IA está aprendendo muito ainda. É, eu concordei que não agora, né? Mas depois de um certo conhecimento de como essa IA vai se comportar e entender melhor ela, talvez exista uma certa fiscalização público-privada. Entendi. Pois bem, gente, estamos chegando ao final do nosso debate. Então vocês podem escanear esse QR para um formulário de autoavaliação, bem rapidinho. E as respostas são confidenciais e serão utilizadas só para os fins de avaliação e aprimoramento, no geral, não.\n","A limpeza foi feita em  104.25956416130066\n"]}]},{"cell_type":"markdown","source":["# Verificando a quantidade de disfluências removidas por cada prompt em comparação com o texto original"],"metadata":{"id":"YGmDaQIhqU0V"}},{"cell_type":"code","source":["hes_original, rep_original, erro_original, corr_original = count_disfluencias_in_clean(texto_limpo, hes, rep, erro, corr)"],"metadata":{"id":"tGI4QFJZgwYh","executionInfo":{"status":"ok","timestamp":1725286322024,"user_tz":180,"elapsed":12,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# Texto limpo por LLM Prompt 1.1 (Zero-shot no context)"],"metadata":{"id":"25yQtxt2gukF"}},{"cell_type":"markdown","source":["## Resultado"],"metadata":{"id":"xhTIO-1U0DmF"}},{"cell_type":"code","source":["\n","levenshtein_data = calculate_metrics(texto_limpo, response1.text)\n","print(levenshtein_data)\n","print()\n","hes_llm, rep_llm, erro_llm, corr_llm = count_disfluencias_in_clean(response1.text, hes, rep, erro, corr)\n","\n","matches_repetições, length_of_incorrect_matches_repeticoes = count_matches(rep_original, rep_llm)\n","matches_hesitações, length_of_incorrect_matches_hesitações = count_matches(hes_original, hes_llm)\n","matches_erros, length_of_incorrect_matches_erros = count_matches(erro_original, erro_llm)\n","matches_correções, length_of_incorrect_matches_correções = count_matches(corr_original, corr_llm)\n","\n","resultados = {\n","    'Repetições': (matches_repetições, len(rep_original)),\n","    'Hesitações': (matches_hesitações, len(hes_original)),\n","    'Erros': (matches_erros, len(erro_original)),\n","    'Correções': (matches_correções, len(corr_original))\n","}\n","\n","total_length_of_incorrect_matches = (length_of_incorrect_matches_repeticoes + length_of_incorrect_matches_hesitações + length_of_incorrect_matches_erros + length_of_incorrect_matches_correções)\n","print(adjust_levenshtein_distance(levenshtein_data, total_length_of_incorrect_matches))\n","print(total_length_of_incorrect_matches)\n","print(exibir_metricas(resultados))"],"metadata":{"id":"se_kXpjdKoVT","executionInfo":{"status":"ok","timestamp":1725286444466,"user_tz":180,"elapsed":334,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"60fe899e-0555-4a2c-81da-5537847d469c"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Levenshtein Distance': '931', 'Levenshtein Similarity': '97.43%', 'Edit Distance': '931', 'Original Length': '22,151', 'Processed Length': '22,228', 'Original Word Count': '3,954', 'Processed Word Count': '3,950'}\n","\n","{'Adjusted Levenshtein Distance': 689, 'Adjusted Levenshtein Similarity': '96.90%'}\n","242\n","Repetições:\n","  Acertos da LLM: 6\n","  Total de chaves no manual: 6\n","  Porcentagem de acertos: 100.00%\n","  Número de chaves não corretamente identificadas: 0\n","\n","Hesitações:\n","  Acertos da LLM: 2\n","  Total de chaves no manual: 14\n","  Porcentagem de acertos: 14.29%\n","  Número de chaves não corretamente identificadas: 12\n","\n","Erros:\n","  Acertos da LLM: 2\n","  Total de chaves no manual: 7\n","  Porcentagem de acertos: 28.57%\n","  Número de chaves não corretamente identificadas: 5\n","\n","Correções:\n","  Acertos da LLM: 2\n","  Total de chaves no manual: 6\n","  Porcentagem de acertos: 33.33%\n","  Número de chaves não corretamente identificadas: 4\n","\n","Média de porcentagem de acertos entre Hesitações, Erros e Repetições: 37.04%\n","None\n"]}]},{"cell_type":"markdown","source":["# Texto limpo por LLM Prompt 1.2 (Zero-shot some context)"],"metadata":{"id":"9pEcG8dCwoWa"}},{"cell_type":"markdown","source":["## Texto"],"metadata":{"id":"Rr7BwHdC0My9"}},{"cell_type":"markdown","source":["## Resultado"],"metadata":{"id":"Y8AHKD9q0LKF"}},{"cell_type":"code","source":["\n","levenshtein_data = calculate_metrics(texto_limpo, response2.text)\n","print(levenshtein_data)\n","print()\n","hes_llm, rep_llm, erro_llm, corr_llm = count_disfluencias_in_clean(response2.text, hes, rep, erro, corr)\n","\n","matches_repetições, length_of_incorrect_matches_repeticoes = count_matches(rep_original, rep_llm)\n","matches_hesitações, length_of_incorrect_matches_hesitações = count_matches(hes_original, hes_llm)\n","matches_erros, length_of_incorrect_matches_erros = count_matches(erro_original, erro_llm)\n","matches_correções, length_of_incorrect_matches_correções = count_matches(corr_original, corr_llm)\n","\n","resultados = {\n","    'Repetições': (matches_repetições, len(rep_original)),\n","    'Hesitações': (matches_hesitações, len(hes_original)),\n","    'Erros': (matches_erros, len(erro_original)),\n","    'Correções': (matches_correções, len(corr_original))\n","}\n","\n","total_length_of_incorrect_matches = (length_of_incorrect_matches_repeticoes + length_of_incorrect_matches_hesitações + length_of_incorrect_matches_erros + length_of_incorrect_matches_correções)\n","print(adjust_levenshtein_distance(levenshtein_data, total_length_of_incorrect_matches))\n","print(total_length_of_incorrect_matches)\n","print(exibir_metricas(resultados))"],"metadata":{"id":"khDlapzskQO2","executionInfo":{"status":"ok","timestamp":1725286452848,"user_tz":180,"elapsed":733,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2e725a2f-74dd-4b6e-8d4c-cfad0bd255a9"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Levenshtein Distance': '1,108', 'Levenshtein Similarity': '97.09%', 'Edit Distance': '1,108', 'Original Length': '22,151', 'Processed Length': '21,835', 'Original Word Count': '3,954', 'Processed Word Count': '3,880'}\n","\n","{'Adjusted Levenshtein Distance': 981, 'Adjusted Levenshtein Similarity': '95.51%'}\n","127\n","Repetições:\n","  Acertos da LLM: 6\n","  Total de chaves no manual: 6\n","  Porcentagem de acertos: 100.00%\n","  Número de chaves não corretamente identificadas: 0\n","\n","Hesitações:\n","  Acertos da LLM: 2\n","  Total de chaves no manual: 14\n","  Porcentagem de acertos: 14.29%\n","  Número de chaves não corretamente identificadas: 12\n","\n","Erros:\n","  Acertos da LLM: 5\n","  Total de chaves no manual: 7\n","  Porcentagem de acertos: 71.43%\n","  Número de chaves não corretamente identificadas: 2\n","\n","Correções:\n","  Acertos da LLM: 3\n","  Total de chaves no manual: 6\n","  Porcentagem de acertos: 50.00%\n","  Número de chaves não corretamente identificadas: 3\n","\n","Média de porcentagem de acertos entre Hesitações, Erros e Repetições: 48.15%\n","None\n"]}]},{"cell_type":"markdown","source":["# Texto limpo por LLM Prompt 2.1 (Few shot some context)"],"metadata":{"id":"ADaxbS2qwvQx"}},{"cell_type":"markdown","source":["## Resultado"],"metadata":{"id":"P13vKE6c0Sc_"}},{"cell_type":"code","source":["\n","levenshtein_data = calculate_metrics(texto_limpo, response3.text)\n","print(levenshtein_data)\n","print()\n","hes_llm, rep_llm, erro_llm, corr_llm = count_disfluencias_in_clean(response3.text, hes, rep, erro, corr)\n","\n","matches_repetições, length_of_incorrect_matches_repeticoes = count_matches(rep_original, rep_llm)\n","matches_hesitações, length_of_incorrect_matches_hesitações = count_matches(hes_original, hes_llm)\n","matches_erros, length_of_incorrect_matches_erros = count_matches(erro_original, erro_llm)\n","matches_correções, length_of_incorrect_matches_correções = count_matches(corr_original, corr_llm)\n","\n","resultados = {\n","    'Repetições': (matches_repetições, len(rep_original)),\n","    'Hesitações': (matches_hesitações, len(hes_original)),\n","    'Erros': (matches_erros, len(erro_original)),\n","    'Correções': (matches_correções, len(corr_original))\n","}\n","\n","total_length_of_incorrect_matches = (length_of_incorrect_matches_repeticoes + length_of_incorrect_matches_hesitações + length_of_incorrect_matches_erros + length_of_incorrect_matches_correções)\n","print(adjust_levenshtein_distance(levenshtein_data, total_length_of_incorrect_matches))\n","print(total_length_of_incorrect_matches)\n","print(exibir_metricas(resultados))"],"metadata":{"id":"aNglAFD20VWS","executionInfo":{"status":"ok","timestamp":1725286480619,"user_tz":180,"elapsed":337,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"20ee0a28-4dc0-482f-b61a-2fcb2b0be191"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Levenshtein Distance': '1,541', 'Levenshtein Similarity': '95.80%', 'Edit Distance': '1,541', 'Original Length': '22,151', 'Processed Length': '21,828', 'Original Word Count': '3,954', 'Processed Word Count': '3,863'}\n","\n","{'Adjusted Levenshtein Distance': 1354, 'Adjusted Levenshtein Similarity': '93.80%'}\n","187\n","Repetições:\n","  Acertos da LLM: 6\n","  Total de chaves no manual: 6\n","  Porcentagem de acertos: 100.00%\n","  Número de chaves não corretamente identificadas: 0\n","\n","Hesitações:\n","  Acertos da LLM: 6\n","  Total de chaves no manual: 14\n","  Porcentagem de acertos: 42.86%\n","  Número de chaves não corretamente identificadas: 8\n","\n","Erros:\n","  Acertos da LLM: 5\n","  Total de chaves no manual: 7\n","  Porcentagem de acertos: 71.43%\n","  Número de chaves não corretamente identificadas: 2\n","\n","Correções:\n","  Acertos da LLM: 2\n","  Total de chaves no manual: 6\n","  Porcentagem de acertos: 33.33%\n","  Número de chaves não corretamente identificadas: 4\n","\n","Média de porcentagem de acertos entre Hesitações, Erros e Repetições: 62.96%\n","None\n"]}]},{"cell_type":"markdown","source":["# Texto limpo por LLM Prompt COT"],"metadata":{"id":"rdGbaAgryVk6"}},{"cell_type":"markdown","source":["## Resultado"],"metadata":{"id":"T_V-Qdks0pAR"}},{"cell_type":"code","source":["\n","levenshtein_data = calculate_metrics(texto_limpo, response4.text)\n","print(levenshtein_data)\n","print()\n","hes_llm, rep_llm, erro_llm, corr_llm = count_disfluencias_in_clean(response4.text, hes, rep, erro, corr)\n","\n","matches_repetições, length_of_incorrect_matches_repeticoes = count_matches(rep_original, rep_llm)\n","matches_hesitações, length_of_incorrect_matches_hesitações = count_matches(hes_original, hes_llm)\n","matches_erros, length_of_incorrect_matches_erros = count_matches(erro_original, erro_llm)\n","matches_correções, length_of_incorrect_matches_correções = count_matches(corr_original, corr_llm)\n","\n","resultados = {\n","    'Repetições': (matches_repetições, len(rep_original)),\n","    'Hesitações': (matches_hesitações, len(hes_original)),\n","    'Erros': (matches_erros, len(erro_original)),\n","    'Correções': (matches_correções, len(corr_original))\n","}\n","\n","total_length_of_incorrect_matches = (length_of_incorrect_matches_repeticoes + length_of_incorrect_matches_hesitações + length_of_incorrect_matches_erros + length_of_incorrect_matches_correções)\n","print(adjust_levenshtein_distance(levenshtein_data, total_length_of_incorrect_matches))\n","print(total_length_of_incorrect_matches)\n","print(exibir_metricas(resultados))"],"metadata":{"id":"j_OhF968ydsB","executionInfo":{"status":"ok","timestamp":1725286506042,"user_tz":180,"elapsed":495,"user":{"displayName":"PEDRO LIMA","userId":"01272857310217853819"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a16724c1-5a07-443b-d172-2b6c395f2253"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Levenshtein Distance': '683', 'Levenshtein Similarity': '98.19%', 'Edit Distance': '683', 'Original Length': '22,151', 'Processed Length': '22,251', 'Original Word Count': '3,954', 'Processed Word Count': '3,963'}\n","\n","{'Adjusted Levenshtein Distance': 500, 'Adjusted Levenshtein Similarity': '97.75%'}\n","183\n","Repetições:\n","  Acertos da LLM: 6\n","  Total de chaves no manual: 6\n","  Porcentagem de acertos: 100.00%\n","  Número de chaves não corretamente identificadas: 0\n","\n","Hesitações:\n","  Acertos da LLM: 1\n","  Total de chaves no manual: 14\n","  Porcentagem de acertos: 7.14%\n","  Número de chaves não corretamente identificadas: 13\n","\n","Erros:\n","  Acertos da LLM: 2\n","  Total de chaves no manual: 7\n","  Porcentagem de acertos: 28.57%\n","  Número de chaves não corretamente identificadas: 5\n","\n","Correções:\n","  Acertos da LLM: 4\n","  Total de chaves no manual: 6\n","  Porcentagem de acertos: 66.67%\n","  Número de chaves não corretamente identificadas: 2\n","\n","Média de porcentagem de acertos entre Hesitações, Erros e Repetições: 33.33%\n","None\n"]}]}]}